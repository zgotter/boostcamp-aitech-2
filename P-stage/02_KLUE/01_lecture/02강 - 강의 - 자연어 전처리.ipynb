{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02강 - 강의 - 자연어 전처리.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNmpKFTyswGkPvbZDOPWXDN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"LvKv0FoOV7jy"},"source":["# 2. 자연어 전처리"]},{"cell_type":"markdown","metadata":{"id":"R0ngtuKFWA7l"},"source":["## 강의 소개\n","\n","인공지능에서 가장 중요한 **데이터**!! “Garbage in, garbage out” 이라는 말이 있습니다.  \n","일반적으로 좋은 데이터를 학습해야 좋은 성능의 모델을 기대할 수 있습니다.  \n","또한 데이터 전처리는 단순히 '정제' 의 개념이 아니라, 어떤 문제를 해결하겠다는 task 정의의 의미도 포함하고 있습니다!  \n","**반드시 날 것의 데이터와 친하게 지내세요!!!**\n"," \n","이번 강의에는 다양한 한국어에 특화된 전처리 기법을 배우고 실습합니다.😎  \n","한국어로 할 수 있는 거의 모든 전처리를 포함하고 있습니다! 😀\n"]},{"cell_type":"markdown","metadata":{"id":"TZIfzYI0WL-D"},"source":["<br>\n","\n","## 실습 코드 링크\n","\n","- [0. 한국어 전처리](https://drive.google.com/file/d/17BDV1MYUNOYoyddnpXI2kNyS1sVAc_Oi/view?usp=sharing)\n","- [1. 한국어 토크나이징](https://drive.google.com/file/d/1_7FLI-WW6r1VY0sb9AVT03-qaue_DIm1/view?usp=sharing)"]},{"cell_type":"markdown","metadata":{"id":"rSUSO11SWS-C"},"source":["<br>\n","\n","## Further Reading\n","\n","- [청와대 국민청원 데이터 전처리 (소개)](https://www.youtube.com/watch?v=9QW7QL8fvv0)\n","- [청와대 국민청원 데이터 전처리 (실습)](https://www.youtube.com/watch?v=HIcXyyzefYQ)"]},{"cell_type":"markdown","metadata":{"id":"i1qruTZeWWsC"},"source":["<br>\n","\n","## Further Questions\n","\n","- 텍스트 정제라는 것이 정말 필요할까요?\n","  - 어쩌라는거야? 싶으시죠? ☺️☺️\n","  - 실제로 우리가 웹이나 메신저를 통해 사용하는 언어는 '정제 되지 않은 언어' 입니다.\n","  - 해당 데이터가 적용되는 방향에 따라 정제가 필요할 수도, 필요하지 않을 수도 있습니다.\n","  - 오히려 더욱 어려운 데이터로 학습한 모델의 성능이 좋을 수도 있죠 ☺️"]},{"cell_type":"markdown","metadata":{"id":"_GcOGuPWbSHG"},"source":["<br>\n","\n","## Reference"]},{"cell_type":"markdown","metadata":{"id":"eIO6ahSAbjTz"},"source":["### huggingface Tokenizer\n","\n","- [서브워드 구축하기](https://keep-steady.tistory.com/37)\n","- [Huggingface Transformers의 attention mask 문서](https://huggingface.co/transformers/glossary.html#attention-mask)\n","- [Huggingface Transformers의 attention mask 구현](https://github.com/huggingface/tokenizers/tree/2fbd6779f6bdeb55c0fb9cceb3716ec20fc92646/bindings/python/py_src/tokenizers/implementations)"]},{"cell_type":"markdown","metadata":{"id":"qoNAhPZ-bkm3"},"source":["<br>\n","\n","### KoNLPy\n","\n","- [한국어 전처리 위한 Huggingface + KoNLPy 실습](https://www.notion.so/259bc1d236d78a77f044d638d0df300c)"]},{"cell_type":"markdown","metadata":{"id":"0jr2oa4GWcnS"},"source":["<br>\n","\n","## 2.1 자연어 전처리"]},{"cell_type":"markdown","metadata":{"id":"tMUeaVaQWrFS"},"source":["### 2.1.1 전처리란?\n","\n","- 원시 데이터(raw data)를 기계 학습 모델이 학습하는데 적합하게 만드는 프로세스\n","- 학습에 사용될 데이터를 **수집&가공**하는 모든 프로세스"]},{"cell_type":"markdown","metadata":{"id":"uNrR8G7jWpq9"},"source":["<br>\n","\n","### 2.1.2 전처리가 필요한 이유\n","\n","- 전처리는 task의 성능을 가장 확실하게 올릴 수 있는 방법이다.\n","- 모델을 아무리 바꾸고, 튜닝하더라도, 데이터 자체가 문제가 있다면 성능이 나올 수 없다.\n","- 가장 중요한 것은 데이터이다.\n","- 단, 저작권에 유의해야 한다."]},{"cell_type":"markdown","metadata":{"id":"pdjcihF3W8wF"},"source":["<br>\n","\n","### 2.1.3 자연어처리의 단계\n","\n","- Task 설계\n","- 필요 데이터 수집\n","- 통계학적 분석\n","- 전처리\n","- Tagging\n","- Tokenizing\n","- 모델 설계\n","- 모델 구현\n","- 성능 평가\n","- 완료"]},{"cell_type":"markdown","metadata":{"id":"5G6cP8fpXxxP"},"source":["<br>\n","\n","#### 2.1.3.1 Task 설계\n","\n","- ex) 유튜브 라이브에서 악성 댓글을 필터링해주세요 -> 악성 댓글 classifier를 만들자!"]},{"cell_type":"markdown","metadata":{"id":"ws2Dmt2bX9nS"},"source":["<br>\n","\n","#### 2.1.3.2 필요 데이터 수집\n","\n","- ex) 댓글 데이터를 수집"]},{"cell_type":"markdown","metadata":{"id":"UqVExbBSYMMd"},"source":["<br>\n","\n","#### 2.1.3.3 통계학적 분석\n","\n","- Token 개수 -> outlier(ex. 빈도수가 적은 토큰) 제거\n","- 빈도 확인 -> 사전(dictionary) 정의"]},{"cell_type":"markdown","metadata":{"id":"IyKBYpa9YNEb"},"source":["<br>\n","\n","#### 2.1.3.4 전처리\n","\n","- 개행문자 제거\n","- 특수문자 제거\n","- 공백 제거\n","- 중복 표현 제어 (ex. \"ㅋㅋㅋㅋㅋ\", \"ㅠㅠㅠㅠ\", ...)\n","- 이메일, 링크 제거\n","- 제목 제거\n","- 불용어(의미가 없는 용어) 제거\n","- 조사 제거\n","- 띄어쓰기, 문장분리 보정"]},{"cell_type":"markdown","metadata":{"id":"4bBBqRwiYN6y"},"source":["<br>\n","\n","#### 2.1.3.5 Tagging\n","\n","- classification을 위한 labeling"]},{"cell_type":"markdown","metadata":{"id":"_pFflk6FYO7b"},"source":["<br>\n","\n","#### 2.1.3.6 Tokenizing\n","\n","- 토큰의 단위 결정\n","- 자연어를 어떤 단위로 살펴볼 것인가\n","- 어절 tokenizing\n","  - \"오렌지는\", \"맛있다\"\n","- 형태소 tokenizing\n","  - \"오렌지/Noun\", \"는/Subject case marker\", \"맛있/Verb\", \"다/for declarative form\"\n","- WordPiece tokenizing\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1RgafRnfO2XXgHpdYD9ETozbu-oMZceST' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"bVVKw5Egi5Zh"},"source":["<br>\n","\n","#### 2.1.3.7 실제 문제에서는...\n","\n","- 위와 같은 방법으로 한 번에 처리되는 경우는 거의 없다."]},{"cell_type":"markdown","metadata":{"id":"KDQmhB4eYS5D"},"source":["<br>\n","\n","### 2.1.4 Python string 관련 함수"]},{"cell_type":"markdown","metadata":{"id":"LmSaqn6UZNsV"},"source":["#### 2.1.4.1 대소문자의 변환\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1RiuiDdasXXHiOQfMSkK4pACMQ6ZVKwfr' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"TogzkKJwZPdt"},"source":["<br>\n","\n","#### 2.1.4.2 편집, 치환\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1RlRb6_bcAxNlbq7Df5xV8iBIP3_WQIhZ' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"BFcXJ6rpZSr1"},"source":["<br>\n","\n","#### 2.1.4.3 분리, 결합\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1Rn87wCUhzUYcSOR2OOOmxvLvfUDrfEz3' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"0MyoW62ZZnI0"},"source":["<br>\n","\n","#### 2.1.4.4 구성 문자열 판별\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1RpPaWCjpE7xjnUSmYVeDLScE56C1SROt' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"H9zR6fc3ZrXk"},"source":["<br>\n","\n","#### 2.1.4.5 검색\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1RuBvoIk3JDQYHgG2pxnGzcDJRgkHsZ9u' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"PGN67TITZuBl"},"source":["<br>\n","\n","## 2.2 한국어 토큰화\n","\n","- 자연어를 어떤 단위로 관찰할 것인지 확인"]},{"cell_type":"markdown","metadata":{"id":"3JBeeoNAZy0M"},"source":["<br>\n","\n","### 2.2.1 토큰화 (Tokenizing)\n","\n","- 주어진 데이터를 토큰(Token)이라 불리는 단위로 나누는 작업\n","- 토큰이 되는 기준은 다를 수 있음\n","  - 어절, 단어, 형태소, 음절, 자소 등"]},{"cell_type":"markdown","metadata":{"id":"Ow7yxPdSaA7u"},"source":["<br>\n","\n","### 2.2.2 문장 토큰화 (Sentence Tokenizing)\n","\n","- 문장 분리"]},{"cell_type":"markdown","metadata":{"id":"Re5_QNX6aE0e"},"source":["<br>\n","\n","### 2.2.3 단어 토큰화 (Word Tokenizing)\n","\n","- 구두점 분리 및 단어 분리\n","  -  \"Hello, World!\" -> \"Hello\", \",\", \"World\", \"!\""]},{"cell_type":"markdown","metadata":{"id":"y2MAHZbdaQJa"},"source":["<br>\n","\n","### 2.2.4 한국어 토큰화\n","\n","- 영어는 \"New York\"과 같은 합성어 처리와 \"it's\"와 같은 줄임말 예외처리만 하면 띄어쓰기를 기준으로도 잘 동작하는 편\n","- 한국어는 조사나 어미를 붙여서 말을 만드는 교착어로 띄어쓰기만으로는 부족\n","  - ex) he/him -> 그, 그가, 그는, 그를, 그에게\n","- 한국어에서는 어절의 의미를 가지는 최소 단위인 형태소로 분리\n","  - ex) \"안녕하세요\" -> \"안녕/NNG\", \"하/XSA\", \"세/EP\", \"요/EC\""]},{"cell_type":"code","metadata":{"id":"wPOLpFpiarL0"},"source":[""],"execution_count":null,"outputs":[]}]}