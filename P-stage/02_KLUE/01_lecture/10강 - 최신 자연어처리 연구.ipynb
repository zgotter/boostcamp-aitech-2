{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10강 - 최신 자연어처리 연구.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOPIBJZkHMrQGGj4YtvVMza"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"s9ZyZm4XAZkM"},"source":["# 10. 최신 자연어처리 연구"]},{"cell_type":"markdown","metadata":{"id":"igIsD7cpApsU"},"source":["## 강의 소개\n","\n","드디어 KLUE 강의의 마지막 강의입니다.\n","\n","지금 이 순간에도 더 좋은 성능을 갖는 모델을 만들기 위해 많은 연구자들이 RoBERTa, XLNet, BART, T5 등등, 다양한 실험과 새로운 알고리즘을 개발하고 있습니다. 🤗\n","\n","최신 언어모델 관련 연구 트랜드를 살펴볼게요!"]},{"cell_type":"markdown","metadata":{"id":"pTWm42uaAsNS"},"source":["<br>\n","\n","## Reference\n","\n","- Reformer\n","  - [1. The Reformer - Pushing the limits of language modeling](https://colab.research.google.com/github/patrickvonplaten/blog/blob/master/notebooks/03_reformer.ipynb#scrollTo=mLMgZt_38dtR)\n","  - [2. PyTorch Reformer](https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb)\n","  - [3. Reformer For Masked LM](https://github.com/patrickvonplaten/notebooks/blob/master/Reformer_For_Masked_LM.ipynb)\n","  - [4. Training RoBERTa from scratch the missing guide polish language model](https://zablo.net/blog/post/training-roberta-from-scratch-the-missing-guide-polish-language-model)\n","- T-5\n","  - [1. TF-T5-text-to-text](https://github.com/snapthat/TF-T5-text-to-text)\n","  - [2. Text Generation with blurr](https://github.com/ohmeow/ohmeow_website/blob/master/_notebooks/2020-05-23-text-generation-with-blurr.ipynb)\n","  - [3. Transformers Summarization wandb](https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_summarization_wandb.ipynb)\n","  - [4. MT5 Inference for question generation](https://www.kaggle.com/parthplc/mt5-inference-for-question-generation)\n","  - [5. Fine-tune MT5 for question generation in hindi](https://www.kaggle.com/parthplc/finetune-mt5-for-question-generation-in-hindi)\n","- Roberta\n","  - [1. Convert Model to Long](https://github.com/allenai/longformer/blob/master/scripts/convert_model_to_long.ipynb)\n","  - [2. How to train a new language model from scratch using Transformers and](https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/01_how_to_train.ipynb#scrollTo=5oESe8djApQw)\n","  - [3. Warm-starting RoBERTaShared for BBC XSum](https://github.com/patrickvonplaten/notebooks/blob/master/RoBERTaShared_for_BBC_XSum.ipynb)\n","- Longformer\n","  - [1. Longoemer QA Training](https://github.com/patil-suraj/Notebooks/blob/master/longformer_qa_training.ipynb)\n","- Multimodal transformers\n","  - [1. SimpleTransformers](https://github.com/ThilinaRajapakse/simpletransformers/blob/master/README.md#encoder-decoder)\n","  - [2. HuggingFace Transformers와 테이블 형식 데이터를 통합하는 방법](https://ichi.pro/ko/huggingface-transformerswa-teibeul-hyeongsig-deiteoleul-tonghabhaneun-bangbeob-201256872169396)"]},{"cell_type":"markdown","metadata":{"id":"s9fHDAKGBEEV"},"source":["<br>\n","\n","## 10.1 BERT 이후의 LM\n","\n","- BERT 이후에 등장한 다양한 언어 모델을 소개한다."]},{"cell_type":"markdown","metadata":{"id":"Xyi1_OHPBL-7"},"source":["<br>\n","\n","### 10.1.0 BERT와 GPT-2의 문제점\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1dCyaB8AmuYw-BTykZg9JaNrh_IYigUWL' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"mKe-HZbXRRNP"},"source":["<br>\n","\n","### 10.1.1 XLNet"]},{"cell_type":"markdown","metadata":{"id":"RNpDAsUYBYnD"},"source":["#### 10.1.1.1 Relative positional encoding\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1dEXSPkLnJ5c6tLLUCpxf41AIYeyedQZR' width=400/>\n","\n","- Relative positional encoding 방식 적용 (Transformer-XL)\n","- Position encoding -> token 간 관계성을 표현하기 위함\n","- BERT처럼 `0, 1, 3, ...`으로 위치를 표현하는 것이 아니라 현재 token의 위치 대비 0번째, 1번째, 2번째, ... 와 같이 상대적 거리 표현법을 사용\n","- Sequence 길이에 제한이 없어짐"]},{"cell_type":"markdown","metadata":{"id":"IjvaREcfBwlm"},"source":["<br>\n","\n","#### 10.1.1.2 Permutation Language Modeling\n","\n","- MASK 토큰을 없애고 permutation language modeling 사용\n","- 문장의 각 토큰의 순서를 순열로 섞는다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1dJnL_UXN9q9E6GMZ38K6iHbqAzDFiGzY' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"bbMYOE-eB6PF"},"source":["<br>\n","\n","#### 10.1.1.3 GLUE benchmark\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1dUHWnLT3aTBpKwi3S6dO8V7-texYeI3Y' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"W8hdCONkCAuv"},"source":["<br>\n","\n","### 10.1.2 RoBERTa\n","\n","- BERT 구조에서 학습 방법을 고민\n","\n","<br>\n","\n","1. Model 학습 시간 증가 + Batch size 증가 + Train data 증가\n","2. Next Sentence Prediction 제거\n","  - Fine-tuning과 관련 없음\n","  - 너무 쉬운 문제라 오히려 성능 하락\n","3. Longer sentence 추가\n","4. Dynamic masking\n","  - 똑같은 텍스트 데이터에 대해 masking을 10번 다르게 적용하여 학습\n","\n","<br>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1dV4vaEQdvvxCVqaf5dw3NQpntkCwzP4A' width=800/>\n","\n","- 두 문장 유사도 비교 때 경험했듯이, 문제를 어렵게 만들고 어려운 문제를 학습한 모델이 성능이 좋다."]},{"cell_type":"markdown","metadata":{"id":"9R5eChKQChrY"},"source":["<br>\n","\n","### 10.1.3 BART\n","\n","- Transformer Encoder-Decoder 통합 LM\n","- 학습 방법으로는 다양한 방법 선택\n","  - Token Masking: masking된 토큰 예측\n","  - Sentence Permutation: 순열로 순서가 섞인 문장의 올바른 순서 예측\n","  - Document Rotation: 문서의 토큰이 rotation된 것을 올바르게 예측\n","  - Token Deletion\n","  - Text Infilling\n","- 여러 개의 복잡한 task를 학습에 사용함으로서 언어를 좀 더 잘 이해하게 됐다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1dZIQ_qTJgCW6Qy22hirlCcL9aJKZaSO5' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"vBMtVrj7CsRO"},"source":["<br>\n","\n","- GLUE benchmark\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1dcx2tdRrdTb95vChN0__Xkz8keJ1GjVB' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"iLeQ66vNCyft"},"source":["<br>\n","\n","### 10.1.4 T-5\n","\n","- Transformer Encoder-Decoder 통합 LM\n","- 현재까지의 끝판왕!\n","- pre-training 과정에서 온갖 task들을 다양하게 학습할 수 있다.\n","- 학습 시 masking 기법을 사용한다.\n","  - masking 대상이 하나의 토큰만 되는 것이 아니고 의미를 갖는 여러 어절들을 동시에 masking하고 multi mask를 복원하는 과정을 수행한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1deZN5LSWRGpqyX_0rQ3tIHZgTX8g-asU' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"80o49VSSC9wm"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1dgWnmBrQX3pkHdbHbxL3cLhbbgEw30EG' width=600/>\n","\n","- 위 그림에서 \"for inviting\"과 같이 2개의 어절을 하나의 mask 토큰으로 치환한다.\n","- 또한 여러 개의 토큰을 동시에 masking 처리 한다.\n","- 디코더에서는 여러 개의 masking token을 동시에 복원하는 방식으로 학습된다."]},{"cell_type":"markdown","metadata":{"id":"UXUnmxcNDFPP"},"source":["<br>\n","\n","- GLUE benchmark\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1dlDOk-sZ_yYMifmlQFLv-YhziOzNIN_K' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"JkquIRozToVA"},"source":["<br>\n","\n","- [https://huggingface.co/google/mt5-base](https://huggingface.co/google/mt5-base)\n","- multilingual t5 모델\n","- 한국어도 포함되어 있다."]},{"cell_type":"markdown","metadata":{"id":"LClxgLV8DH3d"},"source":["<br>\n","\n","### 10.1.5 Meena\n","\n","- 대화 모델을 위한 LM\n","- Transformer 인코더 블럭 한 개와 디코더 블럭 여러 개를 사용\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1duiXrHinnY5SajQAavrYmHw_DL8jMBDr' width=600/>\n","\n","- 소셜 미디어의 데이터(341GB, 400억개의 단어)를 이용하여 26억개의 파라미터를 가진 신경망 모델을 이용한 end-to-end multi-turn 챗봇\n","- 챗봇의 평가를 위한 새로운 Metric인 **SSA(Sensibleness and Specificity Average)**를 제시\n","  - Sensibleness: 현재까지 진행중인 대화의 가장 적절한 답변을 했는 지를 평가 (적절할수록 점수가 높음)\n","  - Specificity: 얼마나 구체적으로 답변을 했는 지를 평가 (구체적일수록 점수가 높음)"]},{"cell_type":"markdown","metadata":{"id":"ixvGu5muDdr2"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1e8ECNvnK7esw3hn2dhxSYJ5ZQvD5U6w-' width=600/>\n","\n","- Meena는 사람의 점수(86%)와 굉장히 유사한 점수(79%)를 얻었다."]},{"cell_type":"markdown","metadata":{"id":"459gKTbtDicF"},"source":["<br>\n","\n","### 10.1.6 Controllable LM\n","\n","- LM의 윤리성을 control하기 위한 연구들이 진행되고 있다."]},{"cell_type":"markdown","metadata":{"id":"yxloli1EDtuV"},"source":["<br>\n","\n","#### 10.1.6.1 Plug and Play Language Model (PPLM)\n","\n","- 다음에 등장할 단어 -> 확률 분포를 통해 선택\n","- 내가 원하는 단어들의 확률이 최대가 되도록 이전 상태의 vector를 수정\n","- 수정된 vector를 통해 다음 단어 예측\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1eHqH4ZEL9dKPLzfqXAXQEx7N2-e7iOJN' width=800/>\n","\n","- gradient update를 필요로하지 않기 때문에 내가 원하는 단어를 생성하도록 유도할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"xkCzfs7fD4D3"},"source":["<br>\n","\n","- 확률 분포를 사용하는 것이기 때문에 중첩도 가능\n","  - 기쁨 + 놀람 + 게임\n","- 특정 카테고리에 대한 감정을 컨트롤해서 생성 가능\n","  - 정치적, 종교적, 성적, 인종적 키워드에 대해서는 중성적인 단어를 선택해서 생성\n","  - 범죄 사건에 대해서는 부정적인 단어를 선택해서 생성\n","- 확률 분포 조절을 통해 그라데이션 분노 가능\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1fChy83liPuhL1D7KWaxR6Lg-M5DxuIEi' width=400/>"]},{"cell_type":"markdown","metadata":{"id":"9vmhBo0RESgc"},"source":["<br>\n","\n","#### 10.1.6.2 한국어 Bow 실험\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1eJrzAuv2GwdVKxbrV-R_1XDyRdHGkegt' width=300/>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1eMtmi22CUHRGwbkBoPOJau5o2WFQbt9I' width=600/>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1eObu-I5aDusJTd-L8h73iNnaN2RJLJr1' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"oK5u6HVVEZJ9"},"source":["<br>\n","\n","### 10.1.7 질문: 과연 자연어 to 자연어로 충분할까?\n","\n","- 우리가 언어를 배울 때, written language인 책만 보고 학습을 하는가?\n","- 태어나서 첫 마디를 뗄 때가지, 우리는 spoken language를 통해 학습한다.\n","- 또한 인간은 시각, 청각, 후각, 촉각, 미각 등의 모든 감각을 통해 세상을 학습한다.\n","- 그렇다면 인공지능을 구현하기 위해 자연어 to 자연어로 충분할까?"]},{"cell_type":"markdown","metadata":{"id":"s8TQngHbE5sF"},"source":["<br>\n","\n","## 10.2 Multi-modal Language Model\n","\n","- Multi-modal을 활용한 언어 모델들을 살펴보자."]},{"cell_type":"markdown","metadata":{"id":"wHIXIA6RE__L"},"source":["<br>\n","\n","### 10.2.1 할머니세포 (Grandmother cell)"]},{"cell_type":"markdown","metadata":{"id":"l2w8vCc4FSjE"},"source":["#### 10.2.1.1 Philip Roth (1969)의 소설 Portnoy's Complaint\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1e_i4ej6gkA5Yqf97Hlms_K77WwjOJYkp' width=800/>\n","\n","- 즉, '어머니'를 representation하는 concept neuron을 모두 제거하니, 해당 concept에 대한 기억이 사라짐\n","- Jerry Lettvin는 소설에서 아이디어를 얻어 할머니 세포라는 개념을 제시 (1969)\n","- 이 세포는 1개의 단일 세포가 어떤 개념(concept)에 대해 반응 (e.g., 할머니, 어머니)\n","  - 실제로 발견!"]},{"cell_type":"markdown","metadata":{"id":"stByWoHvFuv8"},"source":["<br>\n","\n","#### 10.2.1.2 Electrophysiological recording - Microelectrode arrays (MEAs)\n","\n","- 다양한 이미지를 보여줬을 때 뇌세포의 활성이 어떻게 변화하는 지를 관찰\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1eaFKposyxlgjpjX1ZIp7aOVtnz2pZAS7' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"OKC4uMiuF2yW"},"source":["<br>\n","\n","#### 10.2.1.3 Halle Berry neuron\n","\n","- 수많은 뉴런 중 Halle Berry라는 뉴런이 발견됨\n","- 해당 뉴런은 여러 가지 이미지들 중 Halle Berry라는 여성의 이미지를 보여줄 때 활성화되는 것을 발견했다.\n","- 얼굴 이미지 뿐만 아니라 글자, 그림, 배역 등에서도 반응을 했다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1emnqvRIZ6ltk5lkDVirJh0LMloIpTc1c' width=800/>\n","\n","- 우리의 뇌는 Multi-modal로 객체를 인지한다.\n","  - 이미지, 글자, 그림, 배역 등\n","- Multi-modal 연구는 필수이다."]},{"cell_type":"markdown","metadata":{"id":"G5b4h8DOF_OF"},"source":["<br>\n","\n","### 10.2.2 LXMERT\n","\n","- Cross-modal reasoning language model (Learning Cross-Modality Encoder Representations from Transformers)\n","\n","<br>\n","\n","- 이미지와 자연어를 동시에 학습\n","- 동시에 학습된 정보를 하나의 모델로 합침으로서 이미지와 자연어를 하나로 연결할 수 있다.\n","- Cross-Modality Output은 자연어의 임베딩된 정보와 이미지가 임베딩된 정보가 크로스되어 하나로 합쳐져서 만들어지게 된다.\n","- 그래서 Cross-Modality Output가 BERT에서의 CLS 토큰의 역할을 할 수 있게 된다.\n","- 이것을 통해 분류 task를 수행했을 때 좋은 성능을 나타냈다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1etfhbvWVfgaNrFfIgXpD_-FkyNg46k_2' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"eEwiYTkzGZd3"},"source":["<br>\n","\n","- 이미지 feature - 자연어 feature가 하나의 모델에 반영됨\n","- 이미지에 대한 질문을 자연어로 전달\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1evmAMNKI6QR-Y2lrrzjARGcE0ayXQKNT' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"0V4p-EHbGhlu"},"source":["<br>\n","\n","### 10.2.3 ViLBERT\n","\n","- BERT for vision-and-language\n","- BERT와 구조가 똑같다.\n","- 입력의 앞부분에는 이미지 벡터에 대한 임베딩 토큰을 넣고 sep 토큰을 넣고 뒷부분에 자연어에 대한 벡터를 넣는다.\n","- 출력의 cls 토큰 위에 classification layer를 추가하면 자연어와 이미지가 합쳐진 정보(multi-modal information)를 통해 분류를 수행할 수 있다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1ewrVJ3lA3TDKOC93u7XsoZLKy5k8dOh1' width=800/>\n","\n","<br>\n","\n","- 이미지와 텍스트를 통해 분류\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1exJDwj5knw5K4fVyNGf-qXMACxBncR6G' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"KtQKeJ6JGrx9"},"source":["<br>\n","\n","### 10.2.4 Dall-e\n","\n","- 자연어로부터 이미지를 생성해내는 모델"]},{"cell_type":"markdown","metadata":{"id":"GQL2uJG7G920"},"source":["<br>\n","\n","#### 10.2.4.1 이미지 생성 예시\n","\n","- ex) 아보카도 모양의 안락 의자\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1f0yqw1cFYTPmHFiuF8Iu2l6EzcaOOcLR' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"2NkfY7ifG49-"},"source":["- ex) 아보카도 모양의 램프\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1f2EWZjmNXOq5bl0qyRq6fCBrHyFpCckQ' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"WY3CDvf-HAPG"},"source":["<br>\n","\n","#### 10.2.4.2 학습 과정\n","\n","1. VQ-VAE를 통해 이미지의 차원 축소 학습\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1f3NufOjfQmUmtlRrsxm-AixXviZZUURM' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"j3RmhNrOHPrO"},"source":["<br>\n","\n","2. Autoregressive 형태로 다음 토큰 예측 학습\n","  - 256 토큰에는 반드시 텍스트 임베딩 벡터가 들어간다. (패딩 포함)\n","  - 그 다음부터는 이미지 벡터를 생성해내도록 한다.\n","  - GPT-2와 유사한 방식\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1f6RAhuVxJ7VTTBWu6V45UIgamtPQjfz-' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"Y3SmuW-YHZBP"},"source":["<br>\n","\n","#### 10.2.4.3 한국어 Dall-e 모델 실험\n","\n","- 학습 데이터: MSCOCO-2014 (13GB)\n","  - 이미지에 대한 서술형 문장으로 구성된 데이터\n","- 모델 사이즈: Dall-e 대비 1/120\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1f6dAMc7mE1BvNflyXxnjFTLx97oGdC84' width=800/>"]},{"cell_type":"code","metadata":{"id":"eCZd1JykHmfv"},"source":[""],"execution_count":null,"outputs":[]}]}