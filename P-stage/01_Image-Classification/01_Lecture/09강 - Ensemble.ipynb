{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"09강 - Ensemble.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNapOvdKKSsBsYSPzEQ/TgJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"USIKJkrkLqvM"},"source":["# 9. Ensemble"]},{"cell_type":"markdown","metadata":{"id":"1y-xe6KjLzRG"},"source":["## 강의 소개\n","\n","- Generalization 성능 향상을 위한 앙상블의 개념에 대해서 알아보고 지금까지 학습된 모델 Weight를 가지고 앙상블 블을 한번 시도해 봅시다.\n","- 또한, 경진대회에서 자주 언급되는 K-fold cross validation과 Test Time Augmentation(TTA)에 대해 알아봅니다.\n","- 마지막으로, Hyperparameter optimization에 대해서 간략하게 다루겠습니다.\n","\n","<br>\n","\n","추가\n","\n","- 제가 Hyperparameter optimization 관련해서 '시간도 오래걸리고 해봤자 성능 변화도 잘 없고' 라는 말을 시작으로 언급드렸는데요. 오해의 소지가 있을 것 같아서 추가적으로 부연 설명을 드리려 합니다.\n","- Hyperparameter Opt는 적절한 파라미터를 찾기 위해 경우에 따라서는 성능 향상에 비해 돈과 시간과 리소스가 많이 필요한 것은 사실입니다. 하지만 \"내 모델의 성능을 최대한 올릴 수 있는 Hyperparameter를 자동으로 찾는다.\"는 관점에서는 상당히 큰 메리트가 있습니다. 그런 의미에서 최근 급부상하고 있는 AutoML분야에서 이 Hyperparameter Opt는 상당히 중요한 요소중 하나입니다. 아래 Further Reading에서 관련 내용을 한번 읽어보시는걸 추천드려요!"]},{"cell_type":"markdown","metadata":{"id":"8VcFYCfUL-gd"},"source":["<br>\n","\n","## Further Reading\n","\n","- [Optuna github](https://github.com/optuna/optuna)\n","- [Hyperparameter Opt 포스팅](https://blog.floydhub.com/guide-to-hyperparameters-search-for-deep-learning-models/)\n","- [AutoML 관련 포스팅](https://medium.com/daria-blog/automl-%EC%9D%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%BC%EA%B9%8C-1af227af2075)"]},{"cell_type":"markdown","metadata":{"id":"ZuYz-epaMXls"},"source":["<br>\n","\n","## 9.1 Overview\n","\n","- 여러 실험을 하다 보면 여러가지 모델로 여러 결과를 만들었을 겁니다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1hZjckFRDJKuQ2eSqliC4zb2GAV-idZlK' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"jVcpHhhTMtqQ"},"source":["<br>\n","\n","## 9.2 Ensemble\n","\n","- Ensemble\n","- Model Averaging (Voting)\n","- Cross Validation\n","- TTA (Test Time Augmentation)"]},{"cell_type":"markdown","metadata":{"id":"Fjm1fL03M6B9"},"source":["<br>\n","\n","### 9.2.1 Ensemble (앙상블)\n","\n","- \"싱글 모델보다 더 나은 성능을 위해 <font color='skyblue'>서로 다른</font> 여러 학습 모델을 사용하는 것\""]},{"cell_type":"markdown","metadata":{"id":"3uELz7ziNJfF"},"source":["<br>\n","\n","### 9.2.2 Ensemble of Deep NN\n","\n","- Low Bias, High Variance $\\rightarrow$ Overfitting\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=15wLaiWs3kATOITrMhNEjH_zuqX5r92HB' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"7WjHwWykNQ_o"},"source":["<br>\n","\n","### 9.2.3 Model Averaging (Voting)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1qBdcR5Icp7gos8-PrI5Yto2IajD8ukuX' width=800/>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1_yDDtJJ4l9xYAcPady4TytarCU1LQ6aM' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"YJuElmZJN93N"},"source":["<br>\n","\n","### 9.2.4 Cross Validation\n","\n","- 훈련 셋과 검증 셋을 분리는 하되, 검증 셋을 학습에 활용할 수는 없을까?\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1IH70tLpp2iWOwyUWGC08dEiXk1KCnyfU' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"cBoBIWSPOI9o"},"source":["<br>\n","\n","### 9.2.5 Stratified K-Fold Cross Validation\n","\n","- 가능한 경우를 모두 고려 + Split 시에 Class 분포까지 고려\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1l1XY5RJuOQMzT6V0HvRCi3puyFTMYhZR' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"Oo7E3ywFObi0"},"source":["<br>\n","\n","### 9.2.6 TTA (Test Time Augmentation)\n","\n","- 테스트할 때 Augmentation 을 어떻게 하는가?\n","- 모델의 출력을 애매하게 만들 수 있지 않을까?\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1ErbA1ltw1O0_xRMOe-WVzqW2W52VOwd1' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"03qsVKjnOrRn"},"source":["<br>\n","\n","- 테스트 이미지를 Augmentation 후 모델 추론, 출력된 여러 가지 결과를 앙상블\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1yuDb0FIrA6XZLFos-2Ri0KJfYcBRp18Z' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"-hdL1_OqO0V4"},"source":["<br>\n","\n","### 9.2.7 성능과 효율의 Trade-off\n","\n","- 앙상블 효과는 확실히 있지만 그 만큼 학습, 추론 시간이 배로 소모됨\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1WFikxkutoLy__Mef9a1CmWBTLCTy7d7U' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"tP9qW7mtO-0m"},"source":["<br>\n","\n","## 9.3 Hyperparameter Optimization\n","\n","- Hyperparameter?\n","- Optuna"]},{"cell_type":"markdown","metadata":{"id":"zfNaMK51PH8V"},"source":["<br>\n","\n","### 9.3.1 Hyperparameter?\n","\n","- 시스템의 매커니즘에 영향을 주는 주요한 파라미터\n","  - Learning rate\n","  - Batch size\n","  - Hidden Layer 갯수\n","  - Loss 파라미터\n","  - Optimizier 파라미터\n","  - k-fold\n","  - Dropout\n","  - Regularization"]},{"cell_type":"markdown","metadata":{"id":"2wtcn3saPWzM"},"source":["<br>\n","\n","- 파라미터를 변경할 때 마다 학습을 해야 한다.\n","- 시간과 장비가 충분하다면 해볼 수 있겠으나..\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=16wKCufWxKDrfQYNtyGXtMQhy4wh6q2mZ' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"wpZRrb-6Pd9Q"},"source":["<br>\n","\n","### 9.3.2 Optuna\n","\n","- 파라미터 범위를 주고 그 범위 안에서 trials 만큼 시행\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1QUEfX90ZbGYZaQSi0r7riuv4kg3Eo7QJ' width=600/>\n","\n","- 출처: https://optuna.org/#code_examples"]},{"cell_type":"code","metadata":{"id":"a7YNzyglPo1f"},"source":[""],"execution_count":null,"outputs":[]}]}