{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01강 - 딥러닝 기본 용어 설명 - Historical Review.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP1KnTbvmFIElYFFFE1aYXl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"n41sUm4Lelek"},"source":["# 1. 딥러닝 기본 용어 설명 - Historical Review"]},{"cell_type":"markdown","metadata":{"id":"rbsPZvcsfeoz"},"source":["## 1.1 Introduction\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=16PUigtAnvlPRjUVmUH-pk_T23QvLmyF-' width=600/>\n","\n","딥러닝을 연구한다. $\\neq$ 인공지능 전부를 연구한다."]},{"cell_type":"markdown","metadata":{"id":"JWqykbbXjGo7"},"source":["- Key Components of Deep Learning\n","  - The **data** that the model can learn from\n","  - The **model** how to transform the data\n","  - The **loss** function that quantifies the badness of the model\n","  - The **otimization algorithm** to adjust the parameters to minimize the loss"]},{"cell_type":"markdown","metadata":{"id":"eKNVmwh7m1V-"},"source":["- 새로운 논문이 나왔을 때 위 4가지 관점을 바탕으로 어느 부분이 새로워졌는 지를 보면 어떤 contribution 이 있는 지 이해하기 쉽다."]},{"cell_type":"markdown","metadata":{"id":"W1qDur5vfpLq"},"source":["<br>\n","\n","### 1.1.1 Data\n","\n","- Data depend on the type of the problem to solve.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=106g82cRXH0plmQEsJK7XS6yUphhouZbm' width=600/>\n","\n","- semantic Segmentation\n","  - 이미지가 주어지면 이미지의 각 픽셀별로 어느 클래스에 속하는 지 판단  \n","  (클래스 : 도로, 사람, 자동차, 하늘 등)\n","- Pose Estimation\n","  - 이미지의 2차원, 3차원 skeleton 분석"]},{"cell_type":"markdown","metadata":{"id":"4Fe7WsPPfrLB"},"source":["<br>\n","\n","### 1.1.2 Model\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1bQFd3_0r2y7WCwy9zzDGAa1-7QmXjOhk' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"QmqYM-NBfs_C"},"source":["<br>\n","\n","### 1.1.3 Loss\n","\n","- The **loss** function is a proxy(근사치) of what we want to achieve.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=19SJ_VHaweIDXmZiLQFLHM9hBuJaO-Cbz' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"9yVZczkBfu-x"},"source":["<br>\n","\n","### 1.1.4 Optimization Algorithm\n","\n","- Optimization\n","- Regularization\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1W_lXwVr97ZvMzUF6EH7FgN2r5ErWtOHn' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"OSenN1xLgDD6"},"source":["<br>\n","\n","## 1.2 Historical Review"]},{"cell_type":"markdown","metadata":{"id":"F26VXZTmgF8p"},"source":["### 1.2.1 2012 - AlexNet\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1cOy1z3FZmBoFY4mfB8-3FtNAQ0IbuqpQ' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"3cCfwr5aow3q"},"source":["- CNN\n","- 224x224 이미지가 들어왔을 때 해당 이미지를 분류\n","- ImageNet 대회에서 딥러닝을 이용하여 처음으로 1등을 한 모델 (2012년)"]},{"cell_type":"markdown","metadata":{"id":"5JA_FsecgI_x"},"source":["<br>\n","\n","### 1.2.2 2013 - DQN\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1GDoioRKNnzbDJm2viT9xhwaSwSMY95xK' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"c4pk3yOApZSf"},"source":["- 알파고를 만든 알고리즘\n","- Q-Learning 이라는 강화학습 기법 사용"]},{"cell_type":"markdown","metadata":{"id":"cJaFjSVQgLa5"},"source":["<br>\n","\n","### 1.2.3 2014 - Encoder / Decoder\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1cA-wyfOiBR8T07McAwqdegt4bJW7tdkt' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"__PgHoRkqSh-"},"source":["- NMT(Neural Machine Translation) 문제를 풀기 위한 모델\n","  - NMT : 기계번역\n","- 단어의 시퀀스가 주어졌을 때 어떤 벡터로 인코딩하고, 이를 다른 언어의 단어 시퀀스로 디코딩"]},{"cell_type":"markdown","metadata":{"id":"Pc2Y2abZgOVB"},"source":["<br>\n","\n","### 1.2.4 2014 - Adam Optimizer\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1yFIO64SE4-HjE0ZlXXTrf5b1hZPqmVvi' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"8eFiib6JgRI7"},"source":["<br>\n","\n","### 1.2.5 2015 - GAN, Generative Adversarial Network\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=11bw4eNlJHlJwncV0u9lwjh5vYA6cVYvu' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"nByCO6r4rUE4"},"source":["- 이미지 생성"]},{"cell_type":"markdown","metadata":{"id":"-N91hQfFgUXJ"},"source":["<br>\n","\n","### 1.2.6 2015 - ResNet, Residual Networks\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1qoNYQO7_YSexkgJwX0CtXee9IqeDqQM2' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"DDtkTa6frvyk"},"source":["- 딥러닝을 딥러닝이라고 부르게 된 계기 (layer 를 많이 쌓음)"]},{"cell_type":"markdown","metadata":{"id":"MTm1nvjugcjB"},"source":["<br>\n","\n","### 1.2.7 2017 - Transformer (Attention Is All You Need)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1IcDB2erfmURhOunsmJXZhKiihe7EJHPS' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"Wp4W2dlMr-oh"},"source":["- 도전적인 내용의 논문"]},{"cell_type":"markdown","metadata":{"id":"f0zJzKdUgfKi"},"source":["<br>\n","\n","### 1.2.8 2018 - BERT (fine-tuned NLP models)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1H9dyZVnfEEsyjrtXtwVLSiiUspKrs2oq' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"4tXQuQLisSsM"},"source":["- Transformer 구조 활용\n","- Bidirectional Encoder 활용\n","- fine-tuned NLP models\n","  - 큰 말뭉치를 활용해서 Pre-train 실시\n","  - 내가 풀고자 하는 소수의 데이터에 해당 네트워크를 fine-tuning"]},{"cell_type":"markdown","metadata":{"id":"nhhgDgp_ghth"},"source":["<br>\n","\n","### 1.2.9 2019 - BIG Language Models\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1capXRqKzeIyxQtZZzI1iRyHUsDiT5sQ6' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"V30lpBIrsxcO"},"source":["- GPT-3\n","  - language model\n","  - 굉장히 많은 파라미터를 갖고 있다."]},{"cell_type":"markdown","metadata":{"id":"zZr2sSinitr-"},"source":["<br>\n","\n","### 1.2.10 2020 - Self Supervised Learning\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1uMpPikb7iJ5ZuRaAhoxe85oARFhb8seR' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"8n1JiZLgiwku"},"source":["- SimCLR\n","  - 학습 데이터 이외에 label 을 모르는 unsupervised data 를 활용\n","- Self Supervised Data Sampling\n","  - 도메인 지식을 통해 학습 데이터를 추가로 생성"]},{"cell_type":"code","metadata":{"id":"3cYmpUKYtWjn"},"source":[""],"execution_count":null,"outputs":[]}]}