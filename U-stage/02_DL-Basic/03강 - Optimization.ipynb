{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"03강 - Optimization.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNGDHZaI30u0R1P+d71IAQs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PUVW_EzPmIgX"},"source":["# 3. 최적화 (Optimization)"]},{"cell_type":"markdown","metadata":{"id":"CKk2T2XbmNNr"},"source":["## 3.1 Introduction"]},{"cell_type":"markdown","metadata":{"id":"StzV1-tMmjua"},"source":["### 3.1.1 Gradient Descent\n","\n","- First-order iterative optimization algorithm for finding a local minimum of a differentiable function.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1-CFA8Y_wWY97EvAelCoqzUvynw0Pr4KK' width=600/>\n","\n","- loss function 이 주어지고 이 것이 줄어들었을 때 최적화를 이룰 것이라고 기대한다.\n","- 내가 찾고자 하는 파라미터를 가지고 loss function 을 편미분한 값을 이용해서 학습을 하겠다는 것이 Gradient Descent 이다.\n","- 1차 미분 사용 (First-order)\n","- 반복적으로 최적화를 실시 (iterative optimization)"]},{"cell_type":"markdown","metadata":{"id":"vLcIGBdtm3nT"},"source":["<br>\n","\n","## 3.2 최적화 문제의 중요한 개념들 (Important Concepts in Optimization)\n","\n","- Generalization\n","- Under-fitting vs. over-fitting\n","- Cross validation\n","- Bias-variance tradeoff\n","- Bootstrapping\n","- Bagging and boosting"]},{"cell_type":"markdown","metadata":{"id":"zwOhmWVXnEvK"},"source":["<br>\n","\n","### 3.2.1 Generalization\n","\n","- How well the learned model will behave on unseen data.\n","- 학습을 마친 모델이 아직 보지 않은 데이터에 대해 얼마나 잘 동작할까?\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1RRei5gfX5bfFbCurJmZkeiOxk2NW7X5N' width=600/>\n","\n","- 일반화 성능을 높이는 것이 우리의 목적이다.\n","- 일반적으로 학습을 진행하면 학습 데이터에 대한 training error 는 감소한다.\n","- 하지만 traininig error 가 0 이 되었다고 해서 원하는 최적값에 도달했다는 보장은 없다.\n","  - 학습에 사용하지 않은 테스트 데이터에 대한 test error 는 증가할 수 있기 때문\n","- generalization performance 는 training error 와 test error 사이의 **차이**를 말한다.\n","- gneralization 이 좋다. == 이 네트워크의 성능이 학습 데이터와 비슷하게 나올 것임을 보장한다.\n","- 학습 데이터에 대한 성능 자체가 좋지 않을 경우 gneralization performance 가 좋다고 해서 테스트 데이터에 대한 성능이 좋다고 볼 수 없다.\n"]},{"cell_type":"markdown","metadata":{"id":"8wD57C5QnaX6"},"source":["<br>\n","\n","### 3.2.2 Underfitting vs. Overfitting\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1cjFoUmuUEt-Pke6W08OnVvGKXPPSTMGT' width=600/>\n","\n","(출처: https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html)\n","\n","- underfitting\n","  - 네트워크가 너무 간단하거나 training 을 너무 조금 시켜서 학습 데이터 조차 잘 못맞추는 현상 (왼쪽 그림)\n","- overfitting\n","  - 학습 데이터에 대해 잘 동작하지만 테스트 데이터에 대해 잘 동작하지 않는 현상 (오른쪽 그림)\n"]},{"cell_type":"markdown","metadata":{"id":"EslkcHdKnvRI"},"source":["<br>\n","\n","### 3.2.3 Cross-validation\n","\n","- Cross-validation is a model validation technique for assessing how the model will generalize to an independent (test) dataset.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1s8NsDWvp-BVQ2oYyefw5YnsflH6Ycveo' width=600/>\n","\n","(출처: https://blog.quantinsti.com/cross-validation-machine-learning-trading-models/)\n","\n","- 보통 training data 와 validation data 를 나눠서 학습 데이터로 제공한다.\n","- training data 로 학습시킨 모델이 학습에 사용되지 않은 validation data 를 기준으로 얼마나 잘 되는 지를 본다.\n","- training data 와 validation data 는 얼만큼 나누는 것이 좋을까?\n","- 이러한 문제를 해결하고자 하는 것이 cross-validation (k-fold validation) 이다.\n","\n","<br>\n","\n","- neural network 를 학습하는 데 많은 종류의 hyperparameter 가 사용된다.\n","- cross-validation 을 통해 최적의 hyperparameter set 을 찾고 학습을 시킬 때는 hyperparameter set 을 고정한 상태에서 모든 데이터를 사용한다.\n","  - 테스트 데이터는 학습에 어떠한 방법으로도 사용되서는 안된다."]},{"cell_type":"markdown","metadata":{"id":"8S1HvLfJoM_L"},"source":["<br>\n","\n","### 3.2.4 Bias and Variance\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1WTeScR-g_ZcLUDEnBDWdufBli_jXcasV' width=400/>\n","\n","(출처: https://work.caltech.edu/telecourse)\n","\n","- Variance\n","  - 입력을 넣었을 때 출력이 얼마나 일관적으로 나오는 가?\n","- bias\n","  - 평균적으로 봤을 때 얼마나 true target 에 접근했는가?"]},{"cell_type":"markdown","metadata":{"id":"nN9q1r4yoVC6"},"source":["<br>\n","\n","### 3.2.5 Bias and Variance Tradeoff\n","\n","$$\n","\\text { Given } \\mathcal{D}=\\left\\{\\left(x_{i}, t_{i}\\right)\\right\\}_{i=1}^{N}, \\text { where } t=f(x)+\\epsilon \\text { and } \\epsilon \\sim \\mathcal{N}\\left(0, \\sigma^{2}\\right)\n","$$\n","\n","- We can derive that what we are minimizing (**cost**) can be decomposed into three different parts\n","  - $\\text{bias}^2$\n","  - variance\n","  - noise.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1y_mG8euvYcsqy25WGututwLqBcWVYsXn' width=600/>\n","\n","- 학습 데이터에 noise 가 포함되어 있다고 가정했을 때 noise 가 포함된 target data 를 minimize 하는 것은 3가지 파트로 나눌 수 있다.\n","  - minimize 하는 것은 한 가지 값(cost)인데 사실은 3가지 component 로 이루어져 있다.\n","- 따라서 3가지를 동시에 minimize 하는 것이 아니라 하나가 작아지면 다른 것은 커질 수 밖에 없다. (trade off)\n","  - bias 를 줄이면 variance 는 높아질 가능성이 크다.\n","  - variance 를 줄이면 bias 는 높아질 가능성이 크다.\n","\n","<br>\n","\n","- 학습 데이터에 noise 가 포함되어 있을 경우에는 bias 와 variance 를 둘 다 줄일 수 있는 것은 힘들다."]},{"cell_type":"markdown","metadata":{"id":"AbWjDEVzpNA8"},"source":["<br>\n","\n","### 3.2.6 Bootstrapping\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1PMr-jkpzD8Ls3Nguhrxmtm-_Fd_PdHvE' width=600/>\n","\n","- Bootstrapping is any test or metric that uses random sampling with replacement.\n","\n","<br>\n","\n","- Bootstrap : 부츠의 신발끈\n","- Bootstrapping : 신발끈을 위로 들어서 하늘을 날겠다.(?)\n","\n","<br>\n","\n","- 학습 데이터가 100개가 있을 때 이를 한 번에 다 사용하는 것이 아니라 100개 중에서 몇 개만 활용한 모델을 여러 개 만들겠다는 것이 Bootstrapping 이다.\n","  - 학습 데이터가 고정되어 있을 때 subsampling 을 통해 학습 데이터를 여러 개를 만들고 이를 가지고 여러 모델을 만들어 사용한다.\n","- 이렇게 생긴 여러 개의 모델에 대해 하나의 입력이 있을 때 각각의 모델이 같은 예측값을 가질 수도 있지만 아닐 수도 있다.\n","- 각 모델들의 예측값의 일관성을 보고 전체적인 모델의 예측을 만든다."]},{"cell_type":"markdown","metadata":{"id":"u5sSQQJ4pePB"},"source":["<br>\n","\n","### 3.2.7 Bagging vs. Boosting\n","\n","- Bagging (**B**ootstrapping **agg**regat**ing**)\n","  - Multiple models are being trained with bootstrapping.\n","  - ex) Base classifiers are fitted on random subset where individual predictions are aggregated (voting or averaging).\n","- Boosting\n","  - It focuses on those specific training samples that are hard to classify.\n","  - A strong model is built by combining weak learners in sequence where each learner learns from the mistakes of the previous weak learner.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1tltLMjdkqfylHhb6YGn7JHwgNE2wJ_us' width=600/>\n","\n","(출처: https://www.datacamp.com/community/tutorials/adaboost-classifier-python)\n","\n","- bagging\n","  - 각각의 모델들을 독립적으로 사용\n","  - 학습 데이터를 여러 개로 subsampling 하여 여러 모델들을 학습시키고 각 모델들의 output 의 평균을 계산한다.\n","  - 앙상블이라고 부르기도 한다.\n","- boosting\n","  - 각각의 모델들을 독립적으로 사용하지 않음\n","  - 학습 데이터를 sequential 하게 바라본다.\n","  - 모델 하나를 만들고 전체 학습 데이터를 통해 학습시킨다.\n","  - 해당 모델이 제대로 예측하지 못한 데이터에 대해서만 학습하는 또 다른 모델을 만든다.\n","  - 이렇게 여러 개의 모델을 만들어서 모델들을 합친다.\n","  - 하나 하나의 모델들(weak learner)을 sequential 하게 합쳐서 하나의 strong learner 를 만드는 것이다."]},{"cell_type":"markdown","metadata":{"id":"qvCVSqxFreX0"},"source":["<br>\n","\n","## 3.3 Practical Gradient Descent Methods"]},{"cell_type":"markdown","metadata":{"id":"9_Vdwm5jrq38"},"source":["### 3.3.1 Grdient Descent 분류\n","\n","- Stochastic gradient descent\n","  - Update with the gradient computed from **a single sample.**\n","  - 데이터 하나 하나를 이용해 gradient 를 update\n","- Mini-batch gradient descent\n","  - Update with the gradient computed from **a subset of data.**\n","  - batch size 만큼의 데이터를 이용해 gradient 를 update\n","  - 대부분의 deep learning 에서는 Mini-batch gradient descent 를 사용\n","- Batch gradient descent\n","  - Update with the gradient computed from **the whole data.**\n","  - 전체 데이터를 이용해 gradient 를 update"]},{"cell_type":"markdown","metadata":{"id":"OFY8-FmKr7iq"},"source":["<br>\n","\n","### 3.3.2 Batch-size Matters (paper)\n","\n","> \"It has been observed in practice that when using a larger batch there is a degradation in the quality of the model, as measured by its ability to generalize.\"\n","\n","> \"We ... present numerical evidence that supports the view that large batch methods tend to converge to **sharp minimizers** of the training and testing functions. In conotrast, small-batch methods consistently converge to **flat minimizers**... this is due to the inherent noise in the gradient estimation.\"\n","\n","- 큰 batch size 를 사용하면 sharp minimizer 에 도달하게 된다.\n","- 작은 batch size 를 사용하면 flat minimizer 에 도달하게 된다.\n","\n","<br>\n","\n","- batch size 를 작게 사용하는 것이 일반적으로 성능이 좋다.\n","  - sharp minimizer 에 도달하는 것 보다 flat minimizer 에 도달하는 것이 더 좋다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=18caJ93fHkqGD-37wYqVn5zfjhJfiIU65' width=600/>\n","\n","(출처: On Large-batch Training for Deep Learning: Generalization Gap and Sharp Minima, 2017)\n","\n","<br>\n","\n","- flat minimum 같은 경우 위 그림과 같이 testing function 이 training function 과 조금 멀어지다 하더라도 testing function 에서 적당히 낮은 값을 갖게 된다.\n","  - 일반화 성능이 좋다.\n","- 하지만 sharp minimum 같은 경우 testing function 이 training function 과 약간만 멀어지게 되더라고 높은 값을 갖게 된다."]},{"cell_type":"markdown","metadata":{"id":"_0bHKjU1sfQy"},"source":["<br>\n","\n","### 3.3.3 Gradient Descent Methods\n","\n","- loss function 을 구하고 나서 보통은 손으로 편미분을 계산하지 않는다.\n","- 다음과 같은 방법들이 자동으로 미분을 계산해준다.\n","- 이 방법들 중 어떤 방법을 사용할 지 내가 선택해야 한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1HCqqAs3bUMRTt1JJCC6jUsSIoMbmzRNk' width=400/>\n","\n","- Stochastic gradient descent\n","- momentum 방법\n","  - Momentum\n","  - Nesterov accelerated gradient, NAG\n","- Adaptive 방법  \n","  - Adagrad\n","  - Adadelta\n","  - RMSprop\n","- momentum + Adaptive 방법\n","  - Adam"]},{"cell_type":"markdown","metadata":{"id":"QKrgih4As5UL"},"source":["<br>\n","\n","#### 3.3.3.1 Gradient Descent\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1S7OYBvUe2XXU7M8kVsLOmljhOijQT7ix' width=300/>\n","\n","- $W$ : neural newtork 의 weight 를 의미한다.\n","- $g_t$ : gradient\n","\n","<br>\n","\n","- 기본적인 gradient descent 는 gradient 는 $\\eta$ 라고 불리는 learning rate(= step size) 만큼 곱해서 기존 weight 에서 빼줘서 weight 를 업데이트 한다.\n","\n","<br>\n","\n","- 이 방법의 문제점은 learning rate 를 설정하는 게 너무 어렵다는 점이다."]},{"cell_type":"markdown","metadata":{"id":"RWQOeJqBtHSz"},"source":["<br>\n","\n","#### 3.3.3.2 Momentum\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1sjGucpRvtH0uQvpIOqTYjDNYMq12gdOE' width=400/>\n","\n","- Momentum : 관성\n","- momentum 은 이동 거리를 조절하는 것이다.\n","- 한 번 gradient 가 특정 방향으로 흐르면 다음 번 gradient 가 다른 방향으로 흘러도 원래 가던 방향을 이어 나가는 것\n","\n","\n","$$\n","\\begin{align*}\n","W_{t+1} &\\leftarrow W_{t}-\\eta a_{t+1} \\\\\n","&\\leftarrow W_{t}-\\eta \\left( \\beta a_t + g_t \\right)\n","\\end{align*}\n","$$\n","\n","- $\\beta$ : momentum 이라는 hyperparameter\n","- $a_{t+1}$ : 현재 gradient($g_t$) 와 이전 시점까지 누적된 gradient($a_t$) 의 합\n"]},{"cell_type":"markdown","metadata":{"id":"MeDtmnOctS9y"},"source":["<br>\n","\n","#### 3.3.3.3 Nesterov Accelerated Gradient (NAG)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1hC3zG6iIHaBmOLceqEtrVBrLAvMlHAnb' width=400/>\n","\n","- Momentum 과 유사하다.\n","- gradient 를 계산할 때 **Lookahead gradient** 를 계산한다.\n","- $a_t$ 라는 현재 정보가 있으면 그 방향으로 한번 가보고 이동한 방향에서 gradient 를 계산하여 accumulation 을 한다."]},{"cell_type":"markdown","metadata":{"id":"he8-MuK3N3Ye"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1ziurmR-dFqEfbfwajnz9MzL9SVWd7WdA' width=600/> (출처: https://golden.com/wiki/Nesterov_momentum)\n","\n","- momentum 을 관성으로 해석해보면 관성의 힘으로 인해 global minimum 을 지나쳐서 수렴(converge) 하지 못할 수 있다.\n","  - momentum : 관성 방향 + gradient 방향 으로 이동\n","- NAG 는 이동한 지점에서의 gradient 를 계산하여 accumulate 하기 때문에 global minimum 방향으로 흘러들어가게 된다.\n","  - NAG : 관성 방향으로 이동 -> 그 지점의 gradient 방향으로 이동\n"]},{"cell_type":"markdown","metadata":{"id":"ZQdwqobzQ7ds"},"source":["- NAG 의 장점은 global minimum 에 momentum 에 비해 좀 더 빠르게 수렴(converge)할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"Bz23rMKytfCf"},"source":["<br>\n","\n","#### 3.3.3.4 Adagrad (Adaptive Gradient)\n","\n","- **Adagrad** adapts the learning rate, performing larger updates for infrequent and smaller updates for frequent parameters.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1hLRJ_gn8bRtAqQunNvugAnNCJpwLrLgd' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"Z3ccMpRARiok"},"source":["- neural network 의 파라미터가 얼만큼 지금까지 변해왔는 지 혹은 안 변해 왔는 지를 살펴본다.\n","  - 많이 변한 파라미터는 적게 변화시킴\n","  - 많이 변하지 않은 파라미터는 많이 변화시킴\n","- 각 파라미터가 얼만큼 변했는 지를 $G_t$ 에 저장해 놓는다.\n","- $G_t$\n","  - Sum of gradient squares\n","  - 지금까지 gradient 가 얼만큼 변했는 지를 제곱해서 더함\n","  - 이 값은 계속해서 커질 것이다. (해당 파라미터가 많이 변했다는 것을 의미)\n","  - 이 값을 분모에 넣어 계산하기 때문에 이 값이 크면 업데이트를 조금하고 값이 작으면 업데이트를 많이 하게 된다.\n","- $\\epsilon$\n","  - for numerical stability\n","  - 0으로 나눠지지 않게 하기 위한 값\n"]},{"cell_type":"markdown","metadata":{"id":"ry4fnrmjSe-d"},"source":["- What will happen if the training occurs for a long period?\n","- 이 방법의 가장 큰 문제는 $G_t$ 값이 계속 커지기 때문에 결국에는 $G_t$ 가 무한대로 가게 되면 분모값이 무한대가 되어 $W$ 값이 업데이트되지 않는다.\n","- 뒤로 갈수록 학습이 멈춰지는 현상이 발생한다."]},{"cell_type":"markdown","metadata":{"id":"gDxOmC9xtzsi"},"source":["<br>\n","\n","#### 3.3.3.5 Adadelta (Adaptive Delta)\n","\n","- **Adadelta** extends **Adagrad** to reduce its monotonically decreasing the learning rate by restricting the accumulation window.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1XrmsrcUOCrBLQU9pZ5cqUZxppN8NNYa2' width=500/>\n","\n","- Adadelta 는 Adagrad 의 문제점이 였던 $G_t$ 가 계속 커지는 현상을 막기 위해 개발된 방법이다.\n","- 현재의 time step $t$ 가 주어졌을 때 주어진 window size 만큼의 time step 안에서의 $G$(gradient 의 제곱)를 사용하겠다는 것이 핵심 아이디어이다.\n"]},{"cell_type":"markdown","metadata":{"id":"MdU9EsrzTQ6B"},"source":["- 하지만 이 방법 또한 window size 를 크게 하면 그 크기 만큼의 이전 $G$ 에 대한 정보를 가지고 있어야 한다.\n","- 이를 방지할 수 있는 방법이 $G$ 를 구할 때 제곱의 합이 아닌 **지수이동평균(Exponential Moving Average)**을 사용하는 것이다.\n","\n","$$\n","G_{t}=\\gamma G_{t-1}+(1-\\gamma) g_{t}^{2}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"j0WSJh1YVdns"},"source":["- $G_t$\n","  - EMA of gradient squares\n","  - gradient 의 제곱의 지수이동평균\n","- $H_t$\n","  - EMA of difference squares"]},{"cell_type":"markdown","metadata":{"id":"U0tKuvolVTqx"},"source":["- Adadelta 의 가장 큰 특징은 learning rate 이 없다는 것이다.\n","- 그래서 실제로는 많이 활용되지 않는다."]},{"cell_type":"markdown","metadata":{"id":"t_3L_Z33uDNI"},"source":["<br>\n","\n","#### 3.3.3.6 RMSprop\n","\n","- **RMSprop** is an unpublished, adaptive learning rate method proposed by Geoff Hinton in his lecture.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=18gUrCPFgK7O7zHbQ_Q5D_Mglv0ECYc0F' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"kXkuAzU6VtWc"},"source":["- Geoff Hinton 이 논문이 아닌 강의 도중 이야기한 방법이다.\n","- Adagrad 처럼 gradient 를 제곱한뒤 합하여 $G_t$ 를 구하는 것이 아니라 EMA 를 통해 구해준다.\n","- 이 값을 분모에 넣고 $\\eta$ 라는 stepsize를 추가한다."]},{"cell_type":"markdown","metadata":{"id":"7RQQgSQFuNTb"},"source":["<br>\n","\n","#### 3.3.3.7 Adam (Adaptive Moment Estimation)\n","\n","- Adaptive Moment Estimation (Adam) lerverages both past gradients and squared gradients.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=12xF2WUa3DIPfN_DK54KLNSBT7HYl9xbD' width=600/>\n","\n","- Adam effectively combines momentum with adaptive learning rate approach."]},{"cell_type":"markdown","metadata":{"id":"nfamNttuWQIk"},"source":["- gradient squares 를 EMA 로 가져가는 동시에 momentum 을 같이 활용한다."]},{"cell_type":"markdown","metadata":{"id":"q4iewfrnW4un"},"source":["\n","- Adam 의 hyperparameter\n","  - $\\beta_1$ : momentum 을 얼마나 유지시킬 것인지에 대한 값\n","  - $\\beta_2$ : gradient squares 의 EMA 정도에 대한 값\n","  - $\\eta$ : learning rate\n","  - $\\epsilon$\n","- 위의 4개의 hyperparameter 를 조정하는 것도 중요하다."]},{"cell_type":"markdown","metadata":{"id":"G9rrjU-4uiWs"},"source":["<br>\n","\n","## 3.4 Regularization\n","\n","- Regularization\n","  - 규제\n","  - 학습에 반대되는 방향으로 규제를 적용한다.\n","  - 일반화를 위해 사용하는 것\n","- Regularization 의 종류\n","  - Ealry stopping\n","  - Parameter norm penalty\n","  - Data augmentation\n","  - Noise robustness\n","  - Label smoothing\n","  - Dropout\n","  - Batch normalization"]},{"cell_type":"markdown","metadata":{"id":"kPApMRuXuwpC"},"source":["<br>\n","\n","### 3.4.1 Early Stopping\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1G8Q2bgXPD8mS8h0tZrlqXNRNxlTTQg83' width=600/>\n","\n","- Note that we need **additional validation data** to do early stopping."]},{"cell_type":"markdown","metadata":{"id":"kIuOo34SYUnc"},"source":["- training error 가 줄어들면 test error 는 줄어들다 다시 증가한다.\n","- testing data 를 보면 안되기 때문에 validation error 를 사용하여 validation error 가 증가하는 시점에서 학습을 중단하는 것을 early stopping 이라고 한다.\n","- early stopping 을 위해서는 추가적인 validation data 가 필요하다는 점이 중요하다."]},{"cell_type":"markdown","metadata":{"id":"UenFZP21u6xi"},"source":["<br>\n","\n","### 3.4.2 Parameter Norm Penalty\n","\n","- It adds smoothness to the function space.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1Np2V6Lk0nhLz7-G1XhVRdcgWhlfnZKoS' width=400/>"]},{"cell_type":"markdown","metadata":{"id":"0NAiDap7ZFoT"},"source":["- neural network 의 파라미터가 너무 커지지 않게 하는 것"]},{"cell_type":"markdown","metadata":{"id":"7fJzNEeWvDYq"},"source":["<br>\n","\n","### 3.4.3 Data Augmentation\n","\n","- More data are always welcomed.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1iiR_5RYLNwktOgeCqnfThpF1ihbnnd9q' width=800/>\n","\n","- 데이터가 많을 수록 더 좋은 성능을 나타낼 수 있다."]},{"cell_type":"markdown","metadata":{"id":"EO87dM3zZWhJ"},"source":["- However, in most cases, training data are given in advance.\n","- In such cases, we need data augmentation.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=18BtegBC9Lf2gc5X_UN4F--VXiQ7R5Kj3' width=400/>\n","\n","- data augmentation 을 통해 data 의 갯수를 늘릴 수 있다.\n","  - ex) 이미지를 회전 시키거나 크기를 확대 및 축소한다.\n","- 이미지의 label 이 변하지 않는 한도 내에서 data augmentation 를 해야 한다.\n","  - ex) MNIST 데이터에서 6 이미지를 뒤집어 9 를 만들어서 학습시키면 안된다."]},{"cell_type":"markdown","metadata":{"id":"zpadyEeXvIlu"},"source":["<br>\n","\n","### 3.4.4 Noise Robustness\n","\n","- Add random noises inputs or weights.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1ted5SlagllMULcnzjXzc2S9CcLA2gqxb' width=600/>\n","\n","- 입력 데이터에 노이즈를 추가\n","- 성능이 왜 좋은 지는 아직 알 수 없다."]},{"cell_type":"markdown","metadata":{"id":"T8hY5W2Evhs6"},"source":["<br>\n","\n","### 3.4.5 Label Smoothing\n","\n","- 데이터 두 개를 뽑아서 이를 섞어주는 것\n","- decision boundary 를 부드럽게 만들어주는 효과가 있다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1ikJd8w2HPXHUzpbXsu7Wz-3AsGyYk9e_' width=600/> (출처: CutMix: Regularization Strategy to Train Strong Classifiers with Localizable Features, 2019)\n","\n","- 강아지와 고양이 사진을 섞어서 학습 데이터를 만들고 이에 맞게 label 도 섞는다."]},{"cell_type":"markdown","metadata":{"id":"BUj6YHV-vz30"},"source":["#### 3.4.5.1 Mix-up\n","\n","- **Mix-up** constructs augmented trainig examples by mixing both input and output of two randomly selected training data.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1nrMMkTAJA5xnYDXiuiHShd8nh6k6HPx6' width=600/> (출처: mixup: Beyond Empirical Risk Minimization, 2018)\n","\n","- 두 이미지의 투명도를 조절하여 섞음"]},{"cell_type":"markdown","metadata":{"id":"ILvYfyTcvufr"},"source":["<br>\n","\n","#### 3.4.5.2 CutMix\n","\n","- **CutMix** constructs augmented training examples by mising inputs with cut and paste and outputs with soft labels of two randomly selected training data.\n","\n","- 특정 부분은 고양이, 나머지 부분은 강아지 이미지를 사용하여 섞는다."]},{"cell_type":"markdown","metadata":{"id":"dU4lIJZRwDzi"},"source":["<br>\n","\n","### 3.4.6 Dropout\n","\n","- In each forward pass, randomly set some neurons to zero.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1dwWKHayDgWOn06l-MassSud08dG83-Fn' width=600/>\n","\n","- neural network 의 weight 를 0으로 만든다."]},{"cell_type":"markdown","metadata":{"id":"vW2-hb10wNkN"},"source":["<br>\n","\n","### 3.4.7 Batch Normalization\n","\n","- Batch normalization compute the empirical mean and variance independently for each dimension (layers) and normalize.\n","\n","$$\n","\\begin{aligned}\n","\\mu_{B} &=\\frac{1}{m} \\sum_{i=1}^{m} x_{i} \\\\\n","\\sigma_{B}^{2} &=\\frac{1}{m} \\sum_{i=1}^{m}\\left(x_{i}-\\mu_{B}\\right)^{2} \\\\\n","\\hat{x}_{i} &=\\frac{x_{i}-\\mu_{B}}{\\sqrt{\\sigma_{B}^{2}+\\epsilon}}\n","\\end{aligned}\n","$$\n","\n","(출처: Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift, 2015)\n","\n","<br>\n","\n","- 내가 적용하고자 하는 layer 에 statistics 를 표준화(normalization)하는 것\n","  - 정규화 : 평균을 빼주고 표준편차로 나눔\n","- layer 를 깊게 쌓을 때 Batch Normalization 를 사용하면 성능 향상을 얻을 수 있다."]},{"cell_type":"markdown","metadata":{"id":"S7Y7jcegwgvl"},"source":["- There are different variances ofo normalizations.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1MX3zd4rNAcFQ5B4YLQe02igLtZ7TcEed' width=600/> (출처: Group Normalization, 2018)\n","\n","- Normalization 의 다양한 방법들이 존재한다."]},{"cell_type":"code","metadata":{"id":"9sF2ohX0jUZ5"},"source":[""],"execution_count":null,"outputs":[]}]}