{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05강 - Modern CNN - 1x1 convolution 의 중요성.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPIddK42H9Krcl55YmJ1zTY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0l9ytKZyVJ8P"},"source":["# 5. Modern CNN - 1x1 convolution 의 중요성\n","\n","- 주의해서 볼 것\n","  - 각각의 파라미터의 숫자\n","  - 네트워크의 깊이\n","- 네트워크의 깊이는 깊어지고, 파라미터의 숫자는 줄어들어 성능이 향상한다."]},{"cell_type":"markdown","metadata":{"id":"UGhHP7d5Vo6c"},"source":["<br>\n","\n","## 5.0 ILSVRC\n","\n","- **I**mageNet **L**arge-**S**cale **V**isual **R**ecognition **C**hallenge\n","  - Classification / Detection / Localization / Segmentation\n","  - 1,000 different categories\n","  - Over 1 million images\n","  - Training set: 456,567 images\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1jdbXQBkYcOm5rwunh5ZE4L2YBQmJiiEH' width=400/>"]},{"cell_type":"markdown","metadata":{"id":"sGOv4yIqpcCR"},"source":["- 년도별 성능 비교\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1VVQP1lqJ689Vu7J1fu20NJR0cJXhwfkW' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"4lnpaKy3VQfo"},"source":["<br>\n","\n","## 5.1 AlexNet (won in 2012)\n","\n","> Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, “ImageNet \n","Classification with Deep Convolutional Neural Networks,” NIPS, 2012\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=17NpP3RDGXZnctqHWzyEbBuVT60g6b-tG' width=600/>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1bUCaawroZEv-UXWFD8kDZwOkGcE9VEOW' width=600/>\n","\n","- AlexNet 주요 특징\n","  - 네트워크가 2개로 나눠져 있다.\n","    - GPU 가 부족했기 때문\n","  - input 에 대한 필터로 11x11x3 을 사용한다.\n","    - 파라미터 관점에서 봤을 때 이는 좋은 선택이 아닐 수 있다.\n","    - 11x11 필터를 사용하게 되면 하나의 convolution 의 커널이 볼 수 있는 이미지의 영역은 커지지만 상대적으로 필요한 파라미터의 갯수는 많아진다.\n","  - 5개의 convolution layer 와 3개의 dense layer 를 사용한다.\n","\n","<br>\n","\n","- Key ideas\n","  - Rectified Linear Unit (ReLU) activation\n","  - GPI implementation (2 GPUs)\n","  - Local response normalization, Overlapping pooling\n","  - Data augmentation\n","  - Dropout"]},{"cell_type":"markdown","metadata":{"id":"UnIxDRMuVn_n"},"source":["<br>\n","\n","### 5.1.1 ReLU Activation\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1run3v5bXPqXJUQTQ2THbmJ1fhpq4SXbN' width=300/>\n","\n","- Preserves properties of linear models\n","  - 선형 모델들이 갖고 있는 좋은 성질들을 갖고 있다.\n","- Easy to optimize with gradient descent\n","- Good generalization\n","- Overcome the vanishing gradient problem\n","  - 중요!"]},{"cell_type":"markdown","metadata":{"id":"BgBrfz8-XgxR"},"source":["<br>\n","\n","## 5.2 VGGNet (won in 2014)\n","\n","> Karen Simonyan, Andrew Zisserman, “Very Deep Convolutional Networks \n","for Large-Scale Image Recognition,” ICLR, 2015\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1jSP_4xBt51XGd0MeCFnDdfejIHpMoRlM' width=600/>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1-v5xu5FhiT5EgD8HZa1fIe_bONF0w5eI' width=600/>\n","\n","- VGGNet 주요 특징\n","  - Increasing depth with 3x3 convolution filters (with stride 1)\n","    - **3x3 convolution 만 사용**했다.\n","  - 1x1 convolution for fully connected layers\n","    - fully connected layer 를 위해 1x1 convolution 사용 (중요하지 않음)\n","  - dropout (p=0.5)\n","  - VGG16, VGG19"]},{"cell_type":"markdown","metadata":{"id":"wo7z3NmsXolK"},"source":["<br>\n","\n","### 5.2.1 Why 3x3 convolution?\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1FR5CW-JcF5YzHoU9i0Cn5T8v_Y6SIobO' width=600/>\n","\n","- convolution filter 의 크기가 커짐으로서 얻을 수 있는 이점은 하나의 필터로 찍었을 때 고려되는 input 의 크기가 커진다는 점이다.\n","  - 이것을 **Receptive field** 라고 한다. (Receptive: 수용적인, 받아들이는)\n","- 3x3 필터를 2번 사용하는 것과 5x5 필터를 1번 사용하는 것은 Receptive field 차원에서는 동일하다.\n","- 하지만 파라미터 갯수는 3x3 필터를 2번 사용한 것이 훨씬 작다."]},{"cell_type":"markdown","metadata":{"id":"Z4BhNmRfX-AX"},"source":["<br>\n","\n","## 5.3 GoogLeNet (won in 2014)\n","\n","> Christian et al. “Going Deeper with Convolutions”, CVPR, 2015\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1CX5Q3mbPxnGGEUNLk1kGUdvVbrsBD_mg' width=600/>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1vPSJ4RSR2EuKyRi3IiOLD6pfIiLOUJ63' width=800/>\n","\n","- **1x1 convolution**은 dimension reduction 효과를 얻을 수 있다.\n","  - 여기서 dimension 은 채널을 의미한다.\n","- 이를 통해 파라미터의 숫자를 줄일 수 있다.\n","\n","<br>\n","\n","- GoogLeNet won the ILSVRC at 2014\n","  - It combined network in network (NiN) with **inception blocks**.\n","  - 비슷하게 생긴 네트워크가 내트워크 안에서 여러 번 반복된다.\n","  - 이러한 것을 네트워크 안에 네트워크가 있다고 해서 network in network (NiN) 이라고 부른다."]},{"cell_type":"markdown","metadata":{"id":"FhjvZtmHYH4N"},"source":["<br>\n","\n","### 5.3.1 Inception Block\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1Vgh4GCMwz6Xt0SaLTHd9vacEv7MOPhNW' width=600/>\n","\n","- inception block 은 하나의 입력이 들어왔을 때 여러 layer 로 펴졌다가 다시 합쳐진다.\n","- convolution filter 를 적용하기 전에 1x1 convolution 이 들어간다.\n","  - 이 것이 중요한 역할을 해준다.\n","\n","<br>\n","\n","- What are benefits of the inception block?\n","  - Reduce the number of parameter.\n","    - 1x1 convolution 이 중간에 끼어들어감으로 인해 파라미터의 갯수를 줄일 수 있다.\n","- How?\n","  - Recall how the number of parameters is computed.\n","  - 1x1 convolution can be seen as channel-wise dimension reduction.\n","    - 1x1 convolution 은 채널 방향으로 dimension 을 줄이는 효과가 있다."]},{"cell_type":"markdown","metadata":{"id":"uZa6XZsyYoPQ"},"source":["<br>\n","\n","### 5.3.2 Benifit of 1x1 convolution\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1jZU6jKwauOq0G-gXSUw6TeIiYghCvWBQ' width=600/>\n","\n","- **1x1 convolution** enables about 30% reduce of the number of parameters!\n","\n","<br>\n","\n","- 3x3 convolution 을 생각해보자. (depth 는 128)\n","- 왼쪽 그림\n","  - channel 이 128 인 입력에 3x3 필터를 적용하여 128 channel 을 같는 출력을 얻기 위해서는 총 147,456 개의 파라미터가 필요하다.\n","- 오른쪽 그림\n","  - 입력과 출력은 왼쪽 그림과 동일하다.\n","  - 중간에 1x1 convolution 을 통해서 128 짜리를 32로 줄인다.  \n","  (채널 방향으로 정보를 줄임)\n","  - 이렇게 줄어든 layer 에 3x3 필터를 적용하여 128 짜리 layer 를 만든다.\n","  - 이렇게 구성한 네트워크의 파라미터 갯수는 왼쪽 그림에 비해 현저히 줄어든 40,960개가 된다."]},{"cell_type":"markdown","metadata":{"id":"D9E1Hek5Yz1X"},"source":["<br>\n","\n","### 5.3.3 leat number of parameters\n","\n","- Quiz: Which CNN architecture has the least number of parameters?\n","  - AlexNet (8-layers) -> 60M\n","  - VGGNet (19-layers) -> 110M\n","  - GoogLeNet (22-layers) -> 4M\n","- The answer is **GoogLeNet**"]},{"cell_type":"markdown","metadata":{"id":"LlIhNrxdZVcR"},"source":["<br>\n","\n","## 5.4 ResNet (won in 2015)\n","\n","> Kaiming He, Xiangyu Zhang, Shaoquing Ren, Jian Sun, “Deep Residual \n","Learninig for Image Recognition,”, CVPR, 2015\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=10EIitn5HEgzBoREEd3zM7ZygoLKB_RM8' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"PaSc73JlZag5"},"source":["<br>\n","\n","### 5.4.1 Deeper neural network\n","\n","- Deeper neural networks are hard to train.\n","  - Overfitting is usually caused by an excessive number of parameters.\n","  - But, not in this case.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1SuehkhpS84vwfi7vRyOLpwIwuYRXj3Lt' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"yA8ygK1-Z6TR"},"source":["<br>\n","\n","### 5.4.2 Identity map\n","\n","- Add an identity map (skip connection)\n","- 1단 짜리 convolution layer 에 입력을 더해준다.\n","- convolution layer 는 입력과의 차이(residual) 만 학습하는 것이다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1YmpeuWmARiQ2vBtq8dVraegw5rhxvVCe' width=700/>"]},{"cell_type":"markdown","metadata":{"id":"jIBF-seh0-IN"},"source":["- 일반적인 모델은 layer 가 많아지면 error 가 덜 떨어지는 반면 ResNet 을 사용하면 많을 layer 를 쌓을수록 error 가 더 떨어진다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1cfYnKiIDMn-LqQMo-4z5CYs26AqHQ2Xi' width=700/>"]},{"cell_type":"markdown","metadata":{"id":"eBU1s3g0dnVc"},"source":["- Add an identity map **after** nonlinear activations\n","- x 와 f(x) 를 더할려면 차원이 같아야 한다.\n","- 차원을 맞추기 위해 x 에 1x1 convolution 을 적용한 것이 Projected Shortcut 이다.\n","  - 현재는 많이 사용하지 않음\n","\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1opeyusQBEdQ9E7AfYwEoDI-2INY-VPA1' width=700/>"]},{"cell_type":"markdown","metadata":{"id":"GR6vuFpLd0zQ"},"source":["<br>\n","\n","### 5.4.3 Batch normalization\n","\n","- Batch normalization **after** convolutions\n","- Batch normalization 이 convolution 다음에 일어난다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1QXz2wKd0xhHEakOhcrH6YajanyYri_y2' width=700/>"]},{"cell_type":"markdown","metadata":{"id":"6BexHD9yflSi"},"source":["<br>\n","\n","### 5.4.4 Bottleneck architecture\n","\n","- Bottleneck architecture 는 GoogLeNet 의 Inception Block 과 동일하다.\n","  - 3x3 convolution 을 하기 전에 1x1 convolution 을 통해 input 의 채널을 줄이고 convolution 을 수행하고 input channel 을 늘리기 위해 1x1 convolution 이 한번 더 들어간다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1parn-Vvxd8FjZOoEdkR4FJhe4sxry4Eu' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"oMqKyU3-frOJ"},"source":["<br>\n","\n","### 5.4.5 Performance & parameter size\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1xTxJ8ri-4vW1LqZ-54GsEslfzyORmnXT' width=800/>\n","\n","- Performance increases while parameter size decreases."]},{"cell_type":"markdown","metadata":{"id":"_O_Au1wYf2Br"},"source":["<br>\n","\n","## 5.5 DenseNet\n","\n","> Gao Huang, Zhuang Liu, Laurens van der Maaten, Kilian Weinberger, \n","“Densely Connected Convolutional Networks,” CVPR, 2017"]},{"cell_type":"markdown","metadata":{"id":"ja3_A6KSf9X-"},"source":["<br>\n","\n","### 5.5.1 concatenation instead of addition\n","\n","- DenseNet uses **concatenation** instead of **addition**\n","- x 와 f(x) 를 더하는 것 대신 concatenation 한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1qLf-S8FhOW3qUViOZrRxN2G4Hba8iY5J' width=400/>"]},{"cell_type":"markdown","metadata":{"id":"ssdREQTK2etb"},"source":["- concatenation 을 하게 되면 채널이 기하급수적으로 커지게 된다.\n","- 그러면 여기에 적용되는 convolution feature map 의 채널 또한 커지게 된다. (파라미터 갯수 또한 증가)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1oPEsnMVkN-2ki1CNcK6-jEeKijQq16LG' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"6zyvfVCegNTh"},"source":["<br>\n","\n","### 5.5.2 Dense & Transition Block\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1R_Taurp4rfK-0gYwvOCSvE_PIIZIQl-v' width=800/>\n","\n","- Dense Block\n","  - Each layer concatenates the feature maps of all preceding layers.\n","  - The number of channels increases geometrically.\n","  - concatenation 을 실시\n","\n","<br>\n","\n","- Transition Block\n","  - BatchNorm -> 1x1 Conv -> 2x2 AvgPooling\n","  - Dimension reduction\n","  - 채널을 줄이기 위해 1x1 convolution 적용\n","\n"]},{"cell_type":"markdown","metadata":{"id":"--fTy8ZsgkEY"},"source":["<br>\n","\n","## 5.6 Summary: Key takeaways\n","\n","- AlexNet\n","  - 최초로 Deep Learning 을 이용하여 ILSVRC에서 수상\n","- VGGNet\n","  - repeated 3x3 blocks\n","  - 3x3 Convolution 을 이용하여 Receptive field 는 유지하면서 더 깊은 네트워크 구성\n","  - [Receptive field 참고 자료](https://cs231n.github.io/convolutional-networks/#conv)\n","- GoogLeNet\n","  - 1x1 convolution\n","  - Inception blocks 을 제안\n","- ResNet\n","  - skip-connection\n","  - Residual connection(Skip connection) 이라는 구조를 제안\n","  - h(x) = f(x) + x 의 구조\n","- DenseNet\n","  - concatenation\n","  - ResNet 과 비슷한 아이디어지만 Addition 이 아닌 Concatenation을 적용한 CNN"]},{"cell_type":"code","metadata":{"id":"qUyiKrq9gy8N"},"source":[""],"execution_count":null,"outputs":[]}]}