{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06강 - Computer Vision Applications.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOIHmPBavty0bwYBT2CBDsy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"yq0OOASD_X1g"},"source":["# 6. Computer Vision Applications"]},{"cell_type":"markdown","metadata":{"id":"MALzHKrS_hiX"},"source":["## 6.1 Semantic Segmentation\n","\n","- 어떤 이미지가 있을 때 이미지를 픽셀마다 분류하는 것\n","- 이미지의 모든 픽셀이 어떤 라벨에 속하는 지 분류\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1a4mvtKuK9wtYDbSQEWRIorHFoJawr3pL' width=600/>\n","\n","<br>\n","\n","- Semantic Segmentation 는 자율주행 같은 문제에 활용된다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1IjbmzE75pEw98I75NfEXWEm2OrqIpkIn' width=600/>\n","\n","- [video](https://www.youtube.com/watch?v=ATlcEDSPWXY)"]},{"cell_type":"markdown","metadata":{"id":"WDi-4INz_ttN"},"source":["<br>\n","\n","### 6.1.1 Fully Convolutional Network (FCN)\n","\n","- This is how an ordinary CNN looks like.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1Y0mpfW33_X6nBWmkrziQcJeObKymD04K' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"gNc6BAZkAgD3"},"source":["- This is a **fully convolutional** network.\n","- fully convolutional 는 dense layer 를 없애고 싶은 것 부터 시작한다.\n","- output 을 convolution 으로 바꾸고자 한다.\n","- dense layer 를 없애는 것을 convolutionalization 이라고 한다.\n","- 이 구조는 input 과 output 만 보면 ordinary CNN 구조와 동일하다. (파라미터가 정확히 일치함)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1EbH5cCrwcW77R8PQuWs8bp51HRFXWoQx' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"4i8Jd7-zAmpU"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1jPyFASWglx3fGt65C8HbNWAnE7k-Na_S' width=800/>\n","\n","- \\# of parameters\n","  - Left: 4x4x16x10 = 2,560\n","  - **Right**: 4x4x16x10 = 2,560\n","    - 4x4x16 커널이 돌아가고 있는 것이다.\n","- This process is called **convolutionalization**."]},{"cell_type":"markdown","metadata":{"id":"zHzdC5A7fcpM"},"source":["- 왜 convolutionalization 을 하는 것일까?"]},{"cell_type":"markdown","metadata":{"id":"hhle8yyDA4cl"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1DdGzAbh-rp8TID-tNrA_tfh9X8zlYc22' width=600/>\n","\n","- Transforming fully connected layers into convolution layers enables a classification net to output a heat map.\n","\n","- fully convolutional network 가 가지는 가장 큰 특징은 input dimension 에 independent 하다는 것이다.\n","- input 이미지에 상관없이 network 가 돌아간다.\n","- output 이 커지게 되면 그것에 비례해서 뒷단의 네트워크가 커지게 된다.\n","  - convolution 이 가지는 shared parameter 의 성질 때문\n","- 그 동작이 heatmap 과 같은 효과를 갖는다.\n","  - 위 이미지에 고양이가 어딨는 지 heatmap 이 나오게 된다."]},{"cell_type":"markdown","metadata":{"id":"cvzcj7qDBGs0"},"source":["- While FCN can run with inputs of any size, the output dimensions are typically reduced by subsampling.\n","  - FCN(Fully Convolution Network)는 input size 에 상관없이 돌아갈 수 있지만 output 의 크기는 줄어들긴 한다.\n","- So we need a way to connect the coarse output to the dense pixels.\n","  - coarse(드문드문한) output을 원래의 dense pixel 로 바꿔주는 방법이 필요하다.\n","  - dimension 을 늘리는 작업이 필요한 것이다.\n","- 늘리는 방법으로서 여러 가지 방법들이 존재한다.\n","  - convolution transpose (deconvolution)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1bxucJQl_AdefZ6yivt3_X2EXjY6K7JpM' width=400/>"]},{"cell_type":"markdown","metadata":{"id":"KWioWp53BW9Q"},"source":["<br>\n","\n","### 6.1.2 Deconvolution (convolution transpose)\n","\n","- Deconvolution 은 convolution 의 역연산이다.\n","- stride 를 2로 하면 출력의 dimension 이 대략 반 정도 줄어든다. (30 -> 15)\n","- deconvolution 은 stride 2 를 주면 15x15 를 30x30 로 늘려준다.\n","- 사실 엄밀히 말하자면 convolution 의 역연산은 존재할 수 없다.\n","  - 10 은 2+8 일수도 있고, 4+6 일수도 있다.\n","- 역연산이라고 생각하면 좋은 점은 network architecture 를 만들 때 파라미터의 숫자와 network architecture 의 크기를 계산할 때 편해진다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1LxqXXg4XcrnqwFj-Waj69IhMEfcWJGAx' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"K7a_8A56inxm"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=18t1kENMCdmgisltCacB374dsI-QtjYTs' width=800/>\n","\n","- padding 없이 stride 2를 주고 convolution 을 수행하면 5x5 가 2x2 가 된다.\n","- deconvolution 역시 똑같은 조건(stride=2)을 주고 수행하면 2x2 가 5x5 가 된다.\n","  - 2x2 픽셀을 padding 을 많이 줘서 5x5 가 나오도록 한다."]},{"cell_type":"markdown","metadata":{"id":"ploo_niGBhZ-"},"source":["<br>\n","\n","### 6.1.3 Results\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1i1xpbZdDXlNtjS9DUwW8ZYsBTkU71DXg' width=600/>"]},{"cell_type":"markdown","metadata":{"id":"PnO1We8rBmR7"},"source":["<br>\n","\n","## 6.2 Object Detection\n","\n","- 이미지 안에서 물체가 어디에 있는 지 찾고자 하는 것\n","- per pixel 이 아니라 bounding box 를 찾는 것"]},{"cell_type":"markdown","metadata":{"id":"LmLpWrUzBpKm"},"source":["### 6.2.1 R-CNN\n","\n","- [paper](https://arxiv.org/pdf/1311.2524.pdf)\n","\n","- Object Detection 할 수 있는 가장 간단한 방법\n","- 이미지 안에서 수많은 패치(region)를 뽑아낸다.\n","  - 각각의 패치의 크기는 서로 다르다.\n","- 모든 패치들을 똑같은 크기로 맞춘다.\n","  - CNN이 돌아갈려면 크기가 같아야 하기 때문\n","- 각 패치에 대해 분류를 수행한다.\n","  - SVM 사용하여 분류\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1fCB0oQa0wzI4LP-KK_3tMQGGMecdr4kL' width=600/>\n","\n","- R-CNN\n","  - (1) takes an input image\n","  - (2) extracts around 2,000 region proposals (using Selective search)\n","  - (3) compute features for each proposal (using AlexNet)\n","  - (4) classifies with linear SVMs.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=10hm1IbUM9L9dbJemE1TM-Pte2Lwajj9q' width=900/>"]},{"cell_type":"markdown","metadata":{"id":"iA3GW3qTkXQo"},"source":["- R-CNN 의 가장 큰 문제는 이미지 안에서 bounding box 를 2,000개를 뽑으면 2,000개의 이미지(패치)를 전부 CNN을 통과시켜야 한다는 것이다.\n","  - CNN 을 2,000번 돌려야 하나의 이미지를 detection 할 수 있는 것이다."]},{"cell_type":"markdown","metadata":{"id":"xi0pxWaKGsk9"},"source":["<br>\n","\n","### 6.2.2 SPPNet (Spatial Pyramid Pooling Network)\n","\n","- [paper](https://arxiv.org/abs/1406.4729)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1a_LLgoN8YKPN5lxsECR0GoiBEBU9NzZp' width=600/>\n","\n","- In R-CNN, the number of crop/warp is usually over 2,000 meaning that CNN must run more than 2,000 times (59s/image on CPU)\n","- However, in SPPNet, CNN runs once.\n","\n","<br>\n","\n","- SPPNet 은 이미지 안에서 CNN 을 한 번만 돌리자는 것이다.\n","- 이미지 안에서 bounding box 를 뽑고 이미지 전체에 대해 convolutional feature map 을 만든 다음에 뽑힌 bounding box 위치에 해당하는 convolutional feature map의 tensor 만 뜯어오자는 것이다.\n","- 이로 인해 R-CNN 에 비해 빠른 속도를 나타낸다."]},{"cell_type":"markdown","metadata":{"id":"vfT_59-mGx0U"},"source":["<br>\n","\n","### 6.2.3 Fast R-CNN\n","\n","- [paper](https://arxiv.org/abs/1504.08083)\n","\n","1. Takes an input and a set of bounding boxes.\n","2. Generated convolutional feature map\n","3. For each region, get a fixed length feature from ROI pooling\n","4. Two outputs: class and bounding-box regressor.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1GHAPJ6GEcFuffUTybBBgMBraDWsz10Id' width=600/>\n","\n","- SPPNet 과 동일한 컨셉을 가져온다.\n","- input 이미지에 대해 bounding box 를 뽑는다.\n","- convolutional feature map 을 한 번 얻는다.\n","- 각각의 region 에 대해서 ROI pooling 을 통해 고정된 길이의 feature 를 뽑는다.\n","- 마지막에 Neural Network 를 통해서 bounding box regressor 와 softmax 가 출력된다.\n","  - softmax : bounding box 의 라벨을 찾는다.\n","  - bounding box regressor : bounding box 를 어떻게 이동하면 좋을 지를 찾는다."]},{"cell_type":"markdown","metadata":{"id":"Tj9XuMR9HxUl"},"source":["<br>\n","\n","### 6.2.4 Faster R-CNN\n","\n","- [paper](https://arxiv.org/abs/1506.01497)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=178flU6Gn6xKT9t6UwJU6NUbjbeltGvWW' width=600/>\n","\n","- 이미지를 통해서 bounding box 를 뽑아내는 region proposal 도 학습하자는 것으로 바꾼 것이다.\n","  - bounding box 를 뽑아내는 selective search 는 내가 풀고자하는 detection 에 맞지 않다.\n","  - 그냥 임의의 방법에 잘 동작하는 bounding box 를 뽑아내는 알고리즘이기 때문이다.\n","- Region Proposal Network 을 통해 bounding box 를 뽑아내는 region proposal 을 학습한다.\n","\n","<br>\n","\n","- Faster R-CNN = **Region Proposal Network** + Fast R-CNN\n"]},{"cell_type":"markdown","metadata":{"id":"GeI1HEiuIFkb"},"source":["<br>\n","\n","#### 6.2.4.1 Regioin Proposal Network\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1YWY8G6t1xF1EEOQ9RAj97_Qy0PGkuDFi' width=800/>\n","\n","- RPN 은 이미지가 있을 때 이미지에서 특정 영역(=패치)이 bounding box 로서의 의미가 있을 지 없을 지를 찾아주는 것이다.\n","  - 이 물체가 무엇인지는 뒷부분의 네트워크가 찾아준다.\n","- 이를 위해 필요한 것이 anchor box 이다.\n","\n","<br>\n","\n","- Anchor boxes : detection boxes with predefined sizes.\n","- Anchor boxes : 미리 정해놓은 bounding box 의 크기\n","- 이미지에 어떤 크기의 이미지들이 있을 것 같다고 미리 알고 있는 것이다.\n","- 이러한 탬플릿들을 만들어 놓고 이 탬플릿들이 얼마나 바뀔지에 대한 offset 을 찾는다.\n","- 궁극적으로는 이 탬플릿을 미리 고정해 놓는 것이 RPN 의 가장 큰 특징이 된다."]},{"cell_type":"markdown","metadata":{"id":"1Ac6nKocIZ66"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1FIgALypu6b2uuyXSaw33dUqGpaJbbhNA' width=800/>\n","\n","- Faster R-CNN 에도 FCN 이 사용된다.\n","- 3가지의 크기가 다른 region이 존재한다.\n","  - 128x128\n","  - 256x256\n","  - 512x512\n","- 또한 3개의 비율이 존재한다.\n","  - 1:1\n","  - 1:2\n","  - 2:1\n","- 이들을 조합하여 총 9개의 region size 들을 만들어 놓고 이들 중 하나를 고르게 된다.\n","\n","<br>\n","\n","- 각각의 region size 마다 bounding box 를 얼마나 키우고 줄일지에 대한 파라미터 4개를 준비한다.\n","  - 위, 아래, 좌, 우, 4방향으로 bounding box 를 이동할 수 있음\n","\n","<br>\n","\n","- 해당 bounding box 가 쓸모 있는 지 없는 지에 대한 파라미터 2개를 준비한다.\n","\n","<br>\n","\n","- 결과적으로 FCN 의 채널 숫자가 9 x (4 + 2) = 54 가 된다."]},{"cell_type":"markdown","metadata":{"id":"oBr2vCFzIciA"},"source":["<br>\n","\n","#### 6.2.4.2 Faster R-CNN Result\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=14C7FXFGoaeWL8o4yromq1PBgJVb0hJ-w' width=800/>"]},{"cell_type":"markdown","metadata":{"id":"WHFEK7M7IiUX"},"source":["<br>\n","\n","### 6.2.5 YOLO (You Only Looks One)\n","\n","- [paper](https://arxiv.org/abs/1506.02640)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1SoRphQ-Wa-Yh5yRW9QAajn878EBvRNEx' width=800/>\n","\n","- YOLO (v1) is an extremely fast object detection algorithm.\n","  - baseline: 45fps\n","  - smaller version: 155fps\n","- It **simultaneously** predicts multiple bounding boxes and class probabilities.\n","  - No explicit bounding box sampling (compared with Faster R-CNN)\n","    - bounding box 를 따로 뽑는 step 이 없다.\n","    - 이를 한 번에 하기 때문에 속도가 빠르다."]},{"cell_type":"markdown","metadata":{"id":"RWhJ7KHCI_U0"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1R1z8sa3DJyoZfvSuXwDqQBd_tLn2_pbv' width=500/>\n","\n","- Given an image, **YOLO** divides it into SxS grid.\n","  - If the center of an object falls into the grid cell, that grid cell is responsible for detection.\n","  - 이미지 안에 내가 찾고자 하는 물체의 중앙이 해당 grid 안에 들어가면 그 grid cell 이 해당 물체에 대한 bounding box 와 해당 물체가 무엇인 지를 같이 예측해준다."]},{"cell_type":"markdown","metadata":{"id":"0GvptbgQJO0z"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1UC1FiidZV4bcv-DQ6cYbg69zClSFTfNC' width=500/>\n","\n","- 먼저 bounding box 를 찾아야 한다.\n","- Each cell predicts B bounding boxes (B=5).\n","- 각각의 cell 은 B개의 bounding box 를 예측하게 된다.\n","  - Each bounding box predicts\n","    - box refinement (x / y / w / h)\n","    - confidence (of objectness)\n","  - 각각의 5개의 bounding box 의 width, heigh, x, y 를 찾게 되고 bounding box 가 쓸모 있는 지 없는 지 판단한다. (box probability)"]},{"cell_type":"markdown","metadata":{"id":"HpYPPuHlJjd7"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=12a74B0psQug8-Rz8w1h5k1ZoDESAvnq3' width=500/>\n","\n","- Each cell predicts C class probabilities.\n","- bounding box 를 찾는 **동시에** 각각의 SxS grid 가 bounding box(grid cell)에 속하는 중점에 있는 object 가 어떤 class 에 해당하는 지를 예측한다."]},{"cell_type":"markdown","metadata":{"id":"0trIeg_JJn6L"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1fZcQ77Bfv4UXSs1j0XpGEQiGkiv7Uu0q' width=500/>\n","\n","- In total, it becomes a tensor with SxSx(B*5+C) size.\n","  - SxS: Number of cells of the grid\n","  - B*5: B bounding boxes with offsets (x,y,w,h) and confidence\n","  - C: Number of classes\n","- 이 둘에 대한 정보를 취합하게 되면 box 와 이 box 가 어느 클래스에 속하는 지를 알 수 있게 된다.\n","- 이를  tensor 로 표현하게 되면 다음과 같다.\n","  - 높이와 너비는 SxS 가 된다.\n","  - 채널 방향은 B(=5)개의 bounding box 가 있다.\n","  - B개의 bounding box 마다 box 에 대한 probability 가 나온다.\n","  - 또한 동시에 C개의 class probability 가 나온다.\n","  - 최종적으로 SxSx(B*5+C) 크기의 tensor 가 만들어진다."]},{"cell_type":"markdown","metadata":{"id":"9fq8uenrJ8ST"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1DPgFFF4WbeX07cUWsLcodrTOfCD3uO0N' width=800/>\n","\n","- 명화나 영화 장면에 대해 테스트 했을 때 잘 동작하는 것을 볼 수 있다."]},{"cell_type":"code","metadata":{"id":"Glmkspa5J9CF"},"source":[""],"execution_count":null,"outputs":[]}]}