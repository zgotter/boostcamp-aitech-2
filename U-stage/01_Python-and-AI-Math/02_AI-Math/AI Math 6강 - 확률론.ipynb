{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AI Math 6강 - 확률론.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMUSt9Ve1XOilNcOJ77idCm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"2uqXSeb5jvFZ"},"source":["# 3. 확률론\n"]},{"cell_type":"markdown","metadata":{"id":"qUuzVy5LjzI6"},"source":["## 3.1 확률분포는 데이터의 초상화\n","\n","- $X \\times Y$ :  데이터 공간\n","- 확률분포\n","  - $\\mathcal{D}$\n","  - 데이터 공간에서 데이터를 추출하는 분포\n","  - $\\mathcal{D}$는 이론적으로 존재하는 확률분포이기 때문에 사전에 알 수 없다.\n","- 확률변수\n","  - 데이터는 확률변수로 $(\\mathbb{x}, y) \\sim \\mathcal{D}$ 라 표기\n","  - $(\\mathbb{x}, y) \\in X \\times Y$ ($(\\mathbb{x}, y)$ : 데이터 공간 상의 **관측 가능한 데이터**)\n","  - 확률변수는 함수로 생각할 수 있다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1402nG67ChhMZsFVxEyVMq42w7QRnAxvk' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"H_nIFfUsj1ei"},"source":["<br>\n","\n","## 3.2 이산확률변수 vs 연속확률변수\n","\n","- 확률변수는 확률분포 $\\mathcal{D}$ 에 따라 **이산형(discrete)**과 **연속형(continuous)** 확률변수로 구분하게 된다.\n","  - 확률변수는 데이터 공간 $X \\times Y$ 에 의해 결정되는 것이 아닌 확률분포 $\\mathcal{D}$ 에 의해 결정된다."]},{"cell_type":"markdown","metadata":{"id":"7u5Te5NTj4M6"},"source":["<br>\n","\n","### 3.2.1 이산형 확률변수\n","\n","- 이산형 확률변수는 **확률변수가 가질 수 있는 경우의 수**를 모두 고려하여 **확률을 더해서 모델링**한다.\n","- $P(X = \\mathbb{x})$ : 확률변수가 $\\mathbb{x}$ 값을 가질 확률 (**확률질량함수**)\n","\n","$$\n","\\mathbb{P} \\left( X \\in A \\right) = \\sum_{\\mathbb{x} \\in A} P (X = \\mathbb{x})\n","$$"]},{"cell_type":"markdown","metadata":{"id":"pkqDx7qnj7Ki"},"source":["<br>\n","\n","### 3.2.2 연속형 확률변수\n","\n","- 연속형 확률변수는 **데이터 공간에 정의된 확률변수의 밀도(density)** 위에서의 **적분을 통해 모델링**한다.\n","- $P(\\mathbb{x})$ : 누적확률분포의 변화율 (**확률밀도함수**)\n","\n","$$\n","\\mathbb{P} \\left( X \\in A \\right) = \n","\\int_A P(\\mathbb{x}) d\\mathbb{x} = \n","\\int_A \\lim_{h \\rightarrow 0} \\frac{\\mathbb{P} \\left( \\mathbb{x} - h \\leq X \\leq \\mathbb{x} + h \\right)}{2h} d\\mathbb{x}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"BWYuXuytj93q"},"source":["<br>\n","\n","## 3.3 결합분포 (joint distribution)\n","\n","- 결합분포 $P(\\mathbb{x}, y)$ 는 확률분포 $\\mathcal{D}$ 를 모델링한다.\n","- 주어진 데이터의 결합분포 $P(\\mathbb{x}, y)$를 가지고 원래 확률분포 $\\mathcal{D}$를 모델링할 수 있다.\n","  - 확률분포 $\\mathcal{D}$ 가 이산형 확률분포일 때 결합분포 $P(\\mathbb{x}, y)$는 이산형일수도, 연속형일 수도 있다.\n","  - 확률분포 $\\mathcal{D}$ 가 연속형 확률분포일 때 결합분포 $P(\\mathbb{x}, y)$는 이산형일수도, 연속형일 수도 있다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1KwrL95AZI66SeKcIBlutkFcRKW-b-tF5' width=500/>"]},{"cell_type":"markdown","metadata":{"id":"NHRl0saikAqC"},"source":["<br>\n","\n","## 3.4 주변확률분포 (marginal distribution)\n","\n","- $P(\\mathbb{x})$ 는 입력 $\\mathbb{x}$에 대한 주변확률분포이다.\n","- $P(\\mathbb{x})$ 는 $\\mathbb{y}$에 대한 정보를 주진 않는다.\n","- 주변확률분포 $P(\\mathbb{x})$는 결합분포 $P(\\mathbb{x}, y)$에서 유도 가능하다.\n","\n","$$\n","P(\\mathbb{x}) = \\sum_y P(\\mathbb{x}, \\mathbb{y}) \\qquad \n","P(\\mathbb{x}) = \\int_\\mathbb{y} P(\\mathbb{x}, \\mathbb{y}) d\\mathbb{y}\n","$$\n","\n","\n","\n","- $\\mathbb{x}$ 값에 따른 빈도수 ($y$ 상관 x)\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1ysq_PhZfMW3E66EWuo52IJytGIaAiv7M' width=400/>"]},{"cell_type":"markdown","metadata":{"id":"ilV6lKG4kDmy"},"source":["<br>\n","\n","## 3.5 조건부확률분포\n","\n","- 조건부확률분포 $P(\\mathbb{x} \\, | \\, y)$ 는 데이터 공간에서 입력 $\\mathbb{x}$와 출력 $y$ 사이의 관계를 모델링한다.\n","- $P(\\mathbb{x} \\, | \\, y)$ 는 특정 클래스가 주어진 조건에서 데이터의 확률분포를 보여준다.\n","\n","\n","\n","- $y$가 1일 때의  $\\mathbb{x}$ 값에 따른 빈도수\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1fkV8A_Nf6FtOEgh6GUHssAWuBhc8GkYR' width=400/>"]},{"cell_type":"markdown","metadata":{"id":"sqbHjS9gkGOi"},"source":["<br>\n","\n","## 3.6 조건부확률과 기계학습\n","\n","- 조건부확률 $P(y \\, | \\, \\mathbb{x})$ 는 입력변수 $\\mathbb{x}$ 에 대해 정답이 $y$ 일 확률을 의미한다.\n","  - 연속확률분포의 경우 $P(y \\, | \\, \\mathbb{x})$ 는 확률이 아니도 밀도로 해석한다."]},{"cell_type":"markdown","metadata":{"id":"I7qf_P7okI1r"},"source":["<br>\n","\n","### 3.6.1 로지스틱 회귀\n","\n","- 로지스틱 회귀에서 사용했던 선형 모델과 소프트맥스 함수의 결합은 **데이터에서 추출된 패턴을 기반으로 확률을 해석**하는 데 사용된다."]},{"cell_type":"markdown","metadata":{"id":"ItPvAODXkPo7"},"source":["<br>\n","\n","### 3.6.2 분류 문제\n","\n","- 분류 문제에서 $\\text{softmax}(W \\phi + \\mathbb{b})$ 은 데이터 $\\mathbb{x}$ 로부터 추출된 특징패턴 $\\phi (\\mathbb{x})$ 과 가중치 행렬 $W$ 을 통해 **조건부 확률** $P(y \\, | \\, \\mathbb{x})$ 을 계산한다.\n","  - $P(y \\, | \\, \\phi (\\mathbb{x}))$ 이라 써도 된다."]},{"cell_type":"markdown","metadata":{"id":"DaPuFu3pkRrq"},"source":["<br>\n","\n","### 3.6.3 회귀 문제\n","\n","- 회귀 문제의 경우 **조건부기대값** $\\mathbb{E} [y \\,|\\, \\mathbb{x}]$ 을 추정한다.\n","\n","$$\n","\\mathbb{E} [y \\,|\\, \\mathbb{x}] = \\mathbb{E}_{y \\sim P(y \\,|\\, \\mathbb{x})} [y \\,|\\, \\mathbb{x}] = \\int_y y P(y \\,|\\, \\mathbb{x}) dy\n","$$\n","\n","- 조건부기대값은 $\\mathbb{E} || y - f(\\mathbb{x}) ||_2$ ($L_2$ 노름)을 최소화하는 함수 $f(\\mathbb{x})$ 와 일치한다.\n","  - 그렇기 때문에 회귀 문제에서 조건부확률 대신 조건부기대값을 사용한다."]},{"cell_type":"markdown","metadata":{"id":"55QYVj4WkUAq"},"source":["<br>\n","\n","### 3.6.4 딥러닝\n","\n","- 딥러닝은 다층신경망(MLP, Multi Layer Perceptron)을 사용하여 특징패턴 $\\phi$ 을 추출한다.\n","- 특징패턴을 학습하기 위해 어떤 손실함수를 사용할 지는 기계학습 문제와 모델에 의해 결정된다."]},{"cell_type":"markdown","metadata":{"id":"HuXank12kXBy"},"source":["<br>\n","\n","## 3.7 기대값 이란?\n","\n","- 확률분포가 주어지면 데이터를 분석하는 데 사용 가능한 여러 종류의 **통계적 범함수(statistical functional)를 계산**할 수 있다.\n","- **기대값(expectation)**\n","  - 데이터를 대표하는 통계량\n","  - 대표적인 통계적 범함수 중 하나\n","  - 확률분포를 통해 다른 통계적 범함수를 계산하는 데 사용"]},{"cell_type":"markdown","metadata":{"id":"b7yFeU2RkeBS"},"source":["<br>\n","\n","### 3.7.1 **이산확률분포**의 기대값\n","\n","- **급수** 사용\n","- 각 함수에 **확률질량함수**를 곱해준다.\n","\n","$$\n","\\mathbb{E}_{\\mathbb{x} \\sim P(\\mathbb{x})} [f(\\mathbb{x})] = \n","\\sum_{\\mathbb{x} \\in \\mathcal{X}} f(\\mathbb{x}) P(\\mathbb{x})\n","$$"]},{"cell_type":"markdown","metadata":{"id":"YW5IY2IQkkfq"},"source":["<br>\n","\n","### 3.7.2 **연속확률분포**의 기대값\n","\n","- **적분** 사용\n","- 각 함수에 **확률밀도함수**를 곱해준다.\n","\n","$$\n","\\mathbb{E}_{\\mathbb{x} \\sim P(\\mathbb{x})} [f(\\mathbb{x})] = \n","\\int_{\\mathcal{X}} f(\\mathbb{x}) P(\\mathbb{x}) d \\mathbb{x}\n","$$"]},{"cell_type":"markdown","metadata":{"id":"VieVNk3kkp-k"},"source":["<br>\n","\n","### 3.7.3 기대값의 활용\n","\n","- 기대값을 이용해 분산, 첨도, 공분산 등 여러 통계량을 계산할 수 있다."]},{"cell_type":"markdown","metadata":{"id":"_Bsg6p77k0Nk"},"source":["- 분산\n","\n","$$\n","\\mathbb{V}(\\mathbb{x}) = \\mathbb{E}_{\\mathbb{x} \\sim P(\\mathbb{x})} \\left[\\left( \\mathbb{x} - \\mathbb{E}[\\mathbb{x}]\\right)^2 \\right]\n","$$\n","\n","$$\n","\\mathbb{V}(\\mathbb{x}) = \\mathbb{E} \\left[ \\mathbb{x}^2 \\right] - \\left(\\mathbb{E} \\left[ \\mathbb{x} \\right]\\right)^2\n","$$\n","\n","- 첨도\n","\n","$$\n","\\text{Skewness}(\\mathbb{x}) = \\mathbb{E} \\left[ \\left( \\frac{\\mathbb{x} - \\mathbb{E}[\\mathbb{x}]}{\\sqrt{\\mathbb{V}(\\mathbb{x})}} \\right)^3 \\right]\n","$$\n","\n","\n","- 공분산\n","  \n","$$\n","\\text{Cov} \\left( \\mathbb{x}_1, \\, \\mathbb{x}_2 \\right) = \\mathbb{E}_{\\mathbb{x}_1,\\mathbb{x}_2 \\sim P(\\mathbb{x}_1, \\mathbb{x}_2)} \\left[ \\left( \\mathbb{x}_1 - \\mathbb{E}[\\mathbb{x_1}] \\right) \\left( \\mathbb{x}_2 - \\mathbb{E}[\\mathbb{x_2}] \\right) \\right]\n","$$"]},{"cell_type":"markdown","metadata":{"id":"D7CnZADBlDCk"},"source":["<br>\n","\n","## 3.8 몬테카를로 샘플링\n","\n","- https://www.deeplearningbook.org/contents/monte_carlo.html\n","- 기계학습의 많은 문제들은 **확률분포를 명시적으로 모를 때**가 대부분이다.\n","- 확률분포를 모를 때 **데이터를 이용하여 기대값을 계산**하려면 **몬테카를로(Monte Carlo) 샘플링 방법을 사용**해야 한다.\n","- 몬테카를로는 이산형이든 연속형이든 상관없이 성립한다.\n","- 확률분포에서 독립적($i.i.d.$)으로 샘플링해야 한다.\n","\n","$$\n","\\mathbb{E}_{\\mathbb{x} \\sim P(\\mathbb{x})} [f(\\mathbb{x})] \\approx\n","\\frac{1}{N} \\sum_{i=1}^N f(\\mathbb{x}^{(i)}), \\qquad \\mathbb{x}^{(i)} \\overset{i.i.d.}{\\sim} P(\\mathbb{x})\n","$$\n","\n","- 몬테카를로 샘플링은 독립추출만 보장된다면 **대수의 법칙(law of large number)에 의해 수렴성을 보장**한다.\n","- 몬테카를로 샘플링은 기계학습에서 매우 다양하게 응용되는 방법이다."]},{"cell_type":"markdown","metadata":{"id":"ezWvuM4vlLOb"},"source":["<br>\n","\n","### 3.8.1 몬테카를로 예제 : 적분 계산하기\n","\n","- 함수 $f(x) = e^{-x^2}$ 의 $[-1,1]$ 상에서 적분값을 어떻게 구할까?\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1an8X0V4a6N5_7uGEoHafYzmrQlywCtF_' width=600/>\n","\n","- $f(x)$ 의 적분을 해석적으로 구하는 것은 불가능하다.\n","- 구간 $[-1,1]$ 에서 균등분포를 통해 데이터를 샘플링한다.\n","\n","- 구간 $[-1,1]$ 의 길이는 2이므로 적분값을 2로 나누면 기대값을 계산하는 것과 같으므로 몬테카를로 방법을 사용할 수 있다.\n","\n","$$\n","\\frac{1}{2} \\int_{-1}^{1} e^{-x^2} dx \\approx \n","\\frac{1}{N} \\sum_{i=1}^N f(\\mathbb{x}^{(i)}), \\qquad \\mathbb{x}^{(i)} \\sim U(-1,1)\n","$$\n","\n","$$\n","\\int_{-1}^{1} e^{-x^2} dx \\approx \n","\\frac{2}{N} \\sum_{i=1}^N f(\\mathbb{x}^{(i)}), \\qquad \\mathbb{x}^{(i)} \\sim U(-1,1)\n","$$\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xhGPhhhnmm3-","executionInfo":{"status":"ok","timestamp":1627920189944,"user_tz":-540,"elapsed":550,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"9fc2690d-e44c-4b92-b13d-b7d8ed3db84b"},"source":["import numpy as np\n","\n","def mc_int(fun, low, high, sample_size=100, repeat=10):\n","    int_len = np.abs(high - low)\n","    stat = []\n","    for _ in range(repeat):\n","        x = np.random.uniform(low=low, high=high, size=sample_size) # 균등분포에서 데이터를 샘플링\n","        fun_x = fun(x) # 함수 f(x) 에 값 대입\n","        int_val = int_len * np.mean(fun_x) # 함수값의 산술평균 x 구간의 길이(2)\n","        stat.append(int_val)\n","    return np.mean(stat), np.std(stat)\n","        \n","def f_x(x):\n","    return np.exp(-x**2)\n","\n","print(mc_int(f_x, low=-1, high=1, sample_size=10000, repeat=100))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1.4940291696335617, 0.003965164205933249)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Om2lLDIqmnRS"},"source":["- $1.49399 \\, \\pm \\, 0.00401$ 이므로 오차 범위 안에 참값이 있다.\n","- 샘플 수가 적을 경우 몬테카를로 방법을 사용해도 오차 범위가 커질 수 있다."]},{"cell_type":"markdown","metadata":{"id":"JyFxiOl3lQ_a"},"source":["<br>\n","\n","### 3.8.2 몬테카를로 예제 : 원주율에 대한 근사값\n","\n","몬테카를로 방법을 활용하여 원주율에 대한 근사값을 어떻게 구할 수 있을까?\n","\n","- 원의 면적을 알면 $S = \\pi r^2$ 에 의해 원주율을 알 수 있다.\n","- 무작위하게 수를 발생시켜 그것을 좌표로 점을 찍고, 점이 원의 영역에 포함되었는 지의 여부를 판단한다.\n","- 이것을 반복하여 원에 포함된 점과 그렇지 않은 점의 수를 센다.\n","- 두 수의 비율을 통해 원의 면적을 구한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=11MwWwQEbvTAMGQJVJEMbYdjqrVxB6JwZ' width=300/>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1rCmVHYlVAS","executionInfo":{"status":"ok","timestamp":1627920170429,"user_tz":-540,"elapsed":12,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"5476a48a-fe2f-4225-93b2-cf85f0f1dfe7"},"source":["import random\n"," \n","n = 1000\n","count = 0\n","for i in range(n):\n","    x, y = random.random(), random.random() # 0 ~ 1 사이의 난수\n","    if (x**2 + y**2 < 1):\n","        count += 1\n"," \n","a = 4*count/n # count/n 이 원의 1/4 에 해당하는 값이므로 4를 곱해준다.\n","print(a)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["3.132\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u2ZCIKOOmkIM"},"source":[""],"execution_count":null,"outputs":[]}]}