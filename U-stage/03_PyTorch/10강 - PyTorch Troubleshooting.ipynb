{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10강 - PyTorch Troubleshooting.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMkW36RmFa2kXOtTfSmuniB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4VkKVSlfrIEt"},"source":["# 10. PyTorch Troubleshooting\n","\n","> PyTorch를 사용하면서 자주 발생할 수 있는 GPU에서의 Out Of Memory (OOM) 에러 상황들의 예시를 보고 해결하는 법까지 학습합니다. 프로그래밍 도중 디버깅하기 어려운 GPU 사용시 발생할 수 있는 문제들이 발생할 때 GPU 메모리 디버깅을 도와주는 툴과 초보자가 쉽게 놓칠 수 있는 사소한 실수들의 예제들을 확인합니다."]},{"cell_type":"markdown","metadata":{"id":"quXnoLokrS6d"},"source":["<br>\n","\n","## Reference\n","\n","- [PyTorch에서 자주 발생하는 에러 질문들](https://pytorch.org/docs/stable/notes/faq.html)\n","- [OOM시에 GPU 메모리 flush하기](https://discuss.pytorch.org/t/how-to-clean-gpu-memory-after-a-runtimeerror/28781)\n","- [GPU 에러 정리](https://brstar96.github.io/shoveling/device_error_summary/)"]},{"cell_type":"markdown","metadata":{"id":"tsO5E9MLrZlV"},"source":["<br>\n","\n","## 10.1 OOM (Out Of Memory)\n","\n","- 공포의 단어 OOM"]},{"cell_type":"markdown","metadata":{"id":"Aa20Qdq6roCc"},"source":["<br>\n","\n","### 10.1.1 OOM이 해결하기 어려운 이유들\n","\n","- 왜 발생했는지 알기 어려움\n","- 어디서 발생했는지 알기 어려움\n","- Error backtracking 이 이상한데로 감\n","- 메모리의 이전상황의 파악이 어려움"]},{"cell_type":"markdown","metadata":{"id":"I3ltcpJ1rx1o"},"source":["<br>\n","\n","## 10.2 OOM 처리 방안\n","\n","- Batch Szie 줄이기 -> GPU Clean -> Run"]},{"cell_type":"markdown","metadata":{"id":"erIH_MFrr51s"},"source":["<br>\n","\n","### 10.2.1 `GPUtil` 사용하기\n","\n","- nvidia-smi 처럼 GPU의 상태를 보여주는 모듈\n","- Colab은 환경에서 GPU 상태 보여주기 편함\n","- iter마다 메모리가 늘어나는지 확인!!"]},{"cell_type":"markdown","metadata":{"id":"_xmvrQFMsBAV"},"source":["```python\n","!pip install GPUtil\n","```\n","\n","```python\n","import GPUtil\n","GPUtil.showUtilization()\n","```"]},{"cell_type":"markdown","metadata":{"id":"tseGiGgxsDCn"},"source":["&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1egHZaTfGBeRYvxfm7x9QCJ2CCVzAxwGn' width=300/>"]},{"cell_type":"markdown","metadata":{"id":"-FzpqeUOsnDO"},"source":["<br>\n","\n","### 10.2.2 `torch.cuda.empty_cache()`\n","\n","- 사용되지 않은 GPU상 cache를 정리\n","- 가용 메모리를 확보\n","- `del` 과는 구분이 필요\n","- `reset` 대신 쓰기 좋은 함수\n","- loop 시작되기 전에 사용하는 것을 권장"]},{"cell_type":"markdown","metadata":{"id":"q283beR-st8f"},"source":["```python\n","import torch\n","from GPUtil import showUtilization as gpu_usage\n","\n","print(\"Initial GPU Usage\")\n","gpu_usage()\n","\n","tensorList = []\n","for x in range(10):\n","    tensorList.append(torch.randn(10000000,10).cuda())\n","\n","print(\"GPU Usage after allcoating a bunch of Tensors\")\n","gpu_usage()\n","\n","del tensorList\n","\n","print(\"GPU Usage after deleting the Tensors\")\n","gpu_usage()\n","\n","print(\"GPU Usage after emptying the cache\")\n","torch.cuda.empty_cache()\n","gpu_usage()\n","```\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=1EJdEud2BKI8lFOIdobdBJNpjINnXbxx3' width=400/>\n","\n","- 출처: https://blog.paperspace.com/pytorch-memory-multi-gpu-debugging/"]},{"cell_type":"markdown","metadata":{"id":"KaADq_j5s3v8"},"source":["<br>\n","\n","### 10.2.3 trainning loop에 tensor로 축적 되는 변수는 확인\n","\n","- tensor로 처리된 변수는 GPU 상에 메모리 사용\n","- 해당 변수 loop 안에 연산에 있을 때 GPU에 computational graph를 생성(메모리 잠식)\n","\n","```python\n","total_loss = 0\n","for i in range(10000):\n","    optimizer.zero_grad()\n","    output = model(input)\n","    loss = criterion(output) # loss 가 쌓임\n","    loss.backward()\n","    optimizer.step()\n","    total_loss += loss\n","```"]},{"cell_type":"markdown","metadata":{"id":"buUTkjFStKjM"},"source":["- 1-d tensor의 경우 python 기본 객체로 변환하여 처리할 것\n","\n","```python\n","total_loss = 0\n","for x in range(10):\n","    # assume loss is computed\n","    iter_loss = torch.randn(3,4).mean()\n","    iter_loss.requires_grad = True\n","    #total_loss += iter_loss\n","    total_loss += iter_loss.item() # .item() 을 붙이면 python 기본 객체로 반환된다.\n","```\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=18vXP_NunA5iEoveU0Js1UTfLQA0SytzF' width=500/>\n","\n","- 출처: https://blog.paperspace.com/pytorch-memory-multi-gpu-debugging/"]},{"cell_type":"markdown","metadata":{"id":"-prk4n7WtdLM"},"source":["<br>\n","\n","### 10.2.4 `del` 명령어를 적절히 사용\n","\n","- 필요가 없어진 변수는 적절한 삭제가 필요함\n","- python의 메모리 배치 특성상 loop 이 끝나도 메모리를 차지함\n","\n","```python\n","for x in range(10):\n","    i = x\n","print(i) # 9 is printed\n","```\n","\n","```python\n","for i in range(5):\n","    intermediate = f(input[i])\n","    result += g(intermediate)\n","    del intermediate # 다 사용한 변수 삭제\n","output = h(result)\n","return output\n","```"]},{"cell_type":"markdown","metadata":{"id":"5MrFMeX8tpms"},"source":["<br>\n","\n","### 10.2.5 가능 batch 사이즈 실험\n","\n","- 학습시 OOM 이 발생했다면 batch 사이즈를 1로 해서 실험해보기\n","\n","```python\n","oom = False\n","try:\n","    run_model(batch_size)\n","except RuntimeError: # Out of memory\n","    oom = True\n","\n","if oom:\n","    for _ in range(batch_size):\n","        run_model(1)\n","```"]},{"cell_type":"markdown","metadata":{"id":"_Id1uWM9uIYH"},"source":["<br>\n","\n","### 10.2.6 `torch.no_grad()` 사용\n","\n","- Inference 시점에서는 `torch.no_grad()` 구문을 사용\n","- backward pass 으로 인해 쌓이는 메모리에서 자유로움\n","\n","```python\n","with torch.no_grad():\n","    for data, target in test_loader:\n","        output = network(data)\n","        test_loss += F.nll_loss(output, target, size_average=False).item()\n","        pred = output.data.max(1, keepdim=True)[1]\n","        correct += pred.eq(target.data.view_as(pred)).sum()\n","```"]},{"cell_type":"markdown","metadata":{"id":"mQ1Y0J5FuZrE"},"source":["<br>\n","\n","## 10.3 예상치 못한 에러 메세지\n","\n","- OOM 말고도 유사한 에러들이 발생\n","  - CUDNN_STATUS_NOT_INIT\n","    - GPU 를 제대로 설치하지 않았을 때 발생하는 오류\n","  - device-side-assert\n","    - OOM 의 일종\n","- 해당 에러도 cuda와 관련하여 OOM의 일종으로 생각될 수 있으며, 적절한 코드 처리의 필요함\n","- 참고: [이유를 알 수 없는 GPU 에러 정리(device-side assert, CUDA error, CUDNN_STATUS_NOT_INITIALIZED 등등…)](https://brstar96.github.io/shoveling/device_error_summary/)"]},{"cell_type":"markdown","metadata":{"id":"k7Sk1ipquhJc"},"source":["<br>\n","\n","## 10.4 기타 주의사항\n","\n","- colab에서 너무 큰 사이즈는 실행하지 말 것\n","  - linear, CNN, <font color='red'>LSTM</font>\n","- CNN의 대부분의 에러는 크기가 안 맞아서 생기는 경우\n","  - `torchsummary` 등으로 사이즈를 맞출 것\n","- tensor 의 float precision 을 16bit 로 줄일 수도 있음"]},{"cell_type":"code","metadata":{"id":"o8SsccQIux0x"},"source":[""],"execution_count":null,"outputs":[]}]}