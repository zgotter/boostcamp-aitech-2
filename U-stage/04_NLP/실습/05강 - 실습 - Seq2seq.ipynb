{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05강 - 실습 - Seq2seq.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOj305p2aKf4Ib57WMsu5K7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"k_jaVHBDhXHE"},"source":["# 5. 실습: Seq2seq\n","\n","1. Encoder 를 구현한다.\n","2. Decoder 를 구현한다.\n","3. Seq2seq 모델을 구축하고 사용한다."]},{"cell_type":"markdown","metadata":{"id":"_ytGllsIjLC0"},"source":["<br>\n","\n","## 5.1 필요 패키지 import"]},{"cell_type":"code","metadata":{"id":"utDs1gkdjbRL"},"source":["from tqdm import tqdm\n","from torch import nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","import torch\n","import random\n","from pprint import pprint"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23cc6-zBjc2l"},"source":["<br>\n","\n","## 5.2 데이터 전처리\n","\n","- `src_data` 를 `trg_data` 로 바꾸는 task 를 수행하기 위한 sample data 이다.\n","- 전체 단어 수는 100개이고 다음과 같이 pad token, start token, end token 의 id 도 정의한다."]},{"cell_type":"code","metadata":{"id":"OfXeDAxjjtdT"},"source":["vocab_size = 100\n","pad_id = 0\n","sos_id = 1\n","eos_id = 2\n","\n","src_data = [\n","  [3, 77, 56, 26, 3, 55, 12, 36, 31],\n","  [58, 20, 65, 46, 26, 10, 76, 44],\n","  [58, 17, 8],\n","  [59],\n","  [29, 3, 52, 74, 73, 51, 39, 75, 19],\n","  [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93],\n","  [39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99, 5],\n","  [75, 34, 17, 3, 86, 88],\n","  [63, 39, 5, 35, 67, 56, 68, 89, 55, 66],\n","  [12, 40, 69, 39, 49]\n","]\n","\n","trg_data = [\n","  [75, 13, 22, 77, 89, 21, 13, 86, 95],\n","  [79, 14, 91, 41, 32, 79, 88, 34, 8, 68, 32, 77, 58, 7, 9, 87],\n","  [85, 8, 50, 30],\n","  [47, 30],\n","  [8, 85, 87, 77, 47, 21, 23, 98, 83, 4, 47, 97, 40, 43, 70, 8, 65, 71, 69, 88],\n","  [32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18],\n","  [37, 14, 49, 24, 93, 37, 54, 51, 39, 84],\n","  [16, 98, 68, 57, 55, 46, 66, 85, 18],\n","  [20, 70, 14, 6, 58, 90, 30, 17, 91, 18, 90],\n","  [37, 93, 98, 13, 45, 28, 89, 72, 70]\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_jYnpiBhjyEc"},"source":["<br>\n","\n","- 각각의 데이터를 전처리한다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vuc_ViY_j1Az","executionInfo":{"status":"ok","timestamp":1631107181856,"user_tz":-540,"elapsed":4,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"92f2ca80-71ee-4108-fa4b-47d8fcd8bb9c"},"source":["trg_data = [[sos_id] + seq + [eos_id] for seq in tqdm(trg_data)]\n","\n","for t in trg_data:\n","    print(t)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 14706.54it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","[1, 75, 13, 22, 77, 89, 21, 13, 86, 95, 2]\n","[1, 79, 14, 91, 41, 32, 79, 88, 34, 8, 68, 32, 77, 58, 7, 9, 87, 2]\n","[1, 85, 8, 50, 30, 2]\n","[1, 47, 30, 2]\n","[1, 8, 85, 87, 77, 47, 21, 23, 98, 83, 4, 47, 97, 40, 43, 70, 8, 65, 71, 69, 88, 2]\n","[1, 32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18, 2]\n","[1, 37, 14, 49, 24, 93, 37, 54, 51, 39, 84, 2]\n","[1, 16, 98, 68, 57, 55, 46, 66, 85, 18, 2]\n","[1, 20, 70, 14, 6, 58, 90, 30, 17, 91, 18, 90, 2]\n","[1, 37, 93, 98, 13, 45, 28, 89, 72, 70, 2]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"AHFqtZjXj6yj"},"source":["def padding(data, is_src=True):\n","    max_len = len(max(data, key=len))\n","    print(f\"Maximum sequence length: {max_len}\")\n","\n","    valid_lens = []\n","    for i, seq in enumerate(tqdm(data)):\n","        valid_lens.append(len(seq))\n","        if len(seq) < max_len:\n","            data[i] = seq + [pad_id] * (max_len - len(seq))\n","\n","    return data, valid_lens, max_len"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qX3UEDj6mli2","executionInfo":{"status":"ok","timestamp":1631107863682,"user_tz":-540,"elapsed":9,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"d0867c9e-18d8-4ff8-8498-17982138853b"},"source":["src_data, src_lens, src_max_len = padding(src_data)\n","trg_data, trg_lens, trg_max_len = padding(trg_data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum sequence length: 15\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 16339.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Maximum sequence length: 22\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 72691.58it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5umGbeiCmrNz","executionInfo":{"status":"ok","timestamp":1631107938677,"user_tz":-540,"elapsed":490,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"65904138-98c8-43f0-cf13-dd2d600ee4e7"},"source":["# B: batch size, S_L: source maximum sequence length, T_L: target maximum sequence length\n","src_batch = torch.LongTensor(src_data)  # (B, S_L)\n","src_batch_lens = torch.LongTensor(src_lens)  # (B)\n","trg_batch = torch.LongTensor(trg_data)  # (B, T_L)\n","trg_batch_lens = torch.LongTensor(trg_lens)  # (B)\n","\n","print(src_batch.shape)\n","print(src_batch_lens.shape)\n","print(trg_batch.shape)\n","print(trg_batch_lens.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10, 15])\n","torch.Size([10])\n","torch.Size([10, 22])\n","torch.Size([10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"j4FfaL9lm_SD"},"source":["<br>\n","\n","- PackedSquence를 사용을 위해 source data를 기준으로 정렬합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"muGTv7TonE3T","executionInfo":{"status":"ok","timestamp":1631108095009,"user_tz":-540,"elapsed":1013,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"efc6b304-4df5-4b70-ce19-eb171a7e03bb"},"source":["src_batch_lens, sorted_idx = src_batch_lens.sort(descending=True)\n","src_batch = src_batch[sorted_idx]\n","trg_batch = trg_batch[sorted_idx]\n","trg_batch_lens = trg_batch_lens[sorted_idx]\n","\n","print(src_batch)\n","print(src_batch_lens)\n","print(trg_batch)\n","print(trg_batch_lens)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99,  5],\n","        [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93,  0,  0,  0,  0],\n","        [63, 39,  5, 35, 67, 56, 68, 89, 55, 66,  0,  0,  0,  0,  0],\n","        [ 3, 77, 56, 26,  3, 55, 12, 36, 31,  0,  0,  0,  0,  0,  0],\n","        [29,  3, 52, 74, 73, 51, 39, 75, 19,  0,  0,  0,  0,  0,  0],\n","        [58, 20, 65, 46, 26, 10, 76, 44,  0,  0,  0,  0,  0,  0,  0],\n","        [75, 34, 17,  3, 86, 88,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [12, 40, 69, 39, 49,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [58, 17,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n","tensor([15, 11, 10,  9,  9,  8,  6,  5,  3,  1])\n","tensor([[ 1, 37, 14, 49, 24, 93, 37, 54, 51, 39, 84,  2,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18,  2,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 20, 70, 14,  6, 58, 90, 30, 17, 91, 18, 90,  2,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 75, 13, 22, 77, 89, 21, 13, 86, 95,  2,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1,  8, 85, 87, 77, 47, 21, 23, 98, 83,  4, 47, 97, 40, 43, 70,  8, 65,\n","         71, 69, 88,  2],\n","        [ 1, 79, 14, 91, 41, 32, 79, 88, 34,  8, 68, 32, 77, 58,  7,  9, 87,  2,\n","          0,  0,  0,  0],\n","        [ 1, 16, 98, 68, 57, 55, 46, 66, 85, 18,  2,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 37, 93, 98, 13, 45, 28, 89, 72, 70,  2,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 85,  8, 50, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 47, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0]])\n","tensor([12, 14, 13, 11, 22, 18, 11, 11,  6,  4])\n"]}]},{"cell_type":"markdown","metadata":{"id":"QGw_ADJRnSeW"},"source":["<br>\n","\n","## 5.3 Encoder 구현"]},{"cell_type":"code","metadata":{"id":"nZsxLx8VoIkx"},"source":["embedding_size = 256\n","hidden_size = 512\n","num_layers = 2\n","num_dirs = 2\n","dropout = 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A26lGzstodi2"},"source":["<br>\n","\n","- Bidirectional GRU를 이용한 Encoder입니다.\n","  - `self.embedding`: word embedding layer.\n","  - `self.gru`: encoder 역할을 하는 Bi-GRU.\n","  - `self.linear`: 양/단방향 concat된 hidden state를 decoder의 hidden size에 맞게 linear transformation.\n"]},{"cell_type":"code","metadata":{"id":"tJ2dC1baojob"},"source":["class Encoder(nn.Module):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_size)\n","        self.gru = nn.GRU(\n","            input_size=embedding_size,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            bidirectional=True if num_dirs > 1 else False,\n","            dropout=dropout\n","        )\n","        self.linear = nn.Linear(num_dirs * hidden_size, hidden_size)\n","\n","    def forward(self, batch, batch_lens): # batch: (B, S_L), batch_lens: (B)\n","        # d_w: word embedding size\n","        batch_emb = self.embedding(batch) # (B, S_L, d_w)\n","        batch_emb = batch_emb.transpose(0, 1) # (S_L, B, d_w)\n","\n","        packed_input = pack_padded_sequence(batch_emb, batch_lens)\n","\n","        h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size)) # (num_layers*num_dirs, B, d_h) = (4, B, d_h)\n","        packed_outputs, h_n = self.gru(packed_input, h_0) # h_n: (4, B, d_h)\n","        outputs = pad_packed_sequence(packed_outputs)[0] # outputs: (S_L, B, 2d_h)\n","\n","        forward_hidden = h_n[-2, :, :]\n","        backward_hidden = h_n[-1, :, :]  \n","        hidden = self.linear(torch.cat((forward_hidden, backward_hidden), dim=-1)).unsqueeze(0) # (1, B, d_h)\n","\n","        return outputs, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-89zmj5Hq-tu"},"source":["encoder = Encoder()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DkUfNYVdrBZ-"},"source":["<br>\n","\n","## 5.4 Decoder 구현\n","\n","- 동일한 설정의 Bi-GRU로 만든 Decoder입니다.\n","  - `self.embedding`: word embedding layer.\n","  - `self.gru`: decoder 역할을 하는 Bi-GRU.\n","  - `self.output_layer`: decoder에서 나온 hidden state를 `vocab_size`로 linear transformation하는 layer."]},{"cell_type":"code","metadata":{"id":"nl6pVM-5uHTM"},"source":["class Decoder(nn.Module):\n","  def __init__(self):\n","    super(Decoder, self).__init__()\n","\n","    self.embedding = nn.Embedding(vocab_size, embedding_size)\n","    self.gru = nn.GRU(\n","        input_size=embedding_size, \n","        hidden_size=hidden_size,\n","    )\n","    self.output_layer = nn.Linear(hidden_size, vocab_size)\n","\n","  def forward(self, batch, hidden):  # batch: (B), hidden: (1, B, d_h)\n","    batch_emb = self.embedding(batch)  # (B, d_w)\n","    batch_emb = batch_emb.unsqueeze(0)  # (1, B, d_w)\n","\n","    outputs, hidden = self.gru(batch_emb, hidden)  # outputs: (1, B, d_h), hidden: (1, B, d_h)\n","    \n","    # V: vocab size\n","    outputs = self.output_layer(outputs)  # (1, B, V)\n","\n","    return outputs.squeeze(0), hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzdA7hatuNkp"},"source":["decoder = Decoder()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GM6hz1qLuPB9"},"source":["<br>\n","\n","## 5.5 Seq2seq 모델 구축\n","\n","- 생성한 encoder와 decoder를 합쳐 Seq2seq 모델을 구축합니다.\n","  - `self.encoder`: encoder.\n","  - `self.decoder`: decoder."]},{"cell_type":"code","metadata":{"id":"LV7PkBEsudK9"},"source":["class Seq2seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Seq2seq, self).__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src_batch, src_batch_lens, trg_batch, teacher_forcing_prob=0.5):\n","        # src_batch: (B, S_L)\n","        # src_batch_lens: (B)\n","        # trg_batch: (B, T_L)\n","\n","        _, hidden = self.encoder(src_batch, src_batch_lens) # hidden: (1, B, d_h)\n","\n","        input_ids = trg_batch[:, 0] # (B)\n","        batch_size = src_batch.shape[0]\n","        outputs = torch.zeros(trg_max_len, batch_size, vocab_size) # (T_L, B, V)\n","\n","        for t in range(1, trg_max_len):\n","            decoder_outputs, hidden = self.decoder(input_ids, hidden) # decoder_outputs: (B, V), hidden: (1, B, d_h)\n","\n","            outputs[t] = decoder_outputs\n","            _, top_ids = torch.max(decoder_outputs, dim=-1) # top_ids: (B)\n","\n","            input_ids = trg_batch[:, t] if random.random() > teacher_forcing_prob else top_ids\n","\n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CI7gQvswNk1"},"source":["seq2seq = Seq2seq(encoder, decoder)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yy2BZe0twPbT"},"source":["<br>\n","\n","## 5.6 모델 사용해보기\n","\n","- 학습 과정이라고 가정하고 모델에 input을 넣어봅니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDQMKS2NwVbD","executionInfo":{"status":"ok","timestamp":1631110499493,"user_tz":-540,"elapsed":622,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"e6db0888-73f6-4a95-9dc7-29971a558ce1"},"source":["outputs = seq2seq(src_batch, src_batch_lens, trg_batch)\n","\n","print(outputs)\n","print(outputs.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[ 0.2533, -0.1049, -0.0585,  ..., -0.0565,  0.1070, -0.0453],\n","         [ 0.2580, -0.1068, -0.0577,  ...,  0.0177,  0.1002, -0.0476],\n","         [ 0.2205, -0.1333, -0.0125,  ...,  0.0085,  0.0785, -0.0423],\n","         ...,\n","         [ 0.1932, -0.1302, -0.0284,  ...,  0.0264,  0.0803, -0.0160],\n","         [ 0.2197, -0.1176, -0.0521,  ...,  0.0193,  0.0980, -0.0733],\n","         [ 0.2213, -0.1205, -0.0525,  ...,  0.0288,  0.1000, -0.0395]],\n","\n","        [[ 0.1053,  0.0687, -0.0634,  ...,  0.0505, -0.0122,  0.1181],\n","         [ 0.0684,  0.0842, -0.0570,  ..., -0.0730,  0.1683, -0.0242],\n","         [ 0.1570, -0.1907,  0.0517,  ...,  0.0817, -0.0596, -0.1490],\n","         ...,\n","         [ 0.0770,  0.0455, -0.0506,  ...,  0.0904, -0.0288,  0.1310],\n","         [ 0.2327, -0.1220,  0.0281,  ..., -0.0750,  0.0338,  0.0305],\n","         [ 0.0552, -0.1648,  0.0352,  ...,  0.0835,  0.0171,  0.1351]],\n","\n","        ...,\n","\n","        [[-0.0750, -0.2232, -0.1743,  ...,  0.3806, -0.0131,  0.1312],\n","         [-0.1523, -0.1630,  0.0203,  ...,  0.2757,  0.0127,  0.1636],\n","         [-0.1003, -0.2098, -0.1703,  ...,  0.4040, -0.0296,  0.1617],\n","         ...,\n","         [-0.0635, -0.2073, -0.1690,  ...,  0.3978, -0.0164,  0.1391],\n","         [-0.1541, -0.1755,  0.0075,  ...,  0.2903,  0.0166,  0.1445],\n","         [-0.1531, -0.1755,  0.0075,  ...,  0.2897,  0.0161,  0.1448]],\n","\n","        [[-0.1500, -0.0292,  0.1350,  ...,  0.1089,  0.0338,  0.1233],\n","         [-0.0333, -0.2163, -0.1476,  ...,  0.3382,  0.0030,  0.1642],\n","         [-0.1640, -0.0203,  0.1349,  ...,  0.1248,  0.0291,  0.1465],\n","         ...,\n","         [-0.1444, -0.0193,  0.1335,  ...,  0.1199,  0.0348,  0.1309],\n","         [-0.0390, -0.2208, -0.1564,  ...,  0.3486,  0.0017,  0.1531],\n","         [-0.0386, -0.2208, -0.1564,  ...,  0.3482,  0.0012,  0.1533]],\n","\n","        [[-0.0268, -0.1161, -0.1128,  ...,  0.2990,  0.0240,  0.1286],\n","         [-0.0047, -0.1848, -0.2342,  ...,  0.3318,  0.1120, -0.0350],\n","         [-0.0333, -0.1121, -0.1127,  ...,  0.3075,  0.0216,  0.1412],\n","         ...,\n","         [-0.0215, -0.1120, -0.1158,  ...,  0.3070,  0.0234,  0.1339],\n","         [-0.0077, -0.1861, -0.2400,  ...,  0.3401,  0.1105, -0.0428],\n","         [-0.0075, -0.1862, -0.2400,  ...,  0.3399,  0.1103, -0.0427]]],\n","       grad_fn=<CopySlices>)\n","torch.Size([22, 10, 100])\n"]}]},{"cell_type":"markdown","metadata":{"id":"x6h7rSTAwe4M"},"source":["<br>\n","\n","- Language Modeling 에 대한 loss 계산을 위해 shift 한 target 과 비교한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=11UNRhJug0bK6VVfhm5Nj5fi8Y7h3v6p8' width=800/>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMn_yzz6xIsc","executionInfo":{"status":"ok","timestamp":1631110825709,"user_tz":-540,"elapsed":494,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"b541779e-e675-4619-dce8-662720c651f8"},"source":["loss_function = nn.CrossEntropyLoss()\n","\n","preds = outputs[1:, :, :].transpose(0, 1) # (B, T_L-1, V)\n","loss = loss_function(\n","    preds.contiguous().view(-1, vocab_size),\n","    trg_batch[:, 1:].contiguous().view(-1, 1).squeeze(1)\n",")\n","\n","print(loss)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(4.6455, grad_fn=<NllLossBackward>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"iyIeukpdx_-d"},"source":["<br>\n","\n","- 실제 inference에선 teacher forcing 없이 이전 결과만을 가지고 생성합니다."]},{"cell_type":"code","metadata":{"id":"_iG5iflDyGh_"},"source":["src_sent = [4, 10, 88, 46, 72, 34, 14, 51]\n","src_len = len(src_sent)\n","\n","src_batch = torch.LongTensor(src_sent).unsqueeze(0)  # (1, L)\n","src_batch_lens = torch.LongTensor([src_len])  # (1)\n","\n","_, hidden = seq2seq.encoder(src_batch, src_batch_lens)  # hidden: (1, 1, d_h)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6q7mlVdyLj9"},"source":["input_id = torch.LongTensor([sos_id]) # (1)\n","output = []\n","\n","for t in range(1, trg_max_len):\n","  decoder_output, hidden = seq2seq.decoder(input_id, hidden)  # decoder_output: (1, V), hidden: (1, 1, d_h)\n","\n","  _, top_id = torch.max(decoder_output, dim=-1)  # top_ids: (1)\n","\n","  if top_id == eos_id:\n","    break\n","  else:\n","    output += top_id.tolist()\n","    input_id = top_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fjPrGGdryQnM","executionInfo":{"status":"ok","timestamp":1631110906653,"user_tz":-540,"elapsed":611,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"35a50571-d719-46b7-b3fb-f7bad05228b3"},"source":["print(output)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[77, 5, 8, 33, 36, 77, 6, 65, 58, 31, 58, 31, 58, 31, 58, 31, 58, 31, 58, 31, 58]\n"]}]},{"cell_type":"code","metadata":{"id":"IrG-kWyyySBG"},"source":[""],"execution_count":null,"outputs":[]}]}