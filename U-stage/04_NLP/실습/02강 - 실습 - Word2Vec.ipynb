{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02강 - 실습 - Word2Vec.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1qFDu8AJdvqnBeXwbOOKQZEqRak-0b9xQ","authorship_tag":"ABX9TyMHIgEjmAzWvO+/sYaZFOwY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"_PGz-G9IoOqf"},"source":["# 2 실습: Word2Vec\n","\n","1. 주어진 단어들을 word2vec 모델에 들어갈 수 있는 형태로 만듭니다.\n","2. CBOW, Skip-gram 모델을 각각 구현합니다.\n","3. 모델을 실제로 학습해보고 결과를 확인합니다."]},{"cell_type":"markdown","metadata":{"id":"Nrf4WdtToXvF"},"source":["<br>\n","\n","## 2.1 필요 패키지 import"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iFH6Z9byobBV","executionInfo":{"status":"ok","timestamp":1630940562191,"user_tz":-540,"elapsed":7303,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"b8de61e9-554c-419e-d071-8dd202bdf380"},"source":["!pip install konlpy"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n","\u001b[K     |████████████████████████████████| 19.4 MB 60.7 MB/s \n","\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Collecting beautifulsoup4==4.6.0\n","  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n","\u001b[K     |████████████████████████████████| 86 kB 4.3 MB/s \n","\u001b[?25hCollecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting JPype1>=0.7.0\n","  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n","\u001b[K     |████████████████████████████████| 448 kB 29.1 MB/s \n","\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n","  Attempting uninstall: beautifulsoup4\n","    Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"]}]},{"cell_type":"code","metadata":{"id":"5XsXhEF1ocgW"},"source":["from tqdm import tqdm\n","from konlpy.tag import Okt\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from collections import defaultdict\n","\n","import torch\n","import copy\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PIQTgRkAofLH"},"source":["<br>\n","\n","## 2.2 데이터 전처리\n","\n","- 데이터를 확인하고 Word2Vec 형식에 맞게 전처리합니다.  \n","- 학습 데이터는 1번 실습과 동일하고, 테스트를 위한 단어를 아래와 같이 가정해봅시다."]},{"cell_type":"code","metadata":{"id":"LrphGSEfolmV"},"source":["train_data = [\n","  \"정말 맛있습니다. 추천합니다.\",\n","  \"기대했던 것보단 별로였네요.\",\n","  \"다 좋은데 가격이 너무 비싸서 다시 가고 싶다는 생각이 안 드네요.\",\n","  \"완전 최고입니다! 재방문 의사 있습니다.\",\n","  \"음식도 서비스도 다 만족스러웠습니다.\",\n","  \"위생 상태가 좀 별로였습니다. 좀 더 개선되기를 바랍니다.\",\n","  \"맛도 좋았고 직원분들 서비스도 너무 친절했습니다.\",\n","  \"기념일에 방문했는데 음식도 분위기도 서비스도 다 좋았습니다.\",\n","  \"전반적으로 음식이 너무 짰습니다. 저는 별로였네요.\",\n","  \"위생에 조금 더 신경 썼으면 좋겠습니다. 조금 불쾌했습니다.\"       \n","]\n","\n","test_words = [\"음식\", \"맛\", \"서비스\", \"위생\", \"가격\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A58Mwf8pooPP"},"source":["<br>\n","\n","- Tokenization과 vocab을 만드는 과정은 이전 실습과 유사합니다."]},{"cell_type":"code","metadata":{"id":"L7Ky9Aoporlc"},"source":["tokenizer = Okt()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p7n3MJRRos_P"},"source":["def make_tokenized(data):\n","  tokenized = []\n","  for sent in tqdm(data):\n","    tokens = tokenizer.morphs(sent, stem=True)\n","    tokenized.append(tokens)\n","\n","  return tokenized"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lcyeMlA2ougF","executionInfo":{"status":"ok","timestamp":1630940634682,"user_tz":-540,"elapsed":7080,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"0d7c8c5e-536a-4ac8-995e-f02107289e0d"},"source":["train_tokenized = make_tokenized(train_data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:06<00:00,  1.50it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2iS1J3aKowCV","executionInfo":{"status":"ok","timestamp":1630940639321,"user_tz":-540,"elapsed":563,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"2b6f6944-7ea4-42cc-9c5c-c874870331cd"},"source":["word_count = defaultdict(int)\n","\n","for tokens in tqdm(train_tokenized):\n","  for token in tokens:\n","    word_count[token] += 1"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 26035.41it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1O9XvC0eoyuq","executionInfo":{"status":"ok","timestamp":1630940648609,"user_tz":-540,"elapsed":557,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"30134798-368a-4637-8738-58710abcfc8b"},"source":["word_count = sorted(word_count.items(), key=lambda x: x[1], reverse=True)\n","print(list(word_count))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[('.', 14), ('도', 7), ('이다', 4), ('좋다', 4), ('별로', 3), ('다', 3), ('이', 3), ('너무', 3), ('음식', 3), ('서비스', 3), ('하다', 2), ('방문', 2), ('위생', 2), ('좀', 2), ('더', 2), ('에', 2), ('조금', 2), ('정말', 1), ('맛있다', 1), ('추천', 1), ('기대하다', 1), ('것', 1), ('보단', 1), ('가격', 1), ('비싸다', 1), ('다시', 1), ('가다', 1), ('싶다', 1), ('생각', 1), ('안', 1), ('드네', 1), ('요', 1), ('완전', 1), ('최고', 1), ('!', 1), ('재', 1), ('의사', 1), ('있다', 1), ('만족스럽다', 1), ('상태', 1), ('가', 1), ('개선', 1), ('되다', 1), ('기르다', 1), ('바라다', 1), ('맛', 1), ('직원', 1), ('분들', 1), ('친절하다', 1), ('기념일', 1), ('분위기', 1), ('전반', 1), ('적', 1), ('으로', 1), ('짜다', 1), ('저', 1), ('는', 1), ('신경', 1), ('써다', 1), ('불쾌하다', 1)]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DtFPfvGlo1Bj","executionInfo":{"status":"ok","timestamp":1630940672697,"user_tz":-540,"elapsed":790,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"fd5a7325-c667-4c35-beca-6fe154d94738"},"source":["w2i = {}\n","for pair in tqdm(word_count):\n","  if pair[0] not in w2i:\n","    w2i[pair[0]] = len(w2i)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 60/60 [00:00<00:00, 480263.82it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BRRpchNeo62d","executionInfo":{"status":"ok","timestamp":1630940682394,"user_tz":-540,"elapsed":359,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"49c2b309-417f-442b-c99e-ac759968dc9d"},"source":["print(train_tokenized)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[['정말', '맛있다', '.', '추천', '하다', '.'], ['기대하다', '것', '보단', '별로', '이다', '.'], ['다', '좋다', '가격', '이', '너무', '비싸다', '다시', '가다', '싶다', '생각', '이', '안', '드네', '요', '.'], ['완전', '최고', '이다', '!', '재', '방문', '의사', '있다', '.'], ['음식', '도', '서비스', '도', '다', '만족스럽다', '.'], ['위생', '상태', '가', '좀', '별로', '이다', '.', '좀', '더', '개선', '되다', '기르다', '바라다', '.'], ['맛', '도', '좋다', '직원', '분들', '서비스', '도', '너무', '친절하다', '.'], ['기념일', '에', '방문', '하다', '음식', '도', '분위기', '도', '서비스', '도', '다', '좋다', '.'], ['전반', '적', '으로', '음식', '이', '너무', '짜다', '.', '저', '는', '별로', '이다', '.'], ['위생', '에', '조금', '더', '신경', '써다', '좋다', '.', '조금', '불쾌하다', '.']]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MjcXO1FVo9Td","executionInfo":{"status":"ok","timestamp":1630940695119,"user_tz":-540,"elapsed":453,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"e2221e5e-d1ed-4c8e-ca82-e9211310e169"},"source":["print(w2i)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'.': 0, '도': 1, '이다': 2, '좋다': 3, '별로': 4, '다': 5, '이': 6, '너무': 7, '음식': 8, '서비스': 9, '하다': 10, '방문': 11, '위생': 12, '좀': 13, '더': 14, '에': 15, '조금': 16, '정말': 17, '맛있다': 18, '추천': 19, '기대하다': 20, '것': 21, '보단': 22, '가격': 23, '비싸다': 24, '다시': 25, '가다': 26, '싶다': 27, '생각': 28, '안': 29, '드네': 30, '요': 31, '완전': 32, '최고': 33, '!': 34, '재': 35, '의사': 36, '있다': 37, '만족스럽다': 38, '상태': 39, '가': 40, '개선': 41, '되다': 42, '기르다': 43, '바라다': 44, '맛': 45, '직원': 46, '분들': 47, '친절하다': 48, '기념일': 49, '분위기': 50, '전반': 51, '적': 52, '으로': 53, '짜다': 54, '저': 55, '는': 56, '신경': 57, '써다': 58, '불쾌하다': 59}\n"]}]},{"cell_type":"markdown","metadata":{"id":"jV_ShfNkpAaG"},"source":["<br>\n","\n","## 2.3 Dataset 클래스 정의\n","\n","- 실제 모델에 들어가기 위한 input을 만들기 위해 `Dataset` 클래스를 정의합니다."]},{"cell_type":"code","metadata":{"id":"fdOgNu0ypIr0"},"source":["class CBOWDataset(Dataset):\n","    def __init__(self, train_tokenized, window_size=2):\n","        self.x = []\n","        self.y = []\n","\n","        for tokens in tqdm(train_tokenized):\n","            token_ids = [w2i[token] for token in tokens]\n","            for i, id in enumerate(token_ids):\n","                if i - window_size >= 0 and i + window_size < len(token_ids):\n","                    self.x.append(token_ids[i-window_size:i] + token_ids[i+1:i+window_size+1])\n","                    self.y.append(id)\n","\n","        self.x = torch.LongTensor(self.x) # (전체 데이터 개수, 2 * window_size)\n","        self.y = torch.LongTensor(self.y) # (전체 데이터 개수)\n","\n","    def __len__(self):\n","        return self.x.shape[0]\n","\n","    def __getitem__(self, idx):\n","        return self.x[idx], self.y[idx]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ooF1yEREwYzm"},"source":["class SkipGramDataset(Dataset):\n","  def __init__(self, train_tokenized, window_size=2):\n","    self.x = []\n","    self.y = []\n","\n","    for tokens in tqdm(train_tokenized):\n","      token_ids = [w2i[token] for token in tokens]\n","      for i, id in enumerate(token_ids):\n","        if i-window_size >= 0 and i+window_size < len(token_ids):\n","          self.y += (token_ids[i-window_size:i] + token_ids[i+1:i+window_size+1])\n","          self.x += [id] * 2 * window_size\n","\n","    self.x = torch.LongTensor(self.x)  # (전체 데이터 개수)\n","    self.y = torch.LongTensor(self.y)  # (전체 데이터 개수)\n","\n","  def __len__(self):\n","    return self.x.shape[0]\n","\n","  def __getitem__(self, idx):\n","    return self.x[idx], self.y[idx]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6h--klOrwhq8"},"source":["<br>\n","\n","- 각 모델에 맞는 Dataset 객체를 생성합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"te8nPC2XwqHA","executionInfo":{"status":"ok","timestamp":1630942727973,"user_tz":-540,"elapsed":328,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"52a9aa2f-3455-46b7-8ab9-b27deceda100"},"source":["cbow_set = CBOWDataset(train_tokenized)\n","skipgram_set = SkipGramDataset(train_tokenized)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 33689.19it/s]\n","100%|██████████| 10/10 [00:00<00:00, 47393.27it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EuXDCMrlwwu4","executionInfo":{"status":"ok","timestamp":1630942745982,"user_tz":-540,"elapsed":578,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"13c925b1-769d-4fa1-8010-275ade96578e"},"source":["print(list(skipgram_set))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[(tensor(0), tensor(17)), (tensor(0), tensor(18)), (tensor(0), tensor(19)), (tensor(0), tensor(10)), (tensor(19), tensor(18)), (tensor(19), tensor(0)), (tensor(19), tensor(10)), (tensor(19), tensor(0)), (tensor(22), tensor(20)), (tensor(22), tensor(21)), (tensor(22), tensor(4)), (tensor(22), tensor(2)), (tensor(4), tensor(21)), (tensor(4), tensor(22)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(23), tensor(5)), (tensor(23), tensor(3)), (tensor(23), tensor(6)), (tensor(23), tensor(7)), (tensor(6), tensor(3)), (tensor(6), tensor(23)), (tensor(6), tensor(7)), (tensor(6), tensor(24)), (tensor(7), tensor(23)), (tensor(7), tensor(6)), (tensor(7), tensor(24)), (tensor(7), tensor(25)), (tensor(24), tensor(6)), (tensor(24), tensor(7)), (tensor(24), tensor(25)), (tensor(24), tensor(26)), (tensor(25), tensor(7)), (tensor(25), tensor(24)), (tensor(25), tensor(26)), (tensor(25), tensor(27)), (tensor(26), tensor(24)), (tensor(26), tensor(25)), (tensor(26), tensor(27)), (tensor(26), tensor(28)), (tensor(27), tensor(25)), (tensor(27), tensor(26)), (tensor(27), tensor(28)), (tensor(27), tensor(6)), (tensor(28), tensor(26)), (tensor(28), tensor(27)), (tensor(28), tensor(6)), (tensor(28), tensor(29)), (tensor(6), tensor(27)), (tensor(6), tensor(28)), (tensor(6), tensor(29)), (tensor(6), tensor(30)), (tensor(29), tensor(28)), (tensor(29), tensor(6)), (tensor(29), tensor(30)), (tensor(29), tensor(31)), (tensor(30), tensor(6)), (tensor(30), tensor(29)), (tensor(30), tensor(31)), (tensor(30), tensor(0)), (tensor(2), tensor(32)), (tensor(2), tensor(33)), (tensor(2), tensor(34)), (tensor(2), tensor(35)), (tensor(34), tensor(33)), (tensor(34), tensor(2)), (tensor(34), tensor(35)), (tensor(34), tensor(11)), (tensor(35), tensor(2)), (tensor(35), tensor(34)), (tensor(35), tensor(11)), (tensor(35), tensor(36)), (tensor(11), tensor(34)), (tensor(11), tensor(35)), (tensor(11), tensor(36)), (tensor(11), tensor(37)), (tensor(36), tensor(35)), (tensor(36), tensor(11)), (tensor(36), tensor(37)), (tensor(36), tensor(0)), (tensor(9), tensor(8)), (tensor(9), tensor(1)), (tensor(9), tensor(1)), (tensor(9), tensor(5)), (tensor(1), tensor(1)), (tensor(1), tensor(9)), (tensor(1), tensor(5)), (tensor(1), tensor(38)), (tensor(5), tensor(9)), (tensor(5), tensor(1)), (tensor(5), tensor(38)), (tensor(5), tensor(0)), (tensor(40), tensor(12)), (tensor(40), tensor(39)), (tensor(40), tensor(13)), (tensor(40), tensor(4)), (tensor(13), tensor(39)), (tensor(13), tensor(40)), (tensor(13), tensor(4)), (tensor(13), tensor(2)), (tensor(4), tensor(40)), (tensor(4), tensor(13)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(2), tensor(13)), (tensor(2), tensor(4)), (tensor(2), tensor(0)), (tensor(2), tensor(13)), (tensor(0), tensor(4)), (tensor(0), tensor(2)), (tensor(0), tensor(13)), (tensor(0), tensor(14)), (tensor(13), tensor(2)), (tensor(13), tensor(0)), (tensor(13), tensor(14)), (tensor(13), tensor(41)), (tensor(14), tensor(0)), (tensor(14), tensor(13)), (tensor(14), tensor(41)), (tensor(14), tensor(42)), (tensor(41), tensor(13)), (tensor(41), tensor(14)), (tensor(41), tensor(42)), (tensor(41), tensor(43)), (tensor(42), tensor(14)), (tensor(42), tensor(41)), (tensor(42), tensor(43)), (tensor(42), tensor(44)), (tensor(43), tensor(41)), (tensor(43), tensor(42)), (tensor(43), tensor(44)), (tensor(43), tensor(0)), (tensor(3), tensor(45)), (tensor(3), tensor(1)), (tensor(3), tensor(46)), (tensor(3), tensor(47)), (tensor(46), tensor(1)), (tensor(46), tensor(3)), (tensor(46), tensor(47)), (tensor(46), tensor(9)), (tensor(47), tensor(3)), (tensor(47), tensor(46)), (tensor(47), tensor(9)), (tensor(47), tensor(1)), (tensor(9), tensor(46)), (tensor(9), tensor(47)), (tensor(9), tensor(1)), (tensor(9), tensor(7)), (tensor(1), tensor(47)), (tensor(1), tensor(9)), (tensor(1), tensor(7)), (tensor(1), tensor(48)), (tensor(7), tensor(9)), (tensor(7), tensor(1)), (tensor(7), tensor(48)), (tensor(7), tensor(0)), (tensor(11), tensor(49)), (tensor(11), tensor(15)), (tensor(11), tensor(10)), (tensor(11), tensor(8)), (tensor(10), tensor(15)), (tensor(10), tensor(11)), (tensor(10), tensor(8)), (tensor(10), tensor(1)), (tensor(8), tensor(11)), (tensor(8), tensor(10)), (tensor(8), tensor(1)), (tensor(8), tensor(50)), (tensor(1), tensor(10)), (tensor(1), tensor(8)), (tensor(1), tensor(50)), (tensor(1), tensor(1)), (tensor(50), tensor(8)), (tensor(50), tensor(1)), (tensor(50), tensor(1)), (tensor(50), tensor(9)), (tensor(1), tensor(1)), (tensor(1), tensor(50)), (tensor(1), tensor(9)), (tensor(1), tensor(1)), (tensor(9), tensor(50)), (tensor(9), tensor(1)), (tensor(9), tensor(1)), (tensor(9), tensor(5)), (tensor(1), tensor(1)), (tensor(1), tensor(9)), (tensor(1), tensor(5)), (tensor(1), tensor(3)), (tensor(5), tensor(9)), (tensor(5), tensor(1)), (tensor(5), tensor(3)), (tensor(5), tensor(0)), (tensor(53), tensor(51)), (tensor(53), tensor(52)), (tensor(53), tensor(8)), (tensor(53), tensor(6)), (tensor(8), tensor(52)), (tensor(8), tensor(53)), (tensor(8), tensor(6)), (tensor(8), tensor(7)), (tensor(6), tensor(53)), (tensor(6), tensor(8)), (tensor(6), tensor(7)), (tensor(6), tensor(54)), (tensor(7), tensor(8)), (tensor(7), tensor(6)), (tensor(7), tensor(54)), (tensor(7), tensor(0)), (tensor(54), tensor(6)), (tensor(54), tensor(7)), (tensor(54), tensor(0)), (tensor(54), tensor(55)), (tensor(0), tensor(7)), (tensor(0), tensor(54)), (tensor(0), tensor(55)), (tensor(0), tensor(56)), (tensor(55), tensor(54)), (tensor(55), tensor(0)), (tensor(55), tensor(56)), (tensor(55), tensor(4)), (tensor(56), tensor(0)), (tensor(56), tensor(55)), (tensor(56), tensor(4)), (tensor(56), tensor(2)), (tensor(4), tensor(55)), (tensor(4), tensor(56)), (tensor(4), tensor(2)), (tensor(4), tensor(0)), (tensor(16), tensor(12)), (tensor(16), tensor(15)), (tensor(16), tensor(14)), (tensor(16), tensor(57)), (tensor(14), tensor(15)), (tensor(14), tensor(16)), (tensor(14), tensor(57)), (tensor(14), tensor(58)), (tensor(57), tensor(16)), (tensor(57), tensor(14)), (tensor(57), tensor(58)), (tensor(57), tensor(3)), (tensor(58), tensor(14)), (tensor(58), tensor(57)), (tensor(58), tensor(3)), (tensor(58), tensor(0)), (tensor(3), tensor(57)), (tensor(3), tensor(58)), (tensor(3), tensor(0)), (tensor(3), tensor(16)), (tensor(0), tensor(58)), (tensor(0), tensor(3)), (tensor(0), tensor(16)), (tensor(0), tensor(59)), (tensor(16), tensor(3)), (tensor(16), tensor(0)), (tensor(16), tensor(59)), (tensor(16), tensor(0))]\n"]}]},{"cell_type":"markdown","metadata":{"id":"9edO24Ebw1Ec"},"source":["<br>\n","\n","## 2.4 모델 Class 구현\n","\n","- 차례대로 두 가지 Word2Vec 모델을 구현합니다.  \n","- `self.embedding`: `vocab_size` 크기의 one-hot vector를 특정 크기의 `dim` 차원으로 embedding 시키는 layer.\n","- `self.linear`: 변환된 embedding vector를 다시 원래 `vocab_size`로 바꾸는 layer."]},{"cell_type":"code","metadata":{"id":"WCgi5Xcvw-jU"},"source":["class CBOW(nn.Module):\n","    def __init__(self, vocab_size, dim):\n","        super(CBOW, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, dim, sparse=True)\n","        self.linear = nn.Linear(dim, vocab_size)\n","\n","    # B: batch size, W: window size, d_w: word embedding size, V: vocab size\n","    def forward(self, x):  # x: (B, 2W)\n","        embeddings = self.embedding(x)  # (B, 2W, d_w)\n","        embeddings = torch.sum(embeddings, dim=1)  # (B, d_w)\n","        output = self.linear(embeddings)  # (B, V)\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oTlvnj1xxdJW"},"source":["class SkipGram(nn.Module):\n","  def __init__(self, vocab_size, dim):\n","    super(SkipGram, self).__init__()\n","    self.embedding = nn.Embedding(vocab_size, dim, sparse=True)\n","    self.linear = nn.Linear(dim, vocab_size)\n","\n","  # B: batch size, W: window size, d_w: word embedding size, V: vocab size\n","  def forward(self, x): # x: (B)\n","    embeddings = self.embedding(x)  # (B, d_w)\n","    output = self.linear(embeddings)  # (B, V)\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7SiRp7VCxjTV"},"source":["<br>\n","\n","- 두 가지 모델을 생성합니다."]},{"cell_type":"code","metadata":{"id":"JmDmFPdoxmFU"},"source":["cbow = CBOW(vocab_size=len(w2i), dim=256)\n","skipgram = SkipGram(vocab_size=len(w2i), dim=256)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N8PS1Jjaxszb"},"source":["<br>\n","\n","## 2.5 모델 학습"]},{"cell_type":"markdown","metadata":{"id":"KwD5YcomyR-c"},"source":["### 2.5.1 DataLoader 정의\n","\n","- 다음과 같이 hyperparamter를 세팅하고 `DataLoader` 객체를 만듭니다."]},{"cell_type":"code","metadata":{"id":"QRc1cXCSx2bT"},"source":["batch_size = 4\n","learning_rate = 5e-4\n","num_epochs = 5\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","cbow_loader = DataLoader(cbow_set, batch_size=batch_size)\n","skipgram_loader = DataLoader(skipgram_set, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Jc8nNmcyyQDt"},"source":["<br>\n","\n","### 2.5.2 CBOW 모델 학습"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e9D3Eq3KyYhY","executionInfo":{"status":"ok","timestamp":1630943289689,"user_tz":-540,"elapsed":325,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"9ba1ed0c-175b-447c-8c9f-fdec5fe3adcb"},"source":["cbow.train()\n","cbow = cbow.to(device)\n","optim = torch.optim.SGD(cbow.parameters(), lr=learning_rate)\n","loss_function = nn.CrossEntropyLoss()\n","\n","for e in range(1, num_epochs+1):\n","    print(\"#\" * 50)\n","    print(f\"Epoch: {e}\")\n","    for batch in tqdm(cbow_loader):\n","        x, y = batch\n","        x, y = x.to(device), y.to(device) # (B, W), (B)\n","        output = cbow(x)  # (B, V)\n","\n","        optim.zero_grad()\n","        loss = loss_function(output, y)\n","        loss.backward()\n","        optim.step()\n","\n","        print(f\"Train loss: {loss.item()}\")\n","\n","print(\"Finished.\")       "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["##################################################\n","Epoch: 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 138.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 4.054550647735596\n","Train loss: 5.67555046081543\n","Train loss: 5.198138236999512\n","Train loss: 4.369802951812744\n","Train loss: 5.133298873901367\n","Train loss: 5.997370719909668\n","Train loss: 5.482280731201172\n","Train loss: 5.186917304992676\n","Train loss: 4.893204212188721\n","Train loss: 4.759692192077637\n","Train loss: 5.073273181915283\n","Train loss: 6.199517726898193\n","Train loss: 4.551670074462891\n","Train loss: 5.207858085632324\n","Train loss: 5.625341892242432\n","Train loss: 4.308653354644775\n","##################################################\n","Epoch: 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 627.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 3.9145796298980713\n","Train loss: 5.526880264282227\n","Train loss: 5.061664581298828\n","Train loss: 4.24098014831543\n","Train loss: 4.999307155609131\n","Train loss: 5.667733192443848\n","Train loss: 5.278000831604004\n","Train loss: 5.0507612228393555\n","Train loss: 4.755553722381592\n","Train loss: 4.5520219802856445\n","Train loss: 4.918086528778076\n","Train loss: 5.777098178863525\n","Train loss: 4.378524303436279\n","Train loss: 5.077892303466797\n","Train loss: 5.428253173828125\n","Train loss: 4.175396919250488\n","##################################################\n","Epoch: 3\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 736.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 3.7776684761047363\n","Train loss: 5.380146503448486\n","Train loss: 4.926895618438721\n","Train loss: 4.114384174346924\n","Train loss: 4.8666672706604\n","Train loss: 5.349849224090576\n","Train loss: 5.0769147872924805\n","Train loss: 4.916474342346191\n","Train loss: 4.622776508331299\n","Train loss: 4.352174282073975\n","Train loss: 4.770570278167725\n","Train loss: 5.36696720123291\n","Train loss: 4.20764684677124\n","Train loss: 4.949923515319824\n","Train loss: 5.233956336975098\n","Train loss: 4.04570198059082\n","##################################################\n","Epoch: 4\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 616.01it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 3.643686056137085\n","Train loss: 5.235286712646484\n","Train loss: 4.793839454650879\n","Train loss: 3.9900174140930176\n","Train loss: 4.735400676727295\n","Train loss: 5.0454254150390625\n","Train loss: 4.879087448120117\n","Train loss: 4.784059524536133\n","Train loss: 4.494814872741699\n","Train loss: 4.160479545593262\n","Train loss: 4.630369186401367\n","Train loss: 4.970902442932129\n","Train loss: 4.039138317108154\n","Train loss: 4.823968887329102\n","Train loss: 5.042507171630859\n","Train loss: 3.9195713996887207\n","##################################################\n","Epoch: 5\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 16/16 [00:00<00:00, 712.05it/s]"]},{"output_type":"stream","name":"stdout","text":["Train loss: 3.5125274658203125\n","Train loss: 5.092247009277344\n","Train loss: 4.662514686584473\n","Train loss: 3.867877960205078\n","Train loss: 4.605532169342041\n","Train loss: 4.756099700927734\n","Train loss: 4.684622764587402\n","Train loss: 4.653524398803711\n","Train loss: 4.371607780456543\n","Train loss: 3.9773011207580566\n","Train loss: 4.4969658851623535\n","Train loss: 4.590827465057373\n","Train loss: 3.8731191158294678\n","Train loss: 4.700056076049805\n","Train loss: 4.853995323181152\n","Train loss: 3.7970173358917236\n","Finished.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"cbb_vi3Xy50O"},"source":["<br>\n","\n","### 2.5.3 Skip-gram 모델 학습"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pv53xXykzDOO","executionInfo":{"status":"ok","timestamp":1630943338048,"user_tz":-540,"elapsed":821,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"3f665171-0ca7-4db9-e251-cc7e011df52e"},"source":["skipgram.train()\n","skipgram = skipgram.to(device)\n","optim = torch.optim.SGD(skipgram.parameters(), lr=learning_rate)\n","loss_function = nn.CrossEntropyLoss()\n","\n","for e in range(1, num_epochs+1):\n","  print(\"#\" * 50)\n","  print(f\"Epoch: {e}\")\n","  for batch in tqdm(skipgram_loader):\n","    x, y = batch\n","    x, y = x.to(device), y.to(device) # (B, W), (B)\n","    output = skipgram(x)  # (B, V)\n","\n","    optim.zero_grad()\n","    loss = loss_function(output, y)\n","    loss.backward()\n","    optim.step()\n","\n","    print(f\"Train loss: {loss.item()}\")\n","\n","print(\"Finished.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["##################################################\n","Epoch: 1\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 64/64 [00:00<00:00, 842.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 3.9033303260803223\n","Train loss: 4.652159214019775\n","Train loss: 4.0611982345581055\n","Train loss: 4.882054328918457\n","Train loss: 3.982480049133301\n","Train loss: 4.266542911529541\n","Train loss: 4.451872825622559\n","Train loss: 3.9264135360717773\n","Train loss: 4.0522918701171875\n","Train loss: 3.8711843490600586\n","Train loss: 3.8621044158935547\n","Train loss: 4.104809284210205\n","Train loss: 4.287799835205078\n","Train loss: 5.089155197143555\n","Train loss: 3.946296453475952\n","Train loss: 3.6794650554656982\n","Train loss: 4.245267391204834\n","Train loss: 4.141561508178711\n","Train loss: 4.5511393547058105\n","Train loss: 4.4197821617126465\n","Train loss: 3.967581272125244\n","Train loss: 4.299617767333984\n","Train loss: 4.084833145141602\n","Train loss: 4.1435227394104\n","Train loss: 4.628061294555664\n","Train loss: 4.901200771331787\n","Train loss: 3.741903066635132\n","Train loss: 4.589731693267822\n","Train loss: 4.560562610626221\n","Train loss: 4.7752275466918945\n","Train loss: 3.953383445739746\n","Train loss: 4.116762638092041\n","Train loss: 4.284392356872559\n","Train loss: 4.4076385498046875\n","Train loss: 4.3132734298706055\n","Train loss: 4.188643932342529\n","Train loss: 3.907785654067993\n","Train loss: 4.324801445007324\n","Train loss: 4.318212032318115\n","Train loss: 3.86112642288208\n","Train loss: 4.227009296417236\n","Train loss: 4.547222137451172\n","Train loss: 4.29733943939209\n","Train loss: 4.41861629486084\n","Train loss: 3.8736491203308105\n","Train loss: 3.640650749206543\n","Train loss: 4.174585342407227\n","Train loss: 4.147493839263916\n","Train loss: 4.464191436767578\n","Train loss: 4.148324489593506\n","Train loss: 4.1597089767456055\n","Train loss: 4.758634567260742\n","Train loss: 4.427884578704834\n","Train loss: 4.406950950622559\n","Train loss: 4.184918403625488\n","Train loss: 4.616909027099609\n","Train loss: 4.885015964508057\n","Train loss: 4.36057186126709\n","Train loss: 4.2148308753967285\n","Train loss: 3.795128583908081\n","Train loss: 4.231236457824707\n","Train loss: 4.830429553985596\n","Train loss: 4.321187973022461\n","Train loss: 4.439208984375\n","##################################################\n","Epoch: 2\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 64/64 [00:00<00:00, 757.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 3.8831441402435303\n","Train loss: 4.602764129638672\n","Train loss: 4.03122615814209\n","Train loss: 4.822909355163574\n","Train loss: 3.951694965362549\n","Train loss: 4.2340569496154785\n","Train loss: 4.414535045623779\n","Train loss: 3.9008073806762695\n","Train loss: 4.021469593048096\n","Train loss: 3.8466506004333496\n","Train loss: 3.8413734436035156\n","Train loss: 4.075228691101074\n","Train loss: 4.263861656188965\n","Train loss: 5.0533552169799805\n","Train loss: 3.921790838241577\n","Train loss: 3.6568098068237305\n","Train loss: 4.208268642425537\n","Train loss: 4.109065055847168\n","Train loss: 4.522836685180664\n","Train loss: 4.388424873352051\n","Train loss: 3.876401662826538\n","Train loss: 4.210205078125\n","Train loss: 4.0284504890441895\n","Train loss: 4.114841461181641\n","Train loss: 4.593697547912598\n","Train loss: 4.8444929122924805\n","Train loss: 3.7071638107299805\n","Train loss: 4.5620927810668945\n","Train loss: 4.523254871368408\n","Train loss: 4.736072063446045\n","Train loss: 3.928731918334961\n","Train loss: 4.092088222503662\n","Train loss: 4.254177093505859\n","Train loss: 4.367354869842529\n","Train loss: 4.274726390838623\n","Train loss: 4.163456916809082\n","Train loss: 3.850832462310791\n","Train loss: 4.2736616134643555\n","Train loss: 4.283243656158447\n","Train loss: 3.835437297821045\n","Train loss: 4.1962890625\n","Train loss: 4.512836456298828\n","Train loss: 4.234999179840088\n","Train loss: 4.3594818115234375\n","Train loss: 3.760592222213745\n","Train loss: 3.5514566898345947\n","Train loss: 4.083619117736816\n","Train loss: 4.092106819152832\n","Train loss: 4.427858352661133\n","Train loss: 4.115706920623779\n","Train loss: 4.126119136810303\n","Train loss: 4.7112627029418945\n","Train loss: 4.394613742828369\n","Train loss: 4.377767086029053\n","Train loss: 4.1629791259765625\n","Train loss: 4.587299346923828\n","Train loss: 4.827492713928223\n","Train loss: 4.332419395446777\n","Train loss: 4.182521343231201\n","Train loss: 3.771876811981201\n","Train loss: 4.197709083557129\n","Train loss: 4.7916154861450195\n","Train loss: 4.297255039215088\n","Train loss: 4.394688129425049\n","##################################################\n","Epoch: 3\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/64 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Train loss: 3.8634145259857178\n","Train loss: 4.553588390350342\n","Train loss: 4.0014238357543945\n","Train loss: 4.7642669677734375\n","Train loss: 3.921130418777466\n","Train loss: 4.201992511749268\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 64/64 [00:00<00:00, 690.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train loss: 4.377692222595215\n","Train loss: 3.8753621578216553\n","Train loss: 3.9908132553100586\n","Train loss: 3.8222789764404297\n","Train loss: 3.820754051208496\n","Train loss: 4.04581880569458\n","Train loss: 4.24029016494751\n","Train loss: 5.0176801681518555\n","Train loss: 3.8974289894104004\n","Train loss: 3.6345226764678955\n","Train loss: 4.171518325805664\n","Train loss: 4.076775550842285\n","Train loss: 4.494784832000732\n","Train loss: 4.357227325439453\n","Train loss: 3.7870168685913086\n","Train loss: 4.12297248840332\n","Train loss: 3.972623109817505\n","Train loss: 4.086327075958252\n","Train loss: 4.5595903396606445\n","Train loss: 4.7882537841796875\n","Train loss: 3.6729190349578857\n","Train loss: 4.534857273101807\n","Train loss: 4.486227989196777\n","Train loss: 4.6972575187683105\n","Train loss: 3.9042255878448486\n","Train loss: 4.0675458908081055\n","Train loss: 4.224115371704102\n","Train loss: 4.327514171600342\n","Train loss: 4.236458778381348\n","Train loss: 4.138345241546631\n","Train loss: 3.7953412532806396\n","Train loss: 4.224229335784912\n","Train loss: 4.248685836791992\n","Train loss: 3.81006121635437\n","Train loss: 4.165680408477783\n","Train loss: 4.478835582733154\n","Train loss: 4.174647808074951\n","Train loss: 4.30076265335083\n","Train loss: 3.6503548622131348\n","Train loss: 3.4641857147216797\n","Train loss: 3.9950149059295654\n","Train loss: 4.037254810333252\n","Train loss: 4.391720294952393\n","Train loss: 4.083510875701904\n","Train loss: 4.092965602874756\n","Train loss: 4.664392471313477\n","Train loss: 4.361532211303711\n","Train loss: 4.349043846130371\n","Train loss: 4.141108512878418\n","Train loss: 4.5577898025512695\n","Train loss: 4.770453929901123\n","Train loss: 4.304572105407715\n","Train loss: 4.15060567855835\n","Train loss: 3.748758316040039\n","Train loss: 4.1643781661987305\n","Train loss: 4.753190994262695\n","Train loss: 4.273768901824951\n","Train loss: 4.35054874420166\n","##################################################\n","Epoch: 4\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/64 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Train loss: 3.844132423400879\n","Train loss: 4.504638195037842\n","Train loss: 3.971794605255127\n","Train loss: 4.7061309814453125\n","Train loss: 3.8907878398895264"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 64/64 [00:00<00:00, 774.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Train loss: 4.170349597930908\n","Train loss: 4.341348171234131\n","Train loss: 3.8500795364379883\n","Train loss: 3.9603271484375\n","Train loss: 3.798069953918457\n","Train loss: 3.800245523452759\n","Train loss: 4.0165815353393555\n","Train loss: 4.217080593109131\n","Train loss: 4.982129096984863\n","Train loss: 3.873210906982422\n","Train loss: 3.612604856491089\n","Train loss: 4.135018825531006\n","Train loss: 4.044693946838379\n","Train loss: 4.466983318328857\n","Train loss: 4.3261895179748535\n","Train loss: 3.6995816230773926\n","Train loss: 4.038067817687988\n","Train loss: 3.917372465133667\n","Train loss: 4.057980060577393\n","Train loss: 4.5257415771484375\n","Train loss: 4.732486724853516\n","Train loss: 3.639176845550537\n","Train loss: 4.508022308349609\n","Train loss: 4.449483871459961\n","Train loss: 4.658787250518799\n","Train loss: 3.879864454269409\n","Train loss: 4.043135643005371\n","Train loss: 4.194211006164551\n","Train loss: 4.288120269775391\n","Train loss: 4.198476791381836\n","Train loss: 4.113302707672119\n","Train loss: 3.7414159774780273\n","Train loss: 4.176581859588623\n","Train loss: 4.214536666870117\n","Train loss: 3.7849960327148438\n","Train loss: 4.1351823806762695\n","Train loss: 4.4452223777771\n","Train loss: 4.116396427154541\n","Train loss: 4.242486476898193\n","Train loss: 3.5431480407714844\n","Train loss: 3.378998041152954\n","Train loss: 3.908924102783203\n","Train loss: 3.9829599857330322\n","Train loss: 4.355777740478516\n","Train loss: 4.0517354011535645\n","Train loss: 4.060248851776123\n","Train loss: 4.618033409118652\n","Train loss: 4.328641891479492\n","Train loss: 4.320775508880615\n","Train loss: 4.1193084716796875\n","Train loss: 4.528383255004883\n","Train loss: 4.71390438079834\n","Train loss: 4.277029037475586\n","Train loss: 4.119083404541016\n","Train loss: 3.725773334503174\n","Train loss: 4.1312479972839355\n","Train loss: 4.715155601501465\n","Train loss: 4.250720977783203\n","Train loss: 4.306792259216309\n","##################################################\n","Epoch: 5\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/64 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["Train loss: 3.825288772583008\n","Train loss: 4.455923080444336\n","Train loss: 3.94234037399292\n","Train loss: 4.648508071899414\n","Train loss: 3.860668420791626\n","Train loss: 4.139127254486084\n","Train loss: 4.305509567260742\n","Train loss: 3.824960231781006\n","Train loss: 3.9300127029418945\n"]},{"output_type":"stream","name":"stderr","text":["\r100%|██████████| 64/64 [00:00<00:00, 639.78it/s]"]},{"output_type":"stream","name":"stdout","text":["Train loss: 3.7740259170532227\n","Train loss: 3.779848575592041\n","Train loss: 3.987520217895508\n","Train loss: 4.194230079650879\n","Train loss: 4.946702003479004\n","Train loss: 3.8491363525390625\n","Train loss: 3.591054916381836\n","Train loss: 4.0987749099731445\n","Train loss: 4.012825012207031\n","Train loss: 4.439432621002197\n","Train loss: 4.295313835144043\n","Train loss: 3.6142609119415283\n","Train loss: 3.955641508102417\n","Train loss: 3.862720012664795\n","Train loss: 4.029802322387695\n","Train loss: 4.49215030670166\n","Train loss: 4.67719841003418\n","Train loss: 3.6059460639953613\n","Train loss: 4.481581211090088\n","Train loss: 4.413023471832275\n","Train loss: 4.620664119720459\n","Train loss: 3.85564923286438\n","Train loss: 4.018856048583984\n","Train loss: 4.164465427398682\n","Train loss: 4.249178886413574\n","Train loss: 4.160789489746094\n","Train loss: 4.088322639465332\n","Train loss: 3.689164400100708\n","Train loss: 4.130793571472168\n","Train loss: 4.180795669555664\n","Train loss: 3.760241746902466\n","Train loss: 4.104795455932617\n","Train loss: 4.411996841430664\n","Train loss: 4.060351371765137\n","Train loss: 4.184683799743652\n","Train loss: 3.4391841888427734\n","Train loss: 3.296058177947998\n","Train loss: 3.825496196746826\n","Train loss: 3.9292454719543457\n","Train loss: 4.320030689239502\n","Train loss: 4.020382881164551\n","Train loss: 4.02796745300293\n","Train loss: 4.572195053100586\n","Train loss: 4.295945167541504\n","Train loss: 4.292958736419678\n","Train loss: 4.097579002380371\n","Train loss: 4.499081611633301\n","Train loss: 4.6578521728515625\n","Train loss: 4.249787330627441\n","Train loss: 4.087955951690674\n","Train loss: 3.7029223442077637\n","Train loss: 4.098320484161377\n","Train loss: 4.677511215209961\n","Train loss: 4.2281036376953125\n","Train loss: 4.263421058654785\n","Finished.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","metadata":{"id":"dk0fDIrNzFkE"},"source":["<br>\n","\n","## 2.6 테스트\n","\n","- 학습된 각 모델을 이용하여 test 단어들의 word embedding을 확인합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Ej8lCDKzNB8","executionInfo":{"status":"ok","timestamp":1630943465244,"user_tz":-540,"elapsed":342,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"918b0448-37f2-4bff-9fe0-6d5711610c65"},"source":["for word in test_words:\n","    input_id = torch.LongTensor([w2i[word]]).to(device)\n","    emb = cbow.embedding(input_id)\n","\n","    print(f\"Word: {word}\")\n","    print(emb.squeeze(0))\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Word: 음식\n","tensor([ 1.7712e-01,  1.7069e+00,  2.4660e-01,  9.0252e-01, -1.3213e-01,\n","        -1.1808e+00,  2.3575e+00, -9.1700e-01, -5.4660e-01,  1.1838e+00,\n","        -1.2626e+00, -1.1808e-01, -3.8100e-02,  7.3559e-01,  1.1051e+00,\n","         2.1922e+00,  1.0338e+00, -1.3936e+00,  7.9383e-01,  4.5002e-01,\n","         1.6132e+00, -2.0661e+00,  3.6536e-02,  9.0191e-01, -1.5138e-01,\n","        -5.7717e-01,  4.6874e-01,  8.3352e-01, -8.9390e-01, -1.0004e+00,\n","         6.9371e-01, -9.0990e-01, -1.6480e-01,  1.1343e+00, -5.5651e-01,\n","        -1.7073e-01,  8.8515e-01,  3.2971e-01, -1.0262e+00, -1.0740e-01,\n","         1.1418e+00, -1.0126e+00,  1.2385e+00, -1.5794e+00,  2.3313e-01,\n","         1.1163e-01, -1.0098e-01, -1.3666e+00,  9.5331e-01,  9.7725e-01,\n","         1.0431e+00,  3.2246e+00,  2.9030e-01, -6.6350e-01,  3.5262e-01,\n","        -1.3325e+00,  1.8576e+00,  1.7077e-01, -1.0483e+00, -6.3113e-01,\n","        -3.8485e-01, -1.2340e-02, -1.5933e+00, -4.6251e-01, -2.6286e-02,\n","        -4.1586e-01,  1.3341e+00,  8.2086e-02,  7.3080e-01,  2.1418e+00,\n","        -1.8139e-01, -1.6575e-01, -1.5358e-01, -1.3530e+00,  2.6429e+00,\n","         9.3165e-01, -3.6229e-01,  7.0098e-01,  1.9242e+00,  8.6040e-01,\n","        -1.0081e+00, -8.2979e-01, -9.1333e-01, -5.1826e-02, -3.6892e-01,\n","        -1.9634e+00,  1.6164e+00, -1.9799e-02, -5.0762e-01, -9.1072e-01,\n","         1.4430e+00,  1.2652e+00, -3.3095e-01,  5.6894e-01, -2.5323e-01,\n","         1.5401e+00,  4.7759e-02,  3.3086e-01, -8.7122e-01, -1.1612e+00,\n","         5.0177e-02,  5.9145e-01, -8.0136e-01,  1.1716e-01,  1.5144e-01,\n","         1.2142e+00,  3.3313e-02, -1.5126e+00, -1.3081e+00,  1.6723e+00,\n","         1.2864e+00,  1.4599e+00,  2.3119e+00, -2.5379e-01, -4.3571e-01,\n","        -2.8912e-01,  4.5768e-01,  2.8269e-01,  7.6785e-01, -8.3778e-01,\n","        -8.1638e-01, -6.0130e-01, -1.7427e+00, -5.5788e-01,  5.7468e-01,\n","         1.5610e+00,  8.7705e-01,  3.7554e-01,  4.4530e-02,  6.8713e-01,\n","        -1.1931e-01,  7.0864e-01,  7.7350e-02,  5.8565e-02, -7.0722e-01,\n","         5.2078e-01,  5.0392e-01, -3.8037e-02, -7.2861e-01,  1.1436e+00,\n","         9.8718e-01,  1.7614e-01,  8.8474e-01, -1.9249e-01, -1.5481e+00,\n","        -2.1020e+00,  3.2390e-02,  2.3500e+00,  1.5297e+00,  1.1811e+00,\n","         9.2704e-01, -1.4315e+00, -3.1857e-01, -2.3533e-02,  3.1072e-01,\n","        -4.7591e-01, -7.5746e-03,  8.8115e-02,  4.4470e-01,  9.9822e-02,\n","        -1.9352e+00,  5.3271e-03, -7.6716e-01,  8.5798e-01,  1.3806e+00,\n","        -1.2278e+00, -7.4395e-01, -7.3757e-01, -3.1986e-01,  5.9702e-02,\n","        -3.0713e-01, -4.5516e-01, -5.7627e-01, -7.5048e-02,  2.3606e-01,\n","        -4.1641e-01, -7.8234e-01,  9.7373e-01, -4.1626e-01,  1.3398e+00,\n","        -2.3742e-01,  6.8533e-02, -7.9599e-01, -2.0463e+00, -6.8557e-01,\n","         3.7599e-01,  3.4483e-02,  1.2026e-01, -7.8093e-03,  4.5260e-01,\n","        -9.5522e-01, -1.9088e+00, -1.8357e-02,  9.2992e-01, -9.2790e-01,\n","        -2.4142e-01, -2.3783e-01,  2.5407e-01,  8.1511e-01, -2.4074e+00,\n","        -2.3912e-01,  1.2064e+00,  1.1020e-01, -1.3381e+00,  2.5842e-01,\n","        -4.6204e-01,  7.9664e-01, -2.2229e-01,  4.0846e-01,  1.0281e+00,\n","         7.6415e-02,  1.3944e-01, -1.6364e-01,  2.0382e+00,  3.3375e-01,\n","        -1.5724e+00, -2.0487e-03, -1.3721e+00, -7.4009e-01, -1.9500e+00,\n","        -5.4295e-02, -6.7660e-01, -8.0644e-01, -5.7686e-01,  9.1236e-01,\n","         3.3848e-01,  7.0478e-01, -4.7255e-01, -1.0532e-01, -5.5416e-01,\n","        -1.1982e+00, -4.9313e-01, -6.0675e-01, -1.1611e+00,  7.6056e-01,\n","        -9.8284e-01,  2.8210e-01,  1.2814e-01, -1.4695e+00,  7.4967e-01,\n","        -5.4533e-01,  6.1036e-01, -1.3553e+00,  3.1862e-01,  7.7112e-01,\n","        -1.5853e-01,  8.8603e-01, -4.1921e-01,  9.1741e-01,  1.3752e+00,\n","        -6.5324e-02, -3.4949e-01, -7.4370e-01, -5.9089e-01,  7.5388e-01,\n","         2.6724e-01], grad_fn=<SqueezeBackward1>)\n","\n","Word: 맛\n","tensor([ 1.0002, -0.7156,  0.7828, -0.1362,  0.7660,  0.0986,  1.7140,  0.2499,\n","        -0.0617, -0.1267, -0.6630, -1.0783,  0.6634,  0.1496,  0.0114,  0.3573,\n","         0.2579,  0.0581, -0.0722,  0.5094, -0.6164,  0.1023,  0.9331,  0.6870,\n","        -0.4934,  0.8508,  0.4818,  0.9014, -1.4998,  0.6885, -0.7526, -1.0721,\n","        -0.6818,  0.4227,  1.3660,  0.0920,  2.1772,  0.5697, -0.4549,  1.5280,\n","        -1.5516,  0.2783, -0.0951,  0.5938,  0.6609,  0.2552,  2.1468,  0.4957,\n","        -1.1550, -0.4802,  0.4826, -0.2924, -2.0376,  0.9965, -0.2002,  1.4491,\n","         1.0063, -0.0596, -0.2823, -0.3710,  0.5830, -0.0700, -0.5893, -0.7534,\n","        -0.1819, -0.4178, -0.7011, -0.0195, -2.3928, -0.2171, -0.4522,  0.2194,\n","        -0.2368,  1.0570,  0.2981,  1.1611,  2.1382, -0.1267, -1.8220,  0.0261,\n","         0.5777, -0.9536, -0.0617, -0.7067,  0.7544,  0.2962, -1.0228, -0.1983,\n","         1.8763,  1.1700, -0.7907, -1.0755, -0.1727, -0.5059, -1.6963, -1.3943,\n","        -0.8028, -0.0054,  0.1719, -0.2842, -0.4135,  0.0654,  0.7131,  0.0809,\n","        -0.0675, -0.3844,  2.2888,  0.0476, -0.1758, -0.8770, -0.8344,  1.3456,\n","        -0.8114, -0.1058, -0.9908, -0.8717, -1.6492,  0.3332,  0.0751,  0.5869,\n","        -0.9320, -1.8410,  0.2353, -1.0073,  0.3610,  0.2191, -0.4872,  1.0956,\n","        -0.1787,  0.6044,  1.3698,  0.2279, -0.7246, -0.0649,  1.9069, -1.8519,\n","         1.1634,  1.7312,  0.0264,  0.7460,  0.7766, -0.1290, -0.5678, -0.8414,\n","         1.3187,  0.1432, -0.3832,  1.5814, -1.2476, -1.2810,  1.5421, -0.6197,\n","        -0.9933,  1.4290, -0.3761,  0.2192, -1.2873,  2.0346, -1.3590,  0.6122,\n","        -0.1182, -0.1643, -0.5347, -1.0973,  1.0644,  1.9636,  1.0330,  0.3819,\n","        -0.5927, -1.3235,  0.7669,  0.7005,  1.4110, -1.8605,  0.3652,  0.1758,\n","         0.3437,  0.8222,  0.2798, -1.6768, -1.2687,  0.8206,  1.4345, -0.6391,\n","         2.2034, -0.3505, -0.2644,  0.3810, -1.3024, -1.5442, -0.4401,  0.2281,\n","        -0.5137,  0.7016,  0.4058,  0.8904,  0.6430,  0.8544, -1.4529,  0.2428,\n","         0.8531,  0.3580,  0.1890,  0.0666,  0.2004,  0.5919, -1.1552,  1.4771,\n","        -0.4622, -0.1992, -1.3215, -0.2281,  2.2855, -1.1390,  1.1085,  0.3660,\n","         0.3669,  0.4909,  0.1189,  0.3210,  0.2001, -0.5256, -0.4751, -0.3487,\n","         0.7974, -0.2893, -1.4770,  0.3999,  0.5642, -0.3548, -0.1418, -1.0015,\n","         0.5381, -0.0913, -0.6368, -0.1385,  0.0952,  0.4626,  0.4838, -0.0406,\n","         0.2172,  1.6303, -0.9803, -1.2665, -0.3386,  1.4765,  0.3595, -1.0703,\n","        -0.5133,  0.1773,  0.3848,  0.7827, -0.0522,  0.0889,  0.4721, -0.6959],\n","       grad_fn=<SqueezeBackward1>)\n","\n","Word: 서비스\n","tensor([ 1.0924, -0.2678, -0.7352,  1.1935,  1.3462,  0.4802,  0.0976, -0.6216,\n","        -0.4882,  0.5682,  0.3722,  0.7283,  1.8180,  1.1981, -0.7435,  0.4561,\n","         0.4236, -1.6925, -1.0272,  1.0903,  1.0692, -1.3711, -0.3296,  0.8967,\n","         0.7909, -1.7207,  1.4777, -0.7863, -1.3097,  1.2662, -0.2941, -0.9769,\n","        -0.5531, -0.6675,  0.5825, -1.0781,  2.1686, -0.1253,  0.4065, -1.2628,\n","        -0.4842, -0.6472, -0.8255, -0.6568, -0.2409, -1.0072, -1.0782,  0.0781,\n","         0.7334, -0.1038,  1.4374, -0.8694,  0.3463,  0.6699, -1.1458, -0.9645,\n","         2.6793,  2.0630, -0.2110,  0.9203,  1.3474, -1.0618,  2.4618, -0.6014,\n","        -0.3931, -0.3933,  0.3753, -0.5345, -1.0880,  0.1669,  0.6918,  1.0574,\n","        -0.6243,  0.7763,  0.3328, -0.1900, -0.9709,  0.8089,  0.4314,  0.1978,\n","        -0.9842, -1.0985,  0.0844,  1.3481,  0.8919,  0.2483, -1.3380, -0.8378,\n","         1.6102, -0.2591,  0.4537, -0.2017, -0.0862,  1.3185, -1.5209, -0.4354,\n","         0.8286, -0.1659,  0.0637,  2.5283,  1.1467, -0.8943,  0.1376,  0.6496,\n","        -0.3200, -0.9655,  0.5093, -1.0070,  1.0535, -0.0943, -1.4661, -0.8203,\n","        -0.5116, -0.1714, -0.6640,  0.8851,  1.5195, -0.9948,  1.6988,  0.6663,\n","        -0.1185, -1.1078,  0.7198,  1.0485, -1.0552, -2.0521, -0.7838,  1.4787,\n","         0.9828, -0.5568, -0.6835,  0.4638, -2.0869,  0.3612,  2.5181,  0.5501,\n","         0.0958, -1.0882, -0.5152,  0.5670, -0.2748,  0.1641,  1.2201,  0.8696,\n","        -1.1300,  2.1797, -1.1846,  2.8481, -0.3781,  0.5137,  0.2844,  0.1980,\n","         0.5895, -0.6182, -0.1523,  0.0365,  1.4708,  2.4347, -0.4734,  0.3218,\n","        -0.7244,  1.2348,  0.8975, -1.3933,  1.6064,  0.2396,  0.1077, -1.1484,\n","        -0.4292, -0.0920,  0.6999, -0.2372,  1.2335,  0.6008,  0.5109,  0.2829,\n","         0.0680,  0.2892, -0.1423, -0.3979, -0.2668,  0.9395,  1.3057, -1.8129,\n","        -0.2975,  0.5650,  0.7918, -0.5043,  0.8498, -0.4999, -0.5390,  0.6616,\n","        -1.3889, -2.5351,  0.5761, -0.0565,  0.1583,  0.5683, -0.8459, -0.2075,\n","         0.7163,  0.5973,  1.2679, -0.4812, -0.5472, -2.2079, -0.4166,  0.8503,\n","         1.1856, -0.1426, -0.0223,  2.2503,  0.2211,  0.0725,  0.4576,  1.3479,\n","        -1.4335,  1.6421, -0.7598,  0.2802, -0.0786,  0.2977,  0.9968,  1.4201,\n","        -0.0156,  0.4727, -0.5842,  0.6426, -0.8403, -0.6571, -1.3501,  0.6303,\n","         0.8465, -0.2105,  0.9996,  0.5313, -1.8821, -0.7382,  0.1444,  1.8027,\n","        -1.1476, -1.5419,  0.3803,  1.4606,  2.1004, -1.5259, -0.2254,  0.9930,\n","         0.0485, -0.4275, -1.0625, -0.1472, -0.1453, -0.5481, -0.4531,  0.2219],\n","       grad_fn=<SqueezeBackward1>)\n","\n","Word: 위생\n","tensor([ 2.2730e-01, -1.5145e+00, -2.6056e-01, -1.6275e+00,  9.9755e-01,\n","         2.9265e+00,  1.4658e+00,  9.5654e-01,  1.7069e+00, -6.4984e-01,\n","        -4.9102e-01,  2.0102e-01, -1.6788e+00, -1.4764e+00, -2.6630e-04,\n","         6.8201e-01, -1.4297e+00, -1.8111e+00, -8.2658e-01, -4.7007e-05,\n","        -1.3540e+00,  1.9804e+00, -1.5222e+00, -5.5305e-01, -5.3247e-01,\n","        -1.4170e-01,  7.3438e-01, -2.5837e+00, -1.0688e+00, -4.7009e-01,\n","        -1.8131e+00, -2.5951e-01,  1.6867e-01,  4.8976e-01,  4.5859e-01,\n","        -2.3624e+00, -3.9285e-01,  4.6985e-01, -5.9457e-02,  3.1599e-01,\n","        -3.4674e-01,  5.4199e-01, -1.5160e-01, -3.1548e-01, -2.7819e-01,\n","         7.8196e-01, -4.7455e-01,  1.0971e+00, -6.7186e-01,  1.3371e+00,\n","        -1.5975e+00,  9.1439e-01,  9.3454e-01,  2.0543e+00,  7.3699e-01,\n","         6.5711e-01, -8.5692e-01, -1.2144e+00,  2.0687e+00, -1.0788e-01,\n","         4.7949e-01,  5.8140e-01,  6.2883e-01, -1.0260e+00, -1.2678e+00,\n","         6.8231e-01, -5.1799e-01, -1.1595e+00,  7.4276e-02,  1.4826e+00,\n","         1.2129e+00, -5.6251e-01,  2.0171e-01, -6.1365e-01,  1.4952e-01,\n","         2.1106e-01,  7.0415e-01, -7.4645e-01,  2.4929e-01,  8.6685e-01,\n","         6.0322e-01, -2.2242e-01, -8.0897e-01,  1.0694e+00, -1.0924e+00,\n","        -1.6573e+00, -6.0241e-02,  8.5452e-01,  9.9367e-01, -1.6699e+00,\n","        -2.1360e+00,  1.4420e+00, -1.7586e-01, -5.6836e-01, -9.2558e-01,\n","        -8.5331e-01, -3.0075e-01,  8.5157e-02,  2.7192e-01,  3.7625e-01,\n","        -2.8083e-01,  2.4648e-02, -1.1912e+00,  2.0144e-01, -8.1953e-01,\n","         1.6460e+00, -8.7606e-01, -3.0216e-02, -2.7829e-01,  2.9801e+00,\n","        -1.7247e+00,  2.1618e-01, -2.1839e-01,  1.1735e+00,  6.1693e-01,\n","        -2.0635e+00,  7.5970e-01, -1.1586e+00,  2.6802e-01, -1.5293e+00,\n","         5.5140e-01, -2.9171e-01, -7.0984e-01, -9.9925e-01,  3.2662e-01,\n","        -4.5140e-01, -2.6275e-01,  1.9775e+00,  1.4356e-01,  1.0190e+00,\n","         3.1343e+00,  1.1120e+00, -5.2120e-01, -6.1636e-01, -7.1813e-01,\n","         2.8815e-01, -4.5928e-01,  5.1722e-01,  5.5848e-02,  2.1728e+00,\n","        -1.5259e-01, -9.9169e-01, -2.9568e-01,  5.6044e-01, -1.5471e-01,\n","        -2.3859e-01,  1.3206e+00,  3.2857e-02, -1.1619e-01,  4.4062e-01,\n","         4.5913e-01,  9.7895e-01,  5.0546e-01, -2.7980e-01, -6.8103e-02,\n","        -6.5520e-02, -6.0846e-01, -1.9871e-01, -6.1054e-01, -5.6962e-01,\n","        -8.5820e-01,  4.5472e-01, -6.5213e-01, -5.7332e-01, -9.6252e-01,\n","        -1.6167e+00,  8.4252e-02, -5.0199e-02,  3.6632e-01, -2.9762e-01,\n","         1.1271e+00, -9.2173e-01,  7.5363e-01, -1.0305e+00, -4.3736e-01,\n","        -1.6164e+00,  6.4677e-01,  5.4889e-01, -8.6539e-01, -1.3690e+00,\n","         1.6608e-01,  3.2049e-03, -2.4611e-02,  6.8359e-01,  6.5549e-01,\n","         1.7253e+00, -1.5386e+00, -1.9437e-01,  7.7537e-01, -1.9652e-01,\n","        -1.4752e+00, -1.4356e+00, -1.0687e-01, -1.8636e+00,  7.4174e-01,\n","        -3.7526e-01, -2.1441e+00,  1.5810e-01, -5.1602e-03, -1.2577e+00,\n","        -4.0163e-01,  3.4939e-01,  1.4543e-01, -1.1659e+00,  5.0715e-01,\n","        -6.6360e-01,  1.9950e+00,  7.0076e-01,  1.9342e-01,  1.9389e-01,\n","         1.6389e+00,  1.2561e+00,  4.8074e-01,  1.2995e+00, -1.2746e+00,\n","        -4.2889e-01, -7.0432e-01,  4.4072e-01, -1.7283e+00,  6.2251e-01,\n","         9.0185e-01, -6.6263e-01, -3.8747e-02,  1.2647e+00,  1.1739e+00,\n","        -2.2471e-01,  1.9006e+00, -2.3397e-01,  1.5545e-01,  1.0382e+00,\n","        -1.9206e+00, -1.6651e+00, -5.1195e-01, -2.6782e+00,  1.4468e-01,\n","        -1.9469e-01,  1.2141e-01, -2.5685e+00, -5.7937e-01,  7.5873e-01,\n","         2.5281e+00,  9.3286e-01, -4.3338e-01,  6.2371e-01, -2.2915e-01,\n","         5.8629e-01,  1.4477e+00, -1.3028e-01,  7.1082e-01,  2.3418e+00,\n","         1.4769e-01,  8.9332e-01,  4.0509e-01, -2.3103e-01,  2.3249e+00,\n","         1.5841e-01], grad_fn=<SqueezeBackward1>)\n","\n","Word: 가격\n","tensor([-0.3063,  1.0994, -0.5403,  0.8915, -1.0864, -0.2640, -0.9058, -0.6679,\n","         0.6230, -0.7134, -0.8991, -1.1144, -2.4695, -0.1815,  1.2402,  1.8343,\n","         0.3931, -0.5312,  0.1620,  0.9837,  0.4912, -1.2603, -0.0581, -0.9937,\n","         0.1904,  1.5459,  0.5447, -0.2391, -0.3365, -0.4990,  0.0678, -0.1075,\n","         0.7230,  1.0546, -2.4331,  1.2673, -0.4945,  0.2317, -1.6047,  0.0798,\n","        -1.4358,  0.0492,  0.3416, -0.8139,  1.0167,  1.3023, -0.3695,  0.0659,\n","        -0.6078,  2.2887, -1.3332,  0.9932,  1.0141, -0.7476, -0.4679,  0.1778,\n","        -0.4769, -1.5969, -0.3779,  0.8782, -1.3913, -0.7712,  1.4588,  1.2520,\n","         0.2645, -0.0450, -1.0037,  0.7994,  0.5325,  0.6833, -0.1737, -0.7073,\n","        -1.3937,  0.8092,  1.2097,  0.3514, -1.8954,  0.4434,  1.5182, -1.0293,\n","         0.7500,  0.3061, -1.5760,  1.1036, -1.2597,  0.2644,  1.2019,  1.9719,\n","         2.2069, -1.2150, -0.8624,  0.8501,  1.3100,  0.3772,  0.5732,  0.3747,\n","         0.1180, -0.9745,  1.2751, -1.1790, -0.3031,  0.6708, -2.0104, -0.0639,\n","        -0.1046, -0.8522,  1.9984,  1.3739,  0.7133,  1.1703, -0.0832,  0.7064,\n","         0.1147,  0.9529, -1.2268,  0.6685,  0.3417, -1.8078, -0.6349, -0.2183,\n","         2.3832,  0.6304,  0.8688, -1.0336,  0.0601, -0.4161, -1.1730, -0.4272,\n","        -0.7054, -0.8253,  0.0893,  0.7678, -0.8013, -0.8586,  0.2944, -0.8206,\n","        -0.3780, -1.2713,  0.3374, -0.4382,  0.5277,  0.2135, -0.5837, -0.2060,\n","         0.9249, -0.8690,  0.3840,  1.0453,  1.4539,  0.8890, -0.7071, -0.4025,\n","         0.1229,  1.8758, -1.6923,  0.4280, -0.6983,  0.6309, -1.5908,  0.4152,\n","         0.2943, -1.3093,  0.1855, -0.9081,  0.1580,  0.3244, -0.5975, -0.9035,\n","        -0.1410,  0.8568,  2.3733, -0.6237,  0.9555,  0.2577, -4.1147,  1.4826,\n","        -0.8040,  1.1924,  0.0882,  0.1088,  2.0661, -0.3287,  1.0714, -0.8797,\n","        -0.2504, -1.7767,  0.1336, -0.6787, -0.8619, -1.5442, -0.4451,  0.0403,\n","         0.5465,  0.1819,  0.3952,  1.0478,  0.6251,  1.4378,  0.3013,  0.2156,\n","        -0.1286, -1.3088,  1.5283,  0.3158, -0.5359, -1.0104, -0.4311, -0.9168,\n","        -0.5997, -1.0686, -0.3444,  0.7202, -0.7562, -0.9842,  1.5677, -2.0656,\n","         0.2649,  1.4348, -0.4441,  0.2311, -0.5706, -0.8323, -0.0358, -0.7566,\n","         1.2309, -0.2107, -0.1585, -0.7608,  0.9092, -0.4555,  1.4398,  1.8192,\n","        -0.1934, -0.1043, -0.0443,  2.1683, -1.1002,  0.6062, -0.2465,  0.9631,\n","         0.2623,  0.3821, -1.0334,  0.4004, -0.1489, -0.1977,  1.2680, -0.6520,\n","         0.2362,  2.8389, -2.0137, -0.5954, -0.7468,  0.7074, -0.3071,  0.0665],\n","       grad_fn=<SqueezeBackward1>)\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5TgTFygyzRka","executionInfo":{"status":"ok","timestamp":1630943468692,"user_tz":-540,"elapsed":449,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"3d4b23a4-1604-491c-81ce-00f66f8b8316"},"source":["for word in test_words:\n","    input_id = torch.LongTensor([w2i[word]]).to(device)\n","    emb = skipgram.embedding(input_id)\n","\n","    print(f\"Word: {word}\")\n","    print(max(emb.squeeze(0)))\n","    print()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Word: 음식\n","tensor(4.1343, grad_fn=<UnbindBackward>)\n","\n","Word: 맛\n","tensor(2.7054, grad_fn=<UnbindBackward>)\n","\n","Word: 서비스\n","tensor(2.6690, grad_fn=<UnbindBackward>)\n","\n","Word: 위생\n","tensor(2.6545, grad_fn=<UnbindBackward>)\n","\n","Word: 가격\n","tensor(2.9495, grad_fn=<UnbindBackward>)\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"vaBFTWBbz6GV"},"source":["<br>\n","\n","## 2.7 notebook to pdf"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0TlWJYbbzlgL","executionInfo":{"status":"ok","timestamp":1630943564720,"user_tz":-540,"elapsed":57031,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"3f5065af-25fe-4a68-c028-39bc0fc994bf"},"source":["!apt-get install -qq texlive texlive-xetex texlive-latex-extra pandoc\n","!pip install -qq pypandoc"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracting templates from packages: 100%\n","Preconfiguring packages ...\n","Selecting previously unselected package fonts-droid-fallback.\n","(Reading database ... 148492 files and directories currently installed.)\n","Preparing to unpack .../00-fonts-droid-fallback_1%3a6.0.1r16-1.1_all.deb ...\n","Unpacking fonts-droid-fallback (1:6.0.1r16-1.1) ...\n","Selecting previously unselected package fonts-lato.\n","Preparing to unpack .../01-fonts-lato_2.0-2_all.deb ...\n","Unpacking fonts-lato (2.0-2) ...\n","Selecting previously unselected package poppler-data.\n","Preparing to unpack .../02-poppler-data_0.4.8-2_all.deb ...\n","Unpacking poppler-data (0.4.8-2) ...\n","Selecting previously unselected package tex-common.\n","Preparing to unpack .../03-tex-common_6.09_all.deb ...\n","Unpacking tex-common (6.09) ...\n","Selecting previously unselected package fonts-lmodern.\n","Preparing to unpack .../04-fonts-lmodern_2.004.5-3_all.deb ...\n","Unpacking fonts-lmodern (2.004.5-3) ...\n","Selecting previously unselected package fonts-noto-mono.\n","Preparing to unpack .../05-fonts-noto-mono_20171026-2_all.deb ...\n","Unpacking fonts-noto-mono (20171026-2) ...\n","Selecting previously unselected package fonts-texgyre.\n","Preparing to unpack .../06-fonts-texgyre_20160520-1_all.deb ...\n","Unpacking fonts-texgyre (20160520-1) ...\n","Selecting previously unselected package javascript-common.\n","Preparing to unpack .../07-javascript-common_11_all.deb ...\n","Unpacking javascript-common (11) ...\n","Selecting previously unselected package libcupsfilters1:amd64.\n","Preparing to unpack .../08-libcupsfilters1_1.20.2-0ubuntu3.1_amd64.deb ...\n","Unpacking libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n","Selecting previously unselected package libcupsimage2:amd64.\n","Preparing to unpack .../09-libcupsimage2_2.2.7-1ubuntu2.8_amd64.deb ...\n","Unpacking libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n","Selecting previously unselected package libijs-0.35:amd64.\n","Preparing to unpack .../10-libijs-0.35_0.35-13_amd64.deb ...\n","Unpacking libijs-0.35:amd64 (0.35-13) ...\n","Selecting previously unselected package libjbig2dec0:amd64.\n","Preparing to unpack .../11-libjbig2dec0_0.13-6_amd64.deb ...\n","Unpacking libjbig2dec0:amd64 (0.13-6) ...\n","Selecting previously unselected package libgs9-common.\n","Preparing to unpack .../12-libgs9-common_9.26~dfsg+0-0ubuntu0.18.04.14_all.deb ...\n","Unpacking libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n","Selecting previously unselected package libgs9:amd64.\n","Preparing to unpack .../13-libgs9_9.26~dfsg+0-0ubuntu0.18.04.14_amd64.deb ...\n","Unpacking libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n","Selecting previously unselected package libjs-jquery.\n","Preparing to unpack .../14-libjs-jquery_3.2.1-1_all.deb ...\n","Unpacking libjs-jquery (3.2.1-1) ...\n","Selecting previously unselected package libkpathsea6:amd64.\n","Preparing to unpack .../15-libkpathsea6_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n","Unpacking libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n","Selecting previously unselected package libpotrace0.\n","Preparing to unpack .../16-libpotrace0_1.14-2_amd64.deb ...\n","Unpacking libpotrace0 (1.14-2) ...\n","Selecting previously unselected package libptexenc1:amd64.\n","Preparing to unpack .../17-libptexenc1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n","Unpacking libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n","Selecting previously unselected package rubygems-integration.\n","Preparing to unpack .../18-rubygems-integration_1.11_all.deb ...\n","Unpacking rubygems-integration (1.11) ...\n","Selecting previously unselected package ruby2.5.\n","Preparing to unpack .../19-ruby2.5_2.5.1-1ubuntu1.10_amd64.deb ...\n","Unpacking ruby2.5 (2.5.1-1ubuntu1.10) ...\n","Selecting previously unselected package ruby.\n","Preparing to unpack .../20-ruby_1%3a2.5.1_amd64.deb ...\n","Unpacking ruby (1:2.5.1) ...\n","Selecting previously unselected package rake.\n","Preparing to unpack .../21-rake_12.3.1-1ubuntu0.1_all.deb ...\n","Unpacking rake (12.3.1-1ubuntu0.1) ...\n","Selecting previously unselected package ruby-did-you-mean.\n","Preparing to unpack .../22-ruby-did-you-mean_1.2.0-2_all.deb ...\n","Unpacking ruby-did-you-mean (1.2.0-2) ...\n","Selecting previously unselected package ruby-minitest.\n","Preparing to unpack .../23-ruby-minitest_5.10.3-1_all.deb ...\n","Unpacking ruby-minitest (5.10.3-1) ...\n","Selecting previously unselected package ruby-net-telnet.\n","Preparing to unpack .../24-ruby-net-telnet_0.1.1-2_all.deb ...\n","Unpacking ruby-net-telnet (0.1.1-2) ...\n","Selecting previously unselected package ruby-power-assert.\n","Preparing to unpack .../25-ruby-power-assert_0.3.0-1_all.deb ...\n","Unpacking ruby-power-assert (0.3.0-1) ...\n","Selecting previously unselected package ruby-test-unit.\n","Preparing to unpack .../26-ruby-test-unit_3.2.5-1_all.deb ...\n","Unpacking ruby-test-unit (3.2.5-1) ...\n","Selecting previously unselected package libruby2.5:amd64.\n","Preparing to unpack .../27-libruby2.5_2.5.1-1ubuntu1.10_amd64.deb ...\n","Unpacking libruby2.5:amd64 (2.5.1-1ubuntu1.10) ...\n","Selecting previously unselected package libsynctex1:amd64.\n","Preparing to unpack .../28-libsynctex1_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n","Unpacking libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n","Selecting previously unselected package libtexlua52:amd64.\n","Preparing to unpack .../29-libtexlua52_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n","Unpacking libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n","Selecting previously unselected package libtexluajit2:amd64.\n","Preparing to unpack .../30-libtexluajit2_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n","Unpacking libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n","Selecting previously unselected package libzzip-0-13:amd64.\n","Preparing to unpack .../31-libzzip-0-13_0.13.62-3.1ubuntu0.18.04.1_amd64.deb ...\n","Unpacking libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n","Selecting previously unselected package lmodern.\n","Preparing to unpack .../32-lmodern_2.004.5-3_all.deb ...\n","Unpacking lmodern (2.004.5-3) ...\n","Selecting previously unselected package preview-latex-style.\n","Preparing to unpack .../33-preview-latex-style_11.91-1ubuntu1_all.deb ...\n","Unpacking preview-latex-style (11.91-1ubuntu1) ...\n","Selecting previously unselected package t1utils.\n","Preparing to unpack .../34-t1utils_1.41-2_amd64.deb ...\n","Unpacking t1utils (1.41-2) ...\n","Selecting previously unselected package tex-gyre.\n","Preparing to unpack .../35-tex-gyre_20160520-1_all.deb ...\n","Unpacking tex-gyre (20160520-1) ...\n","Selecting previously unselected package texlive-binaries.\n","Preparing to unpack .../36-texlive-binaries_2017.20170613.44572-8ubuntu0.1_amd64.deb ...\n","Unpacking texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n","Selecting previously unselected package texlive-base.\n","Preparing to unpack .../37-texlive-base_2017.20180305-1_all.deb ...\n","Unpacking texlive-base (2017.20180305-1) ...\n","Selecting previously unselected package texlive-fonts-recommended.\n","Preparing to unpack .../38-texlive-fonts-recommended_2017.20180305-1_all.deb ...\n","Unpacking texlive-fonts-recommended (2017.20180305-1) ...\n","Selecting previously unselected package texlive-latex-base.\n","Preparing to unpack .../39-texlive-latex-base_2017.20180305-1_all.deb ...\n","Unpacking texlive-latex-base (2017.20180305-1) ...\n","Selecting previously unselected package texlive-latex-recommended.\n","Preparing to unpack .../40-texlive-latex-recommended_2017.20180305-1_all.deb ...\n","Unpacking texlive-latex-recommended (2017.20180305-1) ...\n","Selecting previously unselected package texlive.\n","Preparing to unpack .../41-texlive_2017.20180305-1_all.deb ...\n","Unpacking texlive (2017.20180305-1) ...\n","Selecting previously unselected package texlive-pictures.\n","Preparing to unpack .../42-texlive-pictures_2017.20180305-1_all.deb ...\n","Unpacking texlive-pictures (2017.20180305-1) ...\n","Selecting previously unselected package texlive-latex-extra.\n","Preparing to unpack .../43-texlive-latex-extra_2017.20180305-2_all.deb ...\n","Unpacking texlive-latex-extra (2017.20180305-2) ...\n","Selecting previously unselected package texlive-plain-generic.\n","Preparing to unpack .../44-texlive-plain-generic_2017.20180305-2_all.deb ...\n","Unpacking texlive-plain-generic (2017.20180305-2) ...\n","Selecting previously unselected package tipa.\n","Preparing to unpack .../45-tipa_2%3a1.3-20_all.deb ...\n","Unpacking tipa (2:1.3-20) ...\n","Selecting previously unselected package texlive-xetex.\n","Preparing to unpack .../46-texlive-xetex_2017.20180305-1_all.deb ...\n","Unpacking texlive-xetex (2017.20180305-1) ...\n","Setting up libgs9-common (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n","Setting up libkpathsea6:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n","Setting up libjs-jquery (3.2.1-1) ...\n","Setting up libtexlua52:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n","Setting up fonts-droid-fallback (1:6.0.1r16-1.1) ...\n","Setting up libsynctex1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n","Setting up libptexenc1:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n","Setting up tex-common (6.09) ...\n","update-language: texlive-base not installed and configured, doing nothing!\n","Setting up poppler-data (0.4.8-2) ...\n","Setting up tex-gyre (20160520-1) ...\n","Setting up preview-latex-style (11.91-1ubuntu1) ...\n","Setting up fonts-texgyre (20160520-1) ...\n","Setting up fonts-noto-mono (20171026-2) ...\n","Setting up fonts-lato (2.0-2) ...\n","Setting up libcupsfilters1:amd64 (1.20.2-0ubuntu3.1) ...\n","Setting up libcupsimage2:amd64 (2.2.7-1ubuntu2.8) ...\n","Setting up libjbig2dec0:amd64 (0.13-6) ...\n","Setting up ruby-did-you-mean (1.2.0-2) ...\n","Setting up t1utils (1.41-2) ...\n","Setting up ruby-net-telnet (0.1.1-2) ...\n","Setting up libijs-0.35:amd64 (0.35-13) ...\n","Setting up rubygems-integration (1.11) ...\n","Setting up libpotrace0 (1.14-2) ...\n","Setting up javascript-common (11) ...\n","Setting up ruby-minitest (5.10.3-1) ...\n","Setting up libzzip-0-13:amd64 (0.13.62-3.1ubuntu0.18.04.1) ...\n","Setting up libgs9:amd64 (9.26~dfsg+0-0ubuntu0.18.04.14) ...\n","Setting up libtexluajit2:amd64 (2017.20170613.44572-8ubuntu0.1) ...\n","Setting up fonts-lmodern (2.004.5-3) ...\n","Setting up ruby-power-assert (0.3.0-1) ...\n","Setting up texlive-binaries (2017.20170613.44572-8ubuntu0.1) ...\n","update-alternatives: using /usr/bin/xdvi-xaw to provide /usr/bin/xdvi.bin (xdvi.bin) in auto mode\n","update-alternatives: using /usr/bin/bibtex.original to provide /usr/bin/bibtex (bibtex) in auto mode\n","Setting up texlive-base (2017.20180305-1) ...\n","mktexlsr: Updating /var/lib/texmf/ls-R-TEXLIVEDIST... \n","mktexlsr: Updating /var/lib/texmf/ls-R-TEXMFMAIN... \n","mktexlsr: Updating /var/lib/texmf/ls-R... \n","mktexlsr: Done.\n","tl-paper: setting paper size for dvips to a4: /var/lib/texmf/dvips/config/config-paper.ps\n","tl-paper: setting paper size for dvipdfmx to a4: /var/lib/texmf/dvipdfmx/dvipdfmx-paper.cfg\n","tl-paper: setting paper size for xdvi to a4: /var/lib/texmf/xdvi/XDvi-paper\n","tl-paper: setting paper size for pdftex to a4: /var/lib/texmf/tex/generic/config/pdftexconfig.tex\n","Setting up texlive-fonts-recommended (2017.20180305-1) ...\n","Setting up texlive-plain-generic (2017.20180305-2) ...\n","Setting up texlive-latex-base (2017.20180305-1) ...\n","Setting up lmodern (2.004.5-3) ...\n","Setting up texlive-latex-recommended (2017.20180305-1) ...\n","Setting up texlive-pictures (2017.20180305-1) ...\n","Setting up tipa (2:1.3-20) ...\n","Regenerating '/var/lib/texmf/fmtutil.cnf-DEBIAN'... done.\n","Regenerating '/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST'... done.\n","update-fmtutil has updated the following file(s):\n","\t/var/lib/texmf/fmtutil.cnf-DEBIAN\n","\t/var/lib/texmf/fmtutil.cnf-TEXLIVEDIST\n","If you want to activate the changes in the above file(s),\n","you should run fmtutil-sys or fmtutil.\n","Setting up texlive (2017.20180305-1) ...\n","Setting up texlive-latex-extra (2017.20180305-2) ...\n","Setting up texlive-xetex (2017.20180305-1) ...\n","Setting up ruby2.5 (2.5.1-1ubuntu1.10) ...\n","Setting up ruby (1:2.5.1) ...\n","Setting up ruby-test-unit (3.2.5-1) ...\n","Setting up rake (12.3.1-1ubuntu0.1) ...\n","Setting up libruby2.5:amd64 (2.5.1-1ubuntu1.10) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n","Processing triggers for tex-common (6.09) ...\n","Running updmap-sys. This may take some time... done.\n","Running mktexlsr /var/lib/texmf ... done.\n","Building format(s) --all.\n","\tThis may take some time... done.\n","  Building wheel for pypandoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K83w5bfW0C08","executionInfo":{"status":"ok","timestamp":1630943614972,"user_tz":-540,"elapsed":4399,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"fba10d84-2e1f-4716-c0ad-31ee5ead06d9"},"source":["!jupyter nbconvert --to PDF '/content/drive/MyDrive/boostcamp/04_U-stage/004_NLP/02강 - Word Embedding.ipynb'"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[NbConvertApp] Converting notebook /content/drive/MyDrive/boostcamp/04_U-stage/004_NLP/02강 - Word Embedding.ipynb to PDF\n","[NbConvertApp] Writing 114350 bytes to ./notebook.tex\n","[NbConvertApp] Building PDF\n","[NbConvertApp] Running xelatex 3 times: [u'xelatex', u'./notebook.tex', '-quiet']\n","[NbConvertApp] CRITICAL | xelatex failed: [u'xelatex', u'./notebook.tex', '-quiet']\n","This is XeTeX, Version 3.14159265-2.6-0.99998 (TeX Live 2017/Debian) (preloaded format=xelatex)\n"," restricted \\write18 enabled.\n","entering extended mode\n","(./notebook.tex\n","LaTeX2e <2017-04-15>\n","Babel <3.18> and hyphenation patterns for 3 language(s) loaded.\n","(/usr/share/texlive/texmf-dist/tex/latex/base/article.cls\n","Document Class: article 2014/09/29 v1.4h Standard LaTeX document class\n","(/usr/share/texlive/texmf-dist/tex/latex/base/size11.clo))\n","(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcolorbox.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgf.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/pgf/utilities/pgfrcs.sty\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common.tex\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-common-lists.t\n","ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfutil-latex.def\n","(/usr/share/texlive/texmf-dist/tex/latex/ms/everyshi.sty))\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfrcs.code.tex))\n","(/usr/share/texlive/texmf-dist/tex/latex/pgf/basiclayer/pgfcore.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphicx.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/graphics/keyval.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/graphics/graphics.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/graphics/trig.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/graphics.cfg)\n","(/usr/share/texlive/texmf-dist/tex/latex/graphics-def/xetex.def)))\n","(/usr/share/texlive/texmf-dist/tex/latex/pgf/systemlayer/pgfsys.sty\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys.code.tex\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeys.code.tex\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/utilities/pgfkeysfiltered.code.t\n","ex)) (/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgf.cfg)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-xetex.def\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-dvipdfmx.def\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsys-common-pdf.de\n","f))))\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsyssoftpath.code.\n","tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/systemlayer/pgfsysprotocol.code.\n","tex)) (/usr/share/texlive/texmf-dist/tex/latex/xcolor/xcolor.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/graphics-cfg/color.cfg))\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcore.code.tex\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmath.code.tex\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathcalc.code.tex\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathutil.code.tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathparser.code.tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.code.tex\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.basic.code\n",".tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.trigonomet\n","ric.code.tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.random.cod\n","e.tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.comparison\n",".code.tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.base.code.\n","tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.round.code\n",".tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.misc.code.\n","tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfunctions.integerari\n","thmetics.code.tex)))\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/math/pgfmathfloat.code.tex))\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepoints.code.te\n","x)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathconstruct.\n","code.tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathusage.code\n",".tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorescopes.code.te\n","x)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoregraphicstate.c\n","ode.tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransformation\n","s.code.tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorequick.code.tex\n",")\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreobjects.code.t\n","ex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepathprocessing\n",".code.tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorearrows.code.te\n","x)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreshade.code.tex\n",")\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreimage.code.tex\n","\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoreexternal.code.\n","tex))\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorelayers.code.te\n","x)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcoretransparency.c\n","ode.tex)\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/basiclayer/pgfcorepatterns.code.\n","tex)))\n","(/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleshapes.code.tex\n",") (/usr/share/texlive/texmf-dist/tex/generic/pgf/modules/pgfmoduleplot.code.tex\n",")\n","(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-0-65\n",".sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/pgf/compatibility/pgfcomp-version-1-18\n",".sty)) (/usr/share/texlive/texmf-dist/tex/latex/tools/verbatim.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/environ/environ.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/trimspaces/trimspaces.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/etoolbox/etoolbox.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/tcolorbox/tcbbreakable.code.tex\n","Library (tcolorbox): 'tcbbreakable.code.tex' version '4.12'\n",")) (/usr/share/texlive/texmf-dist/tex/latex/float/float.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/base/fontenc.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/base/t1enc.def)\n","(/usr/share/texmf/tex/latex/lm/t1lmr.fd))\n","(/usr/share/texlive/texmf-dist/tex/latex/psnfss/mathpazo.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/caption/caption.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/caption/caption3.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjustbox.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/xkeyval/xkeyval.sty\n","(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkeyval.tex\n","(/usr/share/texlive/texmf-dist/tex/generic/xkeyval/xkvutils.tex)))\n","(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/adjcalc.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/trimclip.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/collectbox/collectbox.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/adjustbox/tc-xetex.def))\n","(/usr/share/texlive/texmf-dist/tex/latex/ifoddpage/ifoddpage.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/varwidth/varwidth.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/tools/enumerate.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/geometry/geometry.sty\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifpdf.sty)\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifvtex.sty)\n","(/usr/share/texlive/texmf-dist/tex/generic/ifxetex/ifxetex.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsmath.sty\n","For additional information on amsmath, use the `?' option.\n","(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amstext.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsgen.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsbsy.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/amsmath/amsopn.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amssymb.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/amsfonts/amsfonts.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/base/textcomp.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/base/ts1enc.def))\n","(/usr/share/texlive/texmf-dist/tex/latex/upquote/upquote.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/eurosym/eurosym.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucs.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/ucs/data/uni-global.def))\n","(/usr/share/texlive/texmf-dist/tex/latex/base/inputenc.sty\n","\n","Package inputenc Warning: inputenc package ignored with utf8 based engines.\n","\n",") (/usr/share/texlive/texmf-dist/tex/latex/fancyvrb/fancyvrb.sty\n","Style option: `fancyvrb' v2.7a, with DG/SPQR fixes, and firstline=lastline fix \n","<2008/02/07> (tvz))\n","(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/grffile.sty\n","(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/kvoptions.sty\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ltxcmds.sty)\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/kvsetkeys.sty\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/infwarerr.sty)\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/etexcmds.sty\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/ifluatex.sty))))\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/pdftexcmds.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hyperref.sty\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-hyperref.sty\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/hobsub-generic.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/auxhook.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/hyperref/pd1enc.def)\n","(/usr/share/texlive/texmf-dist/tex/latex/latexconfig/hyperref.cfg)\n","(/usr/share/texlive/texmf-dist/tex/latex/url/url.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/hyperref/hxetex.def\n","(/usr/share/texlive/texmf-dist/tex/latex/hyperref/puenc.def)\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/stringenc.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/oberdiek/rerunfilecheck.sty))\n","(/usr/share/texlive/texmf-dist/tex/latex/tools/longtable.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/booktabs/booktabs.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/enumitem/enumitem.sty)\n","(/usr/share/texlive/texmf-dist/tex/generic/ulem/ulem.sty)\n","(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/mathrsfs.sty)\n","No file notebook.aux.\n","(/usr/share/texlive/texmf-dist/tex/latex/base/ts1cmr.fd)\n","(/usr/share/texlive/texmf-dist/tex/latex/psnfss/t1ppl.fd)\n","ABD: EveryShipout initializing macros\n","(/usr/share/texlive/texmf-dist/tex/latex/caption/ltcaption.sty)\n","*geometry* driver: auto-detecting\n","*geometry* detected driver: xetex\n","*geometry* verbose mode - [ preamble ] result:\n","* driver: xetex\n","* paper: <default>\n","* layout: <same size as paper>\n","* layoutoffset:(h,v)=(0.0pt,0.0pt)\n","* modes: \n","* h-part:(L,W,R)=(72.26999pt, 469.75502pt, 72.26999pt)\n","* v-part:(T,H,B)=(72.26999pt, 650.43001pt, 72.26999pt)\n","* \\paperwidth=614.295pt\n","* \\paperheight=794.96999pt\n","* \\textwidth=469.75502pt\n","* \\textheight=650.43001pt\n","* \\oddsidemargin=0.0pt\n","* \\evensidemargin=0.0pt\n","* \\topmargin=-37.0pt\n","* \\headheight=12.0pt\n","* \\headsep=25.0pt\n","* \\topskip=11.0pt\n","* \\footskip=30.0pt\n","* \\marginparwidth=59.0pt\n","* \\marginparsep=10.0pt\n","* \\columnsep=10.0pt\n","* \\skip\\footins=10.0pt plus 4.0pt minus 2.0pt\n","* \\hoffset=0.0pt\n","* \\voffset=0.0pt\n","* \\mag=1000\n","* \\@twocolumnfalse\n","* \\@twosidefalse\n","* \\@mparswitchfalse\n","* \\@reversemarginfalse\n","* (1in=72.27pt=25.4mm, 1cm=28.453pt)\n","\n","(/usr/share/texlive/texmf-dist/tex/latex/ucs/ucsencs.def)\n","(/usr/share/texlive/texmf-dist/tex/latex/hyperref/nameref.sty\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/gettitlestring.sty))\n","\n","Package hyperref Warning: Rerun to get /PageLabels entry.\n","\n","(/usr/share/texlive/texmf-dist/tex/latex/psnfss/ot1ppl.fd)\n","(/usr/share/texlive/texmf-dist/tex/latex/psnfss/omlzplm.fd)\n","(/usr/share/texlive/texmf-dist/tex/latex/psnfss/omszplm.fd)\n","(/usr/share/texlive/texmf-dist/tex/latex/psnfss/omxzplm.fd)\n","(/usr/share/texlive/texmf-dist/tex/latex/psnfss/ot1zplm.fd)\n","(/usr/share/texlive/texmf-dist/tex/latex/jknapltx/ursfs.fd)\n","\n","LaTeX Warning: No \\author given.\n","\n","(/usr/share/texlive/texmf-dist/tex/generic/oberdiek/se-ascii-print.def)\n","(/usr/share/texlive/texmf-dist/tex/latex/psnfss/ts1ppl.fd) [1]\n","Underfull \\hbox (badness 10000) in paragraph at lines 541--544\n","\n","(/usr/share/texmf/tex/latex/lm/t1lmtt.fd) [2] [3] [4] [5] [6]\n","Underfull \\hbox (badness 10000) in paragraph at lines 982--984\n","\n","[7] (/usr/share/texmf/tex/latex/lm/ts1lmtt.fd) [8] [9] [10] [11]\n","Underfull \\hbox (badness 10000) in paragraph at lines 1313--1315\n","\n","[12] [13] [14]\n","! FancyVerb Error:\n","  Empty verbatim environment\n",".\n","\\FV@Error ...ncyVerb Error:^^J\\space \\space #1^^J}\n","                                                  \n","l.1530 ... [00:00<00:00, 712.05it/s]\\end{Verbatim}\n","                                                  \n","? \n","! Emergency stop.\n","\\FV@Error ...ncyVerb Error:^^J\\space \\space #1^^J}\n","                                                  \n","l.1530 ... [00:00<00:00, 712.05it/s]\\end{Verbatim}\n","                                                  \n","Output written on notebook.pdf (14 pages).\n","Transcript written on notebook.log.\n","\n","[NbConvertApp] PDF successfully created\n","[NbConvertApp] Writing 62391 bytes to /content/drive/MyDrive/boostcamp/04_U-stage/004_NLP/02강 - Word Embedding.pdf\n"]}]},{"cell_type":"code","metadata":{"id":"1caD93k70ISk"},"source":[""],"execution_count":null,"outputs":[]}]}