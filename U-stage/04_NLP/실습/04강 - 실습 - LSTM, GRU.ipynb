{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"04강 - 실습 - LSTM, GRU.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNm/KBI8ddMf8mL2SenmazQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"qADqUfuzBqRu"},"source":["# 4 실습: LSTM, GRU\n","\n","1. 기존 RNN 과 다른 부분에 대해서 배운다.\n","2. 이전 실습에 이어 다양한 적용법을 배운다."]},{"cell_type":"markdown","metadata":{"id":"fCMxjHBeYK-O"},"source":["<br>\n","\n","## 4.1 필요 패키지 import"]},{"cell_type":"code","metadata":{"id":"GuogJwMpYNgc"},"source":["from tqdm import tqdm\n","from torch import nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","import torch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f3mJ1BsiYPee"},"source":["<br>\n","\n","## 4.2 데이터 전처리\n","\n","- 아래의 sample data 를 확인해보자. (이전 실습과 동일)"]},{"cell_type":"code","metadata":{"id":"b4Qdw2pSYUo1"},"source":["vocab_size = 100\n","pad_id = 0\n","\n","data = [\n","  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\n","  [62,76,79,66,32],\n","  [93,77,16,67,46,74,24,70],\n","  [19,83,88,22,57,40,75,82,4,46],\n","  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\n","  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\n","  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\n","  [94,21,79,24,3,86],\n","  [80,80,33,63,34,63],\n","  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kXz8gKRTYV8s","executionInfo":{"status":"ok","timestamp":1631070552147,"user_tz":-540,"elapsed":351,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"c484e45b-4f45-4879-cede-ab12e3180e85"},"source":["max_len = len(max(data, key=len))\n","print(f\"Maximum sequence length: {max_len}\")\n","\n","valid_lens = []\n","for i, seq in enumerate(tqdm(data)):\n","  valid_lens.append(len(seq))\n","  if len(seq) < max_len:\n","    data[i] = seq + [pad_id] * (max_len - len(seq))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum sequence length: 20\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 35335.33it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdNAMmj9YXzs","executionInfo":{"status":"ok","timestamp":1631070568716,"user_tz":-540,"elapsed":442,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"2c3337ac-9654-436b-ebd7-adb64f73b9f5"},"source":["# B: batch size, L: maximum sequence length\n","batch = torch.LongTensor(data)  # (B, L)\n","batch_lens = torch.LongTensor(valid_lens)  # (B)\n","\n","batch_lens, sorted_idx = batch_lens.sort(descending=True)\n","batch = batch[sorted_idx]\n","\n","print(batch)\n","print(batch_lens)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n","         74, 13],\n","        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n","          0,  0],\n","        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n","          0,  0],\n","        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n","          0,  0],\n","        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n","          0,  0],\n","        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0],\n","        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0]])\n","tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"]}]},{"cell_type":"markdown","metadata":{"id":"qXPak3qFYb0k"},"source":["<br>\n","\n","## 4.3 LSTM 사용\n","\n","- LSTM 에선 cell state 가 추가된다.\n","- cell state 의 shape 은 hidden state 의 shape 과 동일하다."]},{"cell_type":"code","metadata":{"id":"SU_PatzWYkpx"},"source":["embedding_size = 256\n","hidden_size = 512\n","num_layers = 1\n","num_dirs = 1\n","\n","embedding = nn.Embedding(vocab_size, embedding_size)\n","lstm = nn.LSTM(\n","    input_size=embedding_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    bidirectional=True if num_dirs > 1 else False\n",")\n","\n","h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size)) # (num_layers * num_dirs, B, d_h)\n","c_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size)) # (num_layers * num_dirs, B, d_h)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mDsZqXa8ZGfI","executionInfo":{"status":"ok","timestamp":1631070776768,"user_tz":-540,"elapsed":335,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"ee51a5b9-34fa-42ca-c831-4e2c24644529"},"source":["# d_w: word embedding size\n","batch_emb = embedding(batch) # (B, L, d_w)\n","batch_emb.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([10, 20, 256])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KqG0xnaoZOiu","executionInfo":{"status":"ok","timestamp":1631070883283,"user_tz":-540,"elapsed":769,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"a05618ae-cf2a-4cca-b677-6ee9c4839cb2"},"source":["packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n","\n","packed_outputs, (h_n, c_n) = lstm(packed_batch, (h_0, c_0))\n","print(packed_outputs)\n","print(packed_outputs[0].shape)\n","print(h_n.shape)\n","print(c_n.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PackedSequence(data=tensor([[ 0.0349, -0.0717, -0.0494,  ..., -0.1301,  0.0156, -0.0285],\n","        [ 0.0039, -0.0848, -0.1199,  ..., -0.0234,  0.1441,  0.0354],\n","        [ 0.0924,  0.0439, -0.0758,  ...,  0.0022,  0.0554,  0.0257],\n","        ...,\n","        [-0.1049,  0.0285,  0.1007,  ..., -0.1961, -0.0256,  0.0783],\n","        [-0.0058, -0.0997, -0.0244,  ...,  0.1517,  0.2395,  0.0274],\n","        [-0.0137,  0.1824, -0.2192,  ...,  0.1396,  0.1369,  0.0427]],\n","       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n","         1,  1]), sorted_indices=None, unsorted_indices=None)\n","torch.Size([123, 512])\n","torch.Size([1, 10, 512])\n","torch.Size([1, 10, 512])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUTPh9oHZZXn","executionInfo":{"status":"ok","timestamp":1631070918433,"user_tz":-540,"elapsed":342,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"312b244a-a6f8-4518-ab61-f7c6b082fe55"},"source":["outputs, output_lens = pad_packed_sequence(packed_outputs)\n","print(outputs.shape)\n","print(output_lens)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 10, 512])\n","tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"]}]},{"cell_type":"markdown","metadata":{"id":"Bg4bOzzdZxLt"},"source":["<br>\n","\n","## 4.4 GRU 사용\n","\n","- GRU 는 cell state 가 없어 RNN 과 동일하게 사용 가능하다.\n","- GRU 를 이용하여 Language Model task 를 수행해보자."]},{"cell_type":"code","metadata":{"id":"9G3ChG87Z8yl"},"source":["gru = nn.GRU(\n","    input_size=embedding_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    bidirectional=True if num_dirs > 1 else False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"axEHWAJ_aImd"},"source":["output_layer = nn.Linear(hidden_size, vocab_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UzjzohNjaMea","executionInfo":{"status":"ok","timestamp":1631071452075,"user_tz":-540,"elapsed":5,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"610f7f29-61ed-4e55-dd4e-78a1dd6bfdcd"},"source":["input_id = batch.transpose(0, 1)[0, :] # B\n","input_id"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([85, 58, 87, 22, 70, 19, 93, 94, 80, 62])"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"J99UmGczaRff"},"source":["hidden = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))  # (1, B, d_h)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rANjLKawad0D"},"source":["<br>\n","\n","- Teacher forcing 없이 이전에 얻은 결과를 다음 input 으로 이용한다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGBo09y5aim0","executionInfo":{"status":"ok","timestamp":1631071453770,"user_tz":-540,"elapsed":398,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"8868880e-5292-48e6-ef82-2c653be148e8"},"source":["for t in range(max_len):\n","    input_emb = embedding(input_id).unsqueeze(0) # (1, B, d_w)\n","    output, hidden = gru(input_emb, hidden) # output: (1, B, d_h), hidden: (1, B, d_h)\n","\n","    # V: vocab size\n","    output = output_layer(output) # (1, B, V)\n","    probs, top_id = torch.max(output, dim=-1) # probs: (1, B), top_id: (1, B)\n","\n","    print(\"*\" * 50)\n","    print(f\"Time step: {t}\")\n","    print(output.shape)\n","    print(probs.shape)\n","    print(top_id.shape)\n","\n","    input_id = top_id.squeeze(0)  # (B)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["**************************************************\n","Time step: 0\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 1\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 2\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 3\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 4\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 5\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 6\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 7\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 8\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 9\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 10\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 11\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 12\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 13\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 14\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 15\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 16\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 17\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 18\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n","**************************************************\n","Time step: 19\n","torch.Size([1, 10, 100])\n","torch.Size([1, 10])\n","torch.Size([1, 10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"6k44VMErav-u"},"source":["<br>\n","\n","- `max_len` 만큼의 for문을 돌면서 모든 결과물의 모양을 확인했지만 만약 종료 조건(ex. 문장의 끝을 나타내는 end token 등)이 되면 중간에 생성을 그만둘수도 있다."]},{"cell_type":"markdown","metadata":{"id":"y77m7Hm2cELO"},"source":["<br>\n","\n","## 4.5 양방향 및 여러 layer 사용\n","\n","- 이번엔 양방향 + 2개 이상의 layer 를 쓸 때 얻을 수 있는 결과에 대해 알아보자."]},{"cell_type":"code","metadata":{"id":"3bYi3WoDcOpN"},"source":["num_layers = 2\n","num_dirs = 2\n","dropout = 1\n","\n","gru = nn.GRU(\n","    input_size=embedding_size,\n","    hidden_size=hidden_size,\n","    num_layers=num_layers,\n","    bidirectional=True if num_dirs > 1 else False\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pMgaOUjWcZqu"},"source":["<br>\n","\n","- Bidirectional 이 되었고 layer 의 개수가 2로 늘었기 때문에 hidden state 의 shape 도 `(4, B, d_h)` 가 된다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"39VomG90cizM","executionInfo":{"status":"ok","timestamp":1631071769461,"user_tz":-540,"elapsed":355,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"eb838e8d-c3e8-4355-d737-e2849656afa4"},"source":["# d_w: word embedding size\n","# num_layers: layer 의 개수\n","# num_dirs: 방향의 개수\n","\n","batch_emb = embedding(batch) # (B, L, d_w)\n","h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size)) # (num_layers * num_dirs, B, d_h) = (4, B, d_h)\n","\n","packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n","\n","packed_outputs, h_n = gru(packed_batch, h_0)\n","print(packed_outputs)\n","print(packed_outputs[0].shape)\n","print(h_n.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PackedSequence(data=tensor([[ 0.0406, -0.0119, -0.0071,  ..., -0.2520, -0.1993, -0.1060],\n","        [ 0.0410,  0.1082, -0.0604,  ..., -0.0563,  0.1071, -0.2233],\n","        [-0.0133,  0.1561, -0.0856,  ...,  0.2162,  0.0425, -0.0397],\n","        ...,\n","        [ 0.0271,  0.0700,  0.1165,  ...,  0.1129, -0.0277,  0.0016],\n","        [-0.1314, -0.0266,  0.0435,  ..., -0.1107,  0.0446, -0.0148],\n","        [-0.1458, -0.0240, -0.0314,  ..., -0.0883,  0.0723, -0.0078]],\n","       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n","         1,  1]), sorted_indices=None, unsorted_indices=None)\n","torch.Size([123, 1024])\n","torch.Size([4, 10, 512])\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1E8NWtddA9t","executionInfo":{"status":"ok","timestamp":1631071815690,"user_tz":-540,"elapsed":685,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"590a75aa-ff46-4731-b9ac-700de9e1739a"},"source":["outputs, output_lens = pad_packed_sequence(packed_outputs)\n","print(outputs.shape)  # (L, B, num_dirs*d_h)\n","print(output_lens)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([20, 10, 1024])\n","tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"]}]},{"cell_type":"markdown","metadata":{"id":"qzLfJcZEdMJu"},"source":["<br>\n","\n","- 각각의 결과물의 shape는 다음과 같습니다.\n","  - `outputs`: `(max_len, batch_size, num_dir * hidden_size)`  \n","  - `h_n`: `(num_layers*num_dirs, batch_size, hidden_size)`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KwA-O791dUTu","executionInfo":{"status":"ok","timestamp":1631071864848,"user_tz":-540,"elapsed":343,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"ad1b909a-458e-49af-fc7e-2874eb97865a"},"source":["batch_size = h_n.shape[1]\n","print(h_n.view(num_layers, num_dirs, batch_size, hidden_size))\n","print(h_n.view(num_layers, num_dirs, batch_size, hidden_size).shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[[-3.5023e-01, -1.1334e-01, -1.6157e-01,  ...,  4.5304e-01,\n","            1.8469e-01, -2.1680e-02],\n","          [-5.7206e-02,  1.3418e-01,  1.2187e-01,  ..., -2.0633e-01,\n","            1.1726e-01, -1.4778e-01],\n","          [ 7.1233e-02, -3.1554e-01,  1.7080e-01,  ..., -1.2315e-01,\n","           -1.9801e-01, -9.2919e-02],\n","          ...,\n","          [ 3.1512e-01, -4.1218e-01,  1.7909e-01,  ...,  3.0241e-01,\n","            4.4074e-01, -1.5008e-01],\n","          [ 7.7649e-02, -9.8056e-03, -4.0156e-01,  ..., -3.6668e-01,\n","           -2.1716e-01,  2.9913e-02],\n","          [ 3.1635e-01,  1.4461e-01,  2.2485e-02,  ..., -2.8990e-01,\n","            2.8460e-01,  1.2556e-01]],\n","\n","         [[-1.3612e-01,  4.7373e-01, -2.7130e-01,  ..., -8.1935e-02,\n","            6.3042e-02, -1.7000e-01],\n","          [-1.3340e-01, -8.0582e-02, -4.4041e-02,  ...,  9.3998e-02,\n","            1.4388e-02, -4.7930e-01],\n","          [-4.2317e-01,  2.9652e-03,  2.6890e-01,  ...,  5.4826e-01,\n","           -5.1891e-02,  1.4421e-01],\n","          ...,\n","          [-4.3826e-01, -3.6892e-01, -1.7546e-02,  ...,  2.3185e-01,\n","           -2.9758e-01,  3.5193e-02],\n","          [-2.7655e-01,  2.9856e-01, -3.5169e-01,  ...,  5.2367e-01,\n","            7.1478e-02,  1.1677e-01],\n","          [-7.9770e-02,  1.2265e-01,  1.0054e-01,  ...,  4.2211e-01,\n","           -3.1258e-01,  1.6398e-01]]],\n","\n","\n","        [[[-1.4577e-01, -2.3991e-02, -3.1371e-02,  ..., -1.0727e-01,\n","           -3.0092e-02,  1.0537e-01],\n","          [-1.1537e-01,  1.4037e-01, -5.0022e-02,  ...,  3.0432e-01,\n","            2.8238e-01, -1.0726e-01],\n","          [ 2.7074e-02,  6.9978e-02,  1.1645e-01,  ...,  2.5639e-01,\n","            1.7255e-01,  1.7138e-01],\n","          ...,\n","          [-1.6122e-01,  1.2233e-01, -9.1355e-02,  ...,  1.3678e-01,\n","            1.8951e-01, -1.7774e-01],\n","          [ 1.0184e-01,  3.9223e-02,  2.1989e-01,  ..., -2.2367e-01,\n","           -3.5066e-02,  8.6583e-02],\n","          [-1.0443e-01,  6.4534e-02,  2.8780e-02,  ..., -1.1094e-01,\n","            1.0426e-01, -1.5995e-01]],\n","\n","         [[-2.6773e-02,  6.5028e-02, -4.8612e-02,  ..., -2.5195e-01,\n","           -1.9934e-01, -1.0599e-01],\n","          [ 4.6888e-02,  1.0530e-01, -1.6998e-01,  ..., -5.6298e-02,\n","            1.0709e-01, -2.2335e-01],\n","          [-4.5292e-05,  5.0859e-02,  1.8960e-01,  ...,  2.1625e-01,\n","            4.2524e-02, -3.9720e-02],\n","          ...,\n","          [ 1.9644e-01, -6.5005e-02,  1.6599e-01,  ..., -2.6451e-03,\n","           -5.3266e-02, -2.0022e-01],\n","          [ 1.3763e-01,  1.9010e-01, -1.9523e-01,  ...,  8.9378e-02,\n","           -3.9387e-02, -6.1732e-03],\n","          [-1.2958e-01, -4.1955e-02, -6.3343e-02,  ...,  6.1822e-02,\n","            5.2204e-02, -1.0081e-01]]]], grad_fn=<ViewBackward>)\n","torch.Size([2, 2, 10, 512])\n"]}]},{"cell_type":"code","metadata":{"id":"mNEO5_AIdYTm"},"source":[""],"execution_count":null,"outputs":[]}]}