{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"05강 - Sequence to Sequence with Attention.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMlDX3R9jgGRKY4NNw+dAkr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"VFn3vrZVRZLI"},"source":["# 5. Sequence to Sequence with Attention"]},{"cell_type":"markdown","metadata":{"id":"LhVxkc4lReaL"},"source":["<br>\n","\n","## 강의 소개\n","\n","- Sequence를 Encoding와 Decoding할 수 있는 **sequence to sequence**에 대해 알아봅니다.\n","- **Sequence to sequence**는 encoder와 decoder로 이루어져 있는 framework으로 대표적인 자연어 처리 architecture 중 하나입니다. Encoder와 Decoder로는 다양한 알고리즘이 사용될 수 있지만 이번 시간에는 **RNN과 Attention**을 결합한 sequence to sequence 모델을 학습합니다.\n","- 앞선 강의에서 설명드렸던 것처럼 RNN 모델이 갖고 있는 단점을 보완하고자 **Attention**(논문에서는 alignment로 표현되고 있습니다) 기법이 처음 등장했습니다. 다양한 Attention의 종류와 이를 활용한 translation task에 대해서 알아봅니다"]},{"cell_type":"markdown","metadata":{"id":"ZTquC6PvZ7D8"},"source":["<br>\n","\n","## Further Reading\n","\n","- [Sequence to sequence learning with neural networks, ICML’14](https://arxiv.org/abs/1409.3215)\n","- [Effective Approaches to Attention-based Neural Machine Translation, EMNLP 2015](https://arxiv.org/abs/1508.04025)\n","- [CS224n(2019)_Lecture8_NMT](https://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture08-nmt.pdf)"]},{"cell_type":"markdown","metadata":{"id":"DX8pWNSdaGvD"},"source":["<br>\n","\n","## 5.1 Seq2seq Model\n","\n","- It takes a <font color='red'>sequence of words as input</font> and gives a <font color='red'>sequence of words as output</font>\n","- Seq2seq 모델은 RNN 의 구조 중 Many-to-many 에 해당한다.\n","- 입력 시퀀스를 모두 다 읽은 후 출력 시퀀스를 생성한다.\n","  - 입력과 출력 시퀀스 모두 단어 단위의 문장이다.\n","\n","<br>\n","\n","- It composed of an <font color='red'>**encoder**</font> and a <font color='red'>**decoder**</font>\n","- 입력 문장을 읽어들이는 RNN 모델을 인코더(encoder)라고 한다.\n","- 출력 문장을 생성하는 RNN 모델을 디코더(decoder)라고 한다.\n","- 인코더와 디코더는 서로 파라미터들을 공유하지 않는다.\n","- 아래 그림에서 RNN 의 세부구조를 살펴보면 RNN 모델로서 LSTM 을 사용한 것을 확인할 수 있다.\n","\n","<br>\n","\n","- Seq2seq 모델의 인코더에서 마지막 단어까지 읽어들인 후 마지막 time step에서 나오는 hidden state vector는 디코더에 첫 번째 hidden state vector($h_0$)로 사용된다.\n","  - 이 $h_0$ 는 인코더에서 수집한 정보들을 잘 담고 있다가 이 정보를 바탕으로 디코더는 순차적으로 대응하는 단어를 출력으로 예측하게 된다.\n","\n","<br>\n","\n","- 문장을 생성하는 task 에서 첫 번째 단어로 넣어주는 것을 start token(`<START>`, `<SoS>`) 이라고 한다.\n","- 이러한 특수 단어를 vocabulary 상에 정의해두고 이를 디코더의 첫 번째 time step 의 입력으로 넣어줌으로서 첫 번째 단어에 대한 예측을 실행한다.\n","- 디코더에서 문장 생성이 끝나는 시점은 end token(`<END>`, `<EoS>`)이 등장할 때 이다.\n","\n","<br>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=10VdBQbxvhLlViSM7ASg35YXkSBpzg66S' width=800/>\n","\n","- 출처: Sequence to sequence learning with neural networks, ICML’14"]},{"cell_type":"markdown","metadata":{"id":"Pb6RwjQ1bLMN"},"source":["<br>\n","\n","## 5.2 Recall: Types of RNNs\n","\n","- Sequence-to-sequence\n","  - Machine Translation\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=10_HulVJ2hghzy4TbEy8C28AM1EVb83mN' width=800/>\n","\n","- 출처: http://karpathy.github.io/2015/05/21/rnn-effectiveness/"]},{"cell_type":"markdown","metadata":{"id":"ca9M9RySbdJ6"},"source":["<br>\n","\n","## 5.3 Seq2seq Model with Attention\n","\n","- Attention provides a solution to the bottleneck problem\n","- Seq2seq 모델에서 추가적인 모듈로서 Attention 을 활용할 수 있다.\n","- Attention 모듈의 motivation은 Seq2seq 모델에서 사용하는 RNN 기반의 모델 구조가 입력 시퀀스의 길이에 상관없이 **크기가 정해진 hidden state vector**에 필요한 정보를 저장하여 전달되는 특성의 한계를 느꼈기 때문이다.\n","- Attention 을 사용하게 되면 디코더에서는 인코더의 마지막 time step 에서 나온 hidden state vector 하나에만 의존하는 것이 아니라 인코더의 각각의 time step 에서 나온 hidden state vector들을 사용하게 된다."]},{"cell_type":"markdown","metadata":{"id":"6hKmzpQ-h5En"},"source":["<br>\n","\n","### 5.3.1 Core idea\n","\n","- At each time step of the decoder, focus on a particular part of the source sequence\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=12ptVBI1YcS-zce8BF14pTZDyP2C5T2_e' width=800/>\n","\n","- 출처: https://google.github.io/seq2seq/"]},{"cell_type":"markdown","metadata":{"id":"wqwDzojkdbwc"},"source":["<br>\n","\n","### 5.3.2 Process\n","\n","- Attention 모듈이 동작하는 과정을 자세히 살펴보자.\n","- 프랑스어 문장을 영어로 번역하는 task를 예를 들고 있다.\n","- RNN 모듈이 인코더에서 수행이 될 때 인코더의 hidden state vector 가 4개의 차원으로 이루어져 있다고 하자.\n","  - $h_{1}^{(e)}, h_{2}^{(e)}, h_{3}^{(e)}, h_{4}^{(e)}$\n","\n","<br>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=10g84A30mS4M-niqGlTAah8Qee8MyVlKU' width=400/>\n","\n","<br>\n","\n","- 먼저 인코더의 마지막 time step 의 hidden state vector $h_{4}^{(e)}$가 디코더의 $h_0$ 로서 입력으로 들어간다.\n","- 디코더의 첫 번째 time step 에선 인코더에서 들어온 $h_0$와 `<START>` token으로 주어지는 입력 벡터를 사용하여 hidden state vector $h_{1}^{(d)}$를 생성한다.\n","\n","<br>\n","\n","- $h_{1}^{(d)}$를 다음 단어를 예측하기 위해 사용할 뿐만 아니라 이 벡터를 인코더에서 주어진 4개의 hidden state vector 와 각각 내적 연산을 수행하여 **Attention scores** 를 생성한다.\n","  - 이 Attention scores은 내적에 기반한 유사도로서 볼 수 있다.\n","\n","<br>\n","\n","- 이 값들을 softmax 를 통과시켜서 확률값으로 변환시켜주고 이를 **Attention distribution**이라고 한다.\n","  - 확률값으로 구성된 해당 벡터를 **Attention vector**라고 부른다.\n","- Use the attention distribution to take a weighted sum of the encoder hidden states\n","  - 이 확률값들은 인코더의 hidden state vector에 부여되는 가중치로서 사용된다.\n","\n","<br>\n","\n","- 인코더의 hidden state vector 에 Attention distribution 확률값들을 곱하여 가중평균을 구하여 하나의 인코딩 벡터를 구할 수 있다.\n","- 이렇게 구해진 Attention output를 **Context vector** 라고 부른다.\n","- The attention output mostly contains information the hidden states that received high attention\n","\n","<br>\n","\n","- Attention 모듈은 Attention scores 와 Attention distribution 을 구하는 부분으로 정의한다.\n","- Attention 모듈의 입력\n","  - decoder hidden state vector 1개\n","  - encoder hidden state vector 4개\n","- Attention 모듈의 출력\n","  - encoder hidden state vector 의 가중평균된 하나의 벡터"]},{"cell_type":"markdown","metadata":{"id":"M7V5ADV6dwCn"},"source":["<br>\n","\n","- Concatenate attention output with decoder hidden state, then use to compute $\\widehat{y_{1}}$ as before\n","- 디코더의 hidden state vector 와 Attention module 에 의해 만들어진 context 벡터가 concatenate 되어서 output layer의 입력으로 들어간다.\n","- 이 output layer 를 통해 다음에 나올 단어를 예측하게 된다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=10or0PzXfJnwoHR1gVulZdy3x6WI8Ye_d' width=400/>"]},{"cell_type":"markdown","metadata":{"id":"N7Ht_3rqeFYm"},"source":["<br>\n","\n","- 마찬가지로 디코더의 두 번째 time step에서는 이전 time step에서의 출력 벡터를 입력 벡터와 전달받은 hidden state vector $h_{1}^{(d)}$를 사용하여 새로운 hidden state vector $h_{2}^{(d)}$를 생성한다.\n","- 이 벡터를 앞에서와 같이 Attention 모듈을 적용하여 새로운 context vector 를 만들어서 다음에 나올 단어를 예측하게 된다.\n","  - 동일한 Attention 모듈을 사용하되 Attention scores 를 계산할 때 새롭게 생성된 $h_{2}^{(d)}$를 이용한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=10oxJsJaMuF-tT_a7tki5sFKXxOtx-5D9' width=470/>"]},{"cell_type":"markdown","metadata":{"id":"MsE2JATweSXb"},"source":["<br>\n","\n","- 위와 같은 과정을 3번째 time step 에서도 똑같이 실시한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=10toDI2lGUevPqK5p4ezxQqxpKa5rv5UL' width=550/>"]},{"cell_type":"markdown","metadata":{"id":"w66IFTGueTQL"},"source":["<br>\n","\n","- 위와 같은 과정을 4번째 time step 에서도 똑같이 실시한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=10uB4N1Lr7IbGP9g9DX436rIokHUfVnMI' width=620/>\n"]},{"cell_type":"markdown","metadata":{"id":"NRI21CfYeT1D"},"source":["<br>\n","\n","- 위와 같은 과정을 5번째 time step 에서도 똑같이 실시한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=10uaYgqj1rkvhFDZlkdPP3drKn_tRwrDl' width=690/>"]},{"cell_type":"markdown","metadata":{"id":"iu8-DSvbeVDz"},"source":["<br>\n","\n","- 위와 같은 과정을 6번째 time step 에서도 똑같이 실시한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=112a_coDDNXmTUincCBpv3D8bB_bU9sfD' width=760/>"]},{"cell_type":"markdown","metadata":{"id":"xopW_rJ1xoYM"},"source":["<br>\n","\n","### 5.3.3 Teacher Forcing\n","\n","- 디코더에서 예측한 단어가 잘못된 단어인 경우 그 단어를 다음 time step의 입력 벡터로 사용하게 되면 계속해서 잘못된 단어를 예측하게 된다.\n","- 모델 학습 시 디코더에 입력 단어 벡터를 넣어줄 때 제대로된 단어를 강제로 넣어주는 것을 Teacher Forcing 이라고 한다.\n","- inference 단계에서는 teacher forcing 을 사용하지 않고 디코더에서의 각 time step 에서의 출력 단어 벡터를 다음 time step의 입력 단어 벡터로 사용해야 한다."]},{"cell_type":"markdown","metadata":{"id":"ob8fN2AQemZi"},"source":["<br>\n","\n","## 5.4 Different Attention Mechanisms\n","\n","- 위의 예시에서 디코더의 hidden state vector와 인코더의 hidden state vector들과의 유사도(attention scores)를 구할 때 내적을 사용한다고 했는 데, 사실 이 유사도를 구하는 방법에는 여러 가지가 있다."]},{"cell_type":"markdown","metadata":{"id":"UPbvqMmOfGmz"},"source":["<br>\n","\n","### 5.4.1 Luong attention\n","\n","- they get the decoder hidden state at <font color='red'>time $t$</font>\n","- Then calculate attention scores\n","- From that get the context vector which will be concatenated with hidden state of the decoder and then predict the output.\n","\n","<br>\n","\n","- Luong has different types of alignments.\n","  - $h_t$ : 디코더에서 주어지는 hidden state vector\n","  - $\\overline{\\boldsymbol{h}}_{s}$ : 인코더의 각 time step 에서의 hidden state vector들\n","\n","<br>\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=11CI1mprkgzO2MF06bXj6VSeQDribLLh3' width=500/>\n","\n","<br>\n","\n","- dot product\n","  - 내적 수행\n","  - 내적 수행 시 중간에 항등(단위)행렬을 사용하는 것과 동일한 값이 계산된다.\n","- generalized dot product\n","  - 내적 수행 시 중간에 항등(단위)행렬 대신 다른 값을 갖는 행렬을 사용\n","  - 가중치를 부여하는 것으로 생각\n","- concat (Bahdanau)\n","  - $h_t$ 와 $\\overline{\\boldsymbol{h}}_{s}$ 를 이용해서 새로운 학습 가능한 neural network 를 생성\n","  - **이 벡터들을 concatenate** 하여 fully connected layer 를 통과시켜 하나의 스칼라값을 갖도록 모델을 구성할 수 있다.\n","  - 중간에 hidden layer를 추가하는 것도 가능하다.\n","  - 여기서 사용되는 파라미터들의 최적화는 Attention module의 backpropagation 과정에 의해서 업데이트될 수 있다."]},{"cell_type":"markdown","metadata":{"id":"Hd1LmRLQfgOd"},"source":["<br>\n","\n","### 5.4.2 Bahdanau attention\n","\n","- At time $t$, we consider the hidden state of the decoder at <font color='red'>time $t$ − 1</font>.\n","- Then we calculate the alignment, context vectors as above.\n","- But then we concatenate this context with hidden state of the decoder at time $t$ − 1.\n","- So before the softmax, this concatenated vector goes inside a LSTM unit.\n","\n","<br>\n","\n","- Bahdanau has only a **concat-score alignment** model."]},{"cell_type":"markdown","metadata":{"id":"gBv16VYIf3qu"},"source":["<br>\n","\n","## 5.5 Attention is Great!\n","\n","- Attention significantly improves NMT performance\n","  - It is useful to allow the decoder to focus on particular parts of the source\n","- Attention solves the bottleneck problem\n","  - Attention allows the decoder to look directly at source; bypass the bottleneck\n","- Attention helps with vanishing gradient problem\n","  - Provides a shortcut to far-away states\n","- Attention provides some interpretability(해석가능성)\n","  - By inspecting attention distribution, we can see what the decoder was focusing on\n","  - The network just learned alignment by itself"]},{"cell_type":"markdown","metadata":{"id":"QZCTMidsg4UV"},"source":["<br>\n","\n","## 5.6 Attention Examples in Machine Translation\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=11Rh5A-7o260BGye7D0iXuiE88O9BzBD0' width=700/>\n","\n","- It properly learns grammatical orders of words\n","- It skips unnecessary  words such as an article"]},{"cell_type":"markdown","metadata":{"id":"k_jaVHBDhXHE"},"source":["<br>\n","\n","## 5.7 실습: Seq2seq\n","\n","1. Encoder 를 구현한다.\n","2. Decoder 를 구현한다.\n","3. Seq2seq 모델을 구축하고 사용한다."]},{"cell_type":"markdown","metadata":{"id":"_ytGllsIjLC0"},"source":["<br>\n","\n","### 5.7.1 필요 패키지 import"]},{"cell_type":"code","metadata":{"id":"utDs1gkdjbRL"},"source":["from tqdm import tqdm\n","from torch import nn\n","from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n","\n","import torch\n","import random\n","from pprint import pprint"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"23cc6-zBjc2l"},"source":["<br>\n","\n","### 5.7.2 데이터 전처리\n","\n","- `src_data` 를 `trg_data` 로 바꾸는 task 를 수행하기 위한 sample data 이다.\n","- 전체 단어 수는 100개이고 다음과 같이 pad token, start token, end token 의 id 도 정의한다."]},{"cell_type":"code","metadata":{"id":"OfXeDAxjjtdT"},"source":["vocab_size = 100\n","pad_id = 0\n","sos_id = 1\n","eos_id = 2\n","\n","src_data = [\n","  [3, 77, 56, 26, 3, 55, 12, 36, 31],\n","  [58, 20, 65, 46, 26, 10, 76, 44],\n","  [58, 17, 8],\n","  [59],\n","  [29, 3, 52, 74, 73, 51, 39, 75, 19],\n","  [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93],\n","  [39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99, 5],\n","  [75, 34, 17, 3, 86, 88],\n","  [63, 39, 5, 35, 67, 56, 68, 89, 55, 66],\n","  [12, 40, 69, 39, 49]\n","]\n","\n","trg_data = [\n","  [75, 13, 22, 77, 89, 21, 13, 86, 95],\n","  [79, 14, 91, 41, 32, 79, 88, 34, 8, 68, 32, 77, 58, 7, 9, 87],\n","  [85, 8, 50, 30],\n","  [47, 30],\n","  [8, 85, 87, 77, 47, 21, 23, 98, 83, 4, 47, 97, 40, 43, 70, 8, 65, 71, 69, 88],\n","  [32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18],\n","  [37, 14, 49, 24, 93, 37, 54, 51, 39, 84],\n","  [16, 98, 68, 57, 55, 46, 66, 85, 18],\n","  [20, 70, 14, 6, 58, 90, 30, 17, 91, 18, 90],\n","  [37, 93, 98, 13, 45, 28, 89, 72, 70]\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_jYnpiBhjyEc"},"source":["<br>\n","\n","- 각각의 데이터를 전처리한다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vuc_ViY_j1Az","executionInfo":{"status":"ok","timestamp":1631107181856,"user_tz":-540,"elapsed":4,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"92f2ca80-71ee-4108-fa4b-47d8fcd8bb9c"},"source":["trg_data = [[sos_id] + seq + [eos_id] for seq in tqdm(trg_data)]\n","\n","for t in trg_data:\n","    print(t)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 14706.54it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","[1, 75, 13, 22, 77, 89, 21, 13, 86, 95, 2]\n","[1, 79, 14, 91, 41, 32, 79, 88, 34, 8, 68, 32, 77, 58, 7, 9, 87, 2]\n","[1, 85, 8, 50, 30, 2]\n","[1, 47, 30, 2]\n","[1, 8, 85, 87, 77, 47, 21, 23, 98, 83, 4, 47, 97, 40, 43, 70, 8, 65, 71, 69, 88, 2]\n","[1, 32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18, 2]\n","[1, 37, 14, 49, 24, 93, 37, 54, 51, 39, 84, 2]\n","[1, 16, 98, 68, 57, 55, 46, 66, 85, 18, 2]\n","[1, 20, 70, 14, 6, 58, 90, 30, 17, 91, 18, 90, 2]\n","[1, 37, 93, 98, 13, 45, 28, 89, 72, 70, 2]\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","metadata":{"id":"AHFqtZjXj6yj"},"source":["def padding(data, is_src=True):\n","    max_len = len(max(data, key=len))\n","    print(f\"Maximum sequence length: {max_len}\")\n","\n","    valid_lens = []\n","    for i, seq in enumerate(tqdm(data)):\n","        valid_lens.append(len(seq))\n","        if len(seq) < max_len:\n","            data[i] = seq + [pad_id] * (max_len - len(seq))\n","\n","    return data, valid_lens, max_len"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qX3UEDj6mli2","executionInfo":{"status":"ok","timestamp":1631107863682,"user_tz":-540,"elapsed":9,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"d0867c9e-18d8-4ff8-8498-17982138853b"},"source":["src_data, src_lens, src_max_len = padding(src_data)\n","trg_data, trg_lens, trg_max_len = padding(trg_data)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum sequence length: 15\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 16339.32it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Maximum sequence length: 22\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:00<00:00, 72691.58it/s]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5umGbeiCmrNz","executionInfo":{"status":"ok","timestamp":1631107938677,"user_tz":-540,"elapsed":490,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"65904138-98c8-43f0-cf13-dd2d600ee4e7"},"source":["# B: batch size, S_L: source maximum sequence length, T_L: target maximum sequence length\n","src_batch = torch.LongTensor(src_data)  # (B, S_L)\n","src_batch_lens = torch.LongTensor(src_lens)  # (B)\n","trg_batch = torch.LongTensor(trg_data)  # (B, T_L)\n","trg_batch_lens = torch.LongTensor(trg_lens)  # (B)\n","\n","print(src_batch.shape)\n","print(src_batch_lens.shape)\n","print(trg_batch.shape)\n","print(trg_batch_lens.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10, 15])\n","torch.Size([10])\n","torch.Size([10, 22])\n","torch.Size([10])\n"]}]},{"cell_type":"markdown","metadata":{"id":"j4FfaL9lm_SD"},"source":["<br>\n","\n","- PackedSquence를 사용을 위해 source data를 기준으로 정렬합니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"muGTv7TonE3T","executionInfo":{"status":"ok","timestamp":1631108095009,"user_tz":-540,"elapsed":1013,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"efc6b304-4df5-4b70-ce19-eb171a7e03bb"},"source":["src_batch_lens, sorted_idx = src_batch_lens.sort(descending=True)\n","src_batch = src_batch[sorted_idx]\n","trg_batch = trg_batch[sorted_idx]\n","trg_batch_lens = trg_batch_lens[sorted_idx]\n","\n","print(src_batch)\n","print(src_batch_lens)\n","print(trg_batch)\n","print(trg_batch_lens)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[39, 47, 96, 68, 55, 16, 90, 45, 89, 84, 19, 22, 32, 99,  5],\n","        [41, 55, 77, 21, 52, 92, 97, 69, 54, 14, 93,  0,  0,  0,  0],\n","        [63, 39,  5, 35, 67, 56, 68, 89, 55, 66,  0,  0,  0,  0,  0],\n","        [ 3, 77, 56, 26,  3, 55, 12, 36, 31,  0,  0,  0,  0,  0,  0],\n","        [29,  3, 52, 74, 73, 51, 39, 75, 19,  0,  0,  0,  0,  0,  0],\n","        [58, 20, 65, 46, 26, 10, 76, 44,  0,  0,  0,  0,  0,  0,  0],\n","        [75, 34, 17,  3, 86, 88,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [12, 40, 69, 39, 49,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [58, 17,  8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n","        [59,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])\n","tensor([15, 11, 10,  9,  9,  8,  6,  5,  3,  1])\n","tensor([[ 1, 37, 14, 49, 24, 93, 37, 54, 51, 39, 84,  2,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 32, 37, 31, 77, 38, 93, 45, 74, 47, 54, 31, 18,  2,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 20, 70, 14,  6, 58, 90, 30, 17, 91, 18, 90,  2,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 75, 13, 22, 77, 89, 21, 13, 86, 95,  2,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1,  8, 85, 87, 77, 47, 21, 23, 98, 83,  4, 47, 97, 40, 43, 70,  8, 65,\n","         71, 69, 88,  2],\n","        [ 1, 79, 14, 91, 41, 32, 79, 88, 34,  8, 68, 32, 77, 58,  7,  9, 87,  2,\n","          0,  0,  0,  0],\n","        [ 1, 16, 98, 68, 57, 55, 46, 66, 85, 18,  2,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 37, 93, 98, 13, 45, 28, 89, 72, 70,  2,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 85,  8, 50, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0],\n","        [ 1, 47, 30,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n","          0,  0,  0,  0]])\n","tensor([12, 14, 13, 11, 22, 18, 11, 11,  6,  4])\n"]}]},{"cell_type":"markdown","metadata":{"id":"QGw_ADJRnSeW"},"source":["<br>\n","\n","### 5.7.3 Encoder 구현"]},{"cell_type":"code","metadata":{"id":"nZsxLx8VoIkx"},"source":["embedding_size = 256\n","hidden_size = 512\n","num_layers = 2\n","num_dirs = 2\n","dropout = 0.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A26lGzstodi2"},"source":["<br>\n","\n","- Bidirectional GRU를 이용한 Encoder입니다.\n","  - `self.embedding`: word embedding layer.\n","  - `self.gru`: encoder 역할을 하는 Bi-GRU.\n","  - `self.linear`: 양/단방향 concat된 hidden state를 decoder의 hidden size에 맞게 linear transformation.\n"]},{"cell_type":"code","metadata":{"id":"tJ2dC1baojob"},"source":["class Encoder(nn.Module):\n","    def __init__(self):\n","        super(Encoder, self).__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_size)\n","        self.gru = nn.GRU(\n","            input_size=embedding_size,\n","            hidden_size=hidden_size,\n","            num_layers=num_layers,\n","            bidirectional=True if num_dirs > 1 else False,\n","            dropout=dropout\n","        )\n","        self.linear = nn.Linear(num_dirs * hidden_size, hidden_size)\n","\n","    def forward(self, batch, batch_lens): # batch: (B, S_L), batch_lens: (B)\n","        # d_w: word embedding size\n","        batch_emb = self.embedding(batch) # (B, S_L, d_w)\n","        batch_emb = batch_emb.transpose(0, 1) # (S_L, B, d_w)\n","\n","        packed_input = pack_padded_sequence(batch_emb, batch_lens)\n","\n","        h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size)) # (num_layers*num_dirs, B, d_h) = (4, B, d_h)\n","        packed_outputs, h_n = self.gru(packed_input, h_0) # h_n: (4, B, d_h)\n","        outputs = pad_packed_sequence(packed_outputs)[0] # outputs: (S_L, B, 2d_h)\n","\n","        forward_hidden = h_n[-2, :, :]\n","        backward_hidden = h_n[-1, :, :]  \n","        hidden = self.linear(torch.cat((forward_hidden, backward_hidden), dim=-1)).unsqueeze(0) # (1, B, d_h)\n","\n","        return outputs, hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-89zmj5Hq-tu"},"source":["encoder = Encoder()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DkUfNYVdrBZ-"},"source":["<br>\n","\n","### 5.7.4 Decoder 구현\n","\n","- 동일한 설정의 Bi-GRU로 만든 Decoder입니다.\n","  - `self.embedding`: word embedding layer.\n","  - `self.gru`: decoder 역할을 하는 Bi-GRU.\n","  - `self.output_layer`: decoder에서 나온 hidden state를 `vocab_size`로 linear transformation하는 layer."]},{"cell_type":"code","metadata":{"id":"nl6pVM-5uHTM"},"source":["class Decoder(nn.Module):\n","  def __init__(self):\n","    super(Decoder, self).__init__()\n","\n","    self.embedding = nn.Embedding(vocab_size, embedding_size)\n","    self.gru = nn.GRU(\n","        input_size=embedding_size, \n","        hidden_size=hidden_size,\n","    )\n","    self.output_layer = nn.Linear(hidden_size, vocab_size)\n","\n","  def forward(self, batch, hidden):  # batch: (B), hidden: (1, B, d_h)\n","    batch_emb = self.embedding(batch)  # (B, d_w)\n","    batch_emb = batch_emb.unsqueeze(0)  # (1, B, d_w)\n","\n","    outputs, hidden = self.gru(batch_emb, hidden)  # outputs: (1, B, d_h), hidden: (1, B, d_h)\n","    \n","    # V: vocab size\n","    outputs = self.output_layer(outputs)  # (1, B, V)\n","\n","    return outputs.squeeze(0), hidden"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzdA7hatuNkp"},"source":["decoder = Decoder()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GM6hz1qLuPB9"},"source":["<br>\n","\n","### 5.7.5 Seq2seq 모델 구축\n","\n","- 생성한 encoder와 decoder를 합쳐 Seq2seq 모델을 구축합니다.\n","  - `self.encoder`: encoder.\n","  - `self.decoder`: decoder."]},{"cell_type":"code","metadata":{"id":"LV7PkBEsudK9"},"source":["class Seq2seq(nn.Module):\n","    def __init__(self, encoder, decoder):\n","        super(Seq2seq, self).__init__()\n","\n","        self.encoder = encoder\n","        self.decoder = decoder\n","\n","    def forward(self, src_batch, src_batch_lens, trg_batch, teacher_forcing_prob=0.5):\n","        # src_batch: (B, S_L)\n","        # src_batch_lens: (B)\n","        # trg_batch: (B, T_L)\n","\n","        _, hidden = self.encoder(src_batch, src_batch_lens) # hidden: (1, B, d_h)\n","\n","        input_ids = trg_batch[:, 0] # (B)\n","        batch_size = src_batch.shape[0]\n","        outputs = torch.zeros(trg_max_len, batch_size, vocab_size) # (T_L, B, V)\n","\n","        for t in range(1, trg_max_len):\n","            decoder_outputs, hidden = self.decoder(input_ids, hidden) # decoder_outputs: (B, V), hidden: (1, B, d_h)\n","\n","            outputs[t] = decoder_outputs\n","            _, top_ids = torch.max(decoder_outputs, dim=-1) # top_ids: (B)\n","\n","            input_ids = trg_batch[:, t] if random.random() > teacher_forcing_prob else top_ids\n","\n","        return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-CI7gQvswNk1"},"source":["seq2seq = Seq2seq(encoder, decoder)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yy2BZe0twPbT"},"source":["<br>\n","\n","### 5.7.6 모델 사용해보기\n","\n","- 학습 과정이라고 가정하고 모델에 input을 넣어봅니다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XDQMKS2NwVbD","executionInfo":{"status":"ok","timestamp":1631110499493,"user_tz":-540,"elapsed":622,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"e6db0888-73f6-4a95-9dc7-29971a558ce1"},"source":["outputs = seq2seq(src_batch, src_batch_lens, trg_batch)\n","\n","print(outputs)\n","print(outputs.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         ...,\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n","\n","        [[ 0.2533, -0.1049, -0.0585,  ..., -0.0565,  0.1070, -0.0453],\n","         [ 0.2580, -0.1068, -0.0577,  ...,  0.0177,  0.1002, -0.0476],\n","         [ 0.2205, -0.1333, -0.0125,  ...,  0.0085,  0.0785, -0.0423],\n","         ...,\n","         [ 0.1932, -0.1302, -0.0284,  ...,  0.0264,  0.0803, -0.0160],\n","         [ 0.2197, -0.1176, -0.0521,  ...,  0.0193,  0.0980, -0.0733],\n","         [ 0.2213, -0.1205, -0.0525,  ...,  0.0288,  0.1000, -0.0395]],\n","\n","        [[ 0.1053,  0.0687, -0.0634,  ...,  0.0505, -0.0122,  0.1181],\n","         [ 0.0684,  0.0842, -0.0570,  ..., -0.0730,  0.1683, -0.0242],\n","         [ 0.1570, -0.1907,  0.0517,  ...,  0.0817, -0.0596, -0.1490],\n","         ...,\n","         [ 0.0770,  0.0455, -0.0506,  ...,  0.0904, -0.0288,  0.1310],\n","         [ 0.2327, -0.1220,  0.0281,  ..., -0.0750,  0.0338,  0.0305],\n","         [ 0.0552, -0.1648,  0.0352,  ...,  0.0835,  0.0171,  0.1351]],\n","\n","        ...,\n","\n","        [[-0.0750, -0.2232, -0.1743,  ...,  0.3806, -0.0131,  0.1312],\n","         [-0.1523, -0.1630,  0.0203,  ...,  0.2757,  0.0127,  0.1636],\n","         [-0.1003, -0.2098, -0.1703,  ...,  0.4040, -0.0296,  0.1617],\n","         ...,\n","         [-0.0635, -0.2073, -0.1690,  ...,  0.3978, -0.0164,  0.1391],\n","         [-0.1541, -0.1755,  0.0075,  ...,  0.2903,  0.0166,  0.1445],\n","         [-0.1531, -0.1755,  0.0075,  ...,  0.2897,  0.0161,  0.1448]],\n","\n","        [[-0.1500, -0.0292,  0.1350,  ...,  0.1089,  0.0338,  0.1233],\n","         [-0.0333, -0.2163, -0.1476,  ...,  0.3382,  0.0030,  0.1642],\n","         [-0.1640, -0.0203,  0.1349,  ...,  0.1248,  0.0291,  0.1465],\n","         ...,\n","         [-0.1444, -0.0193,  0.1335,  ...,  0.1199,  0.0348,  0.1309],\n","         [-0.0390, -0.2208, -0.1564,  ...,  0.3486,  0.0017,  0.1531],\n","         [-0.0386, -0.2208, -0.1564,  ...,  0.3482,  0.0012,  0.1533]],\n","\n","        [[-0.0268, -0.1161, -0.1128,  ...,  0.2990,  0.0240,  0.1286],\n","         [-0.0047, -0.1848, -0.2342,  ...,  0.3318,  0.1120, -0.0350],\n","         [-0.0333, -0.1121, -0.1127,  ...,  0.3075,  0.0216,  0.1412],\n","         ...,\n","         [-0.0215, -0.1120, -0.1158,  ...,  0.3070,  0.0234,  0.1339],\n","         [-0.0077, -0.1861, -0.2400,  ...,  0.3401,  0.1105, -0.0428],\n","         [-0.0075, -0.1862, -0.2400,  ...,  0.3399,  0.1103, -0.0427]]],\n","       grad_fn=<CopySlices>)\n","torch.Size([22, 10, 100])\n"]}]},{"cell_type":"markdown","metadata":{"id":"x6h7rSTAwe4M"},"source":["<br>\n","\n","- Language Modeling 에 대한 loss 계산을 위해 shift 한 target 과 비교한다.\n","\n","&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","<img src='https://drive.google.com/uc?id=11UNRhJug0bK6VVfhm5Nj5fi8Y7h3v6p8' width=800/>"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMn_yzz6xIsc","executionInfo":{"status":"ok","timestamp":1631110825709,"user_tz":-540,"elapsed":494,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"b541779e-e675-4619-dce8-662720c651f8"},"source":["loss_function = nn.CrossEntropyLoss()\n","\n","preds = outputs[1:, :, :].transpose(0, 1) # (B, T_L-1, V)\n","loss = loss_function(\n","    preds.contiguous().view(-1, vocab_size),\n","    trg_batch[:, 1:].contiguous().view(-1, 1).squeeze(1)\n",")\n","\n","print(loss)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(4.6455, grad_fn=<NllLossBackward>)\n"]}]},{"cell_type":"markdown","metadata":{"id":"iyIeukpdx_-d"},"source":["<br>\n","\n","- 실제 inference에선 teacher forcing 없이 이전 결과만을 가지고 생성합니다."]},{"cell_type":"code","metadata":{"id":"_iG5iflDyGh_"},"source":["src_sent = [4, 10, 88, 46, 72, 34, 14, 51]\n","src_len = len(src_sent)\n","\n","src_batch = torch.LongTensor(src_sent).unsqueeze(0)  # (1, L)\n","src_batch_lens = torch.LongTensor([src_len])  # (1)\n","\n","_, hidden = seq2seq.encoder(src_batch, src_batch_lens)  # hidden: (1, 1, d_h)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a6q7mlVdyLj9"},"source":["input_id = torch.LongTensor([sos_id]) # (1)\n","output = []\n","\n","for t in range(1, trg_max_len):\n","  decoder_output, hidden = seq2seq.decoder(input_id, hidden)  # decoder_output: (1, V), hidden: (1, 1, d_h)\n","\n","  _, top_id = torch.max(decoder_output, dim=-1)  # top_ids: (1)\n","\n","  if top_id == eos_id:\n","    break\n","  else:\n","    output += top_id.tolist()\n","    input_id = top_id"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fjPrGGdryQnM","executionInfo":{"status":"ok","timestamp":1631110906653,"user_tz":-540,"elapsed":611,"user":{"displayName":"김성한","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg4suhwOAnN5grX1rwPh5jj9nqx3rC6svCtsnJJLQ=s64","userId":"13992033533003163921"}},"outputId":"35a50571-d719-46b7-b3fb-f7bad05228b3"},"source":["print(output)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[77, 5, 8, 33, 36, 77, 6, 65, 58, 31, 58, 31, 58, 31, 58, 31, 58, 31, 58, 31, 58]\n"]}]},{"cell_type":"code","metadata":{"id":"IrG-kWyyySBG"},"source":[""],"execution_count":null,"outputs":[]}]}